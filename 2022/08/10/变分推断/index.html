<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>变分推断 | Seline's blog</title><meta name="keywords" content="变分推断,共轭先验"><meta name="author" content="Seline"><meta name="copyright" content="Seline"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="从一个 z 的先验分布prior，用观测到的数据 x 对参数 z 有一个更新，计算出posterior distribution 计算的方法就是用贝叶斯定理 p(x)还可以写成 $\int_zp(x,z)dz$ 可以用后验分布的统计量（posterior means and variances）表示后验分布。但高维的贝叶斯计算比较困难 近似推断 大多数情况下posterior没有解析解。常用">
<meta property="og:type" content="article">
<meta property="og:title" content="变分推断">
<meta property="og:url" content="https://seline02.github.io/2022/08/10/%E5%8F%98%E5%88%86%E6%8E%A8%E6%96%AD/index.html">
<meta property="og:site_name" content="Seline&#39;s blog">
<meta property="og:description" content="从一个 z 的先验分布prior，用观测到的数据 x 对参数 z 有一个更新，计算出posterior distribution 计算的方法就是用贝叶斯定理 p(x)还可以写成 $\int_zp(x,z)dz$ 可以用后验分布的统计量（posterior means and variances）表示后验分布。但高维的贝叶斯计算比较困难 近似推断 大多数情况下posterior没有解析解。常用">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">
<meta property="article:published_time" content="2022-08-10T04:22:33.000Z">
<meta property="article:modified_time" content="2022-11-11T15:24:20.056Z">
<meta property="article:author" content="Seline">
<meta property="article:tag" content="变分推断">
<meta property="article:tag" content="共轭先验">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://seline02.github.io/2022/08/10/%E5%8F%98%E5%88%86%E6%8E%A8%E6%96%AD/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '变分推断',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-11-11 23:24:20'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.2.0"><link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">37</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">9</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><hr/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Seline's blog</a></span><div id="menus"><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">变分推断</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-08-10T04:22:33.000Z" title="发表于 2022-08-10 12:22:33">2022-08-10</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-11-11T15:24:20.056Z" title="更新于 2022-11-11 23:24:20">2022-11-11</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="变分推断"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p><img src="image-20220810122345098.png" alt="image-20220810122345098" style="zoom:50%;"></p>
<p><img src="image-20220810122350369.png" alt="image-20220810122350369" style="zoom:50%;"></p>
<p><img src="image-20220810122356631.png" alt="image-20220810122356631" style="zoom:50%;"></p>
<p>从一个 z 的先验分布prior，用观测到的数据 x 对参数 z 有一个更新，计算出posterior distribution</p>
<p>计算的方法就是用贝叶斯定理</p>
<p>p(x)还可以写成 $\int_zp(x,z)dz$</p>
<p>可以用后验分布的统计量（posterior means and variances）表示后验分布。但高维的贝叶斯计算比较困难</p>
<h4 id="近似推断"><a href="#近似推断" class="headerlink" title="近似推断"></a>近似推断</h4><p><img src="image-20220810122426170.png" alt="image-20220810122426170" style="zoom:50%;"></p>
<p>大多数情况下posterior没有解析解。常用的计算它的方法是MCMC，但速度慢</p>
<p><img src="image-20220810122436994.png" alt="image-20220810122436994" style="zoom:50%;"></p>
<p>要在Q（是一个distribution family）中找一个distribution $q^*(z)$ 和target p(z|x)最近。要定义某种距离L。</p>
<p>目标函数就是 $q^*(z)=argmin_{q(z)\in Q}L(q(z),p(z|x))$</p>
<p>最常用的度量两个distribution间的distance是KL，此时称作variational bayes</p>
<p><img src="image-20220810123326588.png" alt="image-20220810123326588" style="zoom:50%;"></p>
<p>$p(z|x)$ 是unknown的，KL不好直接计算，需要进行某种转化</p>
<p>当 $q^*(z)=p(z|x)$时，理论上达到最优，但 $p(z|x)$ 是不知道的</p>
<p><img src="image-20220810123345509.png" alt="image-20220810123345509" style="zoom:50%;"></p>
<p><img src="image-20220810123352855.png" alt="image-20220810123352855" style="zoom:50%;"></p>
<p>KL = -ELBO + log p(x)</p>
<p>log p(x) = ELBO + KL</p>
<p>log p(x) 是一个常数，最小化 KL，等价于最大化 ELBO</p>
<p>原本想最小化KL，但是后验 p(z|x) 不知道；但是转化为求 ELBO，经过变形是 $\int_zq(z)\log[\frac{p(x,z)}{q(z)}]dz$，其中联合概率 $p(x,z)$ 是知道的，$p(x,z)=p(x|z)p(z)$，其中 $p(x|z)$ 是likelihood，$p(z)$ 是prior，都是知道的</p>
<p>为什么叫 evidence lower bound？$\log p(x)$ 是关于数据的信息，是evidence，KL ≥ 0，log p(x) = ELBO + KL ≥ ELBO，ELBO是evidence的lower bound</p>
<h4 id="平均场推断"><a href="#平均场推断" class="headerlink" title="平均场推断"></a>平均场推断</h4><p><img src="image-20220810133424612.png" alt="image-20220810133424612" style="zoom:50%;"></p>
<p><img src="image-20220810133431783.png" alt="image-20220810133431783" style="zoom:50%;"></p>
<p><img src="image-20220810133437065.png" alt="image-20220810133437065" style="zoom:50%;"></p>
<p>先<strong>把对KL求min的问题转化成对ELBO求max的问题</strong>，再加入一个假设：假设q(z)是可以分解的，其中z有m个分量，逐个优化</p>
<p><img src="image-20220810133447260.png" alt="image-20220810133447260" style="zoom:50%;"></p>
<p>推导：</p>
<p><img src="image-20220810133457154.png" alt="image-20220810133457154" style="zoom:50%;"></p>
<p>从第一步到第二步是因为 q(z) 可以分解，z有m维。把z表示成 $z_j$ 和除了 $z_j$ 之外的变量 $z_{-j}$ (m-1维)</p>
<p>把 $q_j$ 看成一个变量，只对它做优化</p>
<p>第二步到第三步是先对除了 $z_j$ 以外的变量做积分，再对 $z_j$ 积分</p>
<p>定义一个新的分布，假设这个新的分布服从 $\log \widetilde{p}_j(z_j,x)=\mathbb{E}_{q_{-j}}[\log p(z,x)]$ + const，替换原来式子中的</p>
<p><img src="image-20220810133508213.png" alt="image-20220810133508213" style="zoom:50%;"></p>
<p><img src="image-20220810133515301.png" alt="image-20220810133515301" style="zoom:50%;"></p>
<p>$\mathrm{max}_{q_j}ELBO(q_j)$ 的问题又可以转化为 $\mathrm{min}_{q_j}KL(q_j||\widetilde{p}_j(z_j,x))$ 的问题</p>
<p>$q_j^*(z_j)$ 是关于 $z_j$ 的密度函数，对它求积分为1，由此可以求出const</p>
<p><img src="image-20220810133529980.png" alt="image-20220810133529980" style="zoom:50%;"></p>
<p><img src="image-20220810133537304.png" alt="image-20220810133537304" style="zoom:50%;"></p>
<p>一个例子：连数据都没有，直接用 $q(z)$ 去近似 $p(z)$</p>
<p><img src="image-20220810133553397.png" alt="image-20220810133553397" style="zoom:50%;"></p>
<p>对<img src="image-20220810133606511.png" alt="image-20220810133606511" style="zoom:33%;">进行配方，得到正态分布指数的形式</p>
<p>形成如下①②两个方程</p>
<p><img src="image-20220810133621289.png" alt="image-20220810133621289" style="zoom:50%;"></p>
<p>可以解得 $\mathbb{E}[z_1]=\mu_1,\mathbb{E}[z_2]=\mu_2$</p>
<p>有一个解析解<img src="image-20220810133633289.png" alt="image-20220810133633289" style="zoom:50%;"></p>
<p><img src="image-20220810133638932.png" alt="image-20220810133638932" style="zoom:50%;"></p>
<p>mean可以估计到，但是variance不准确，这里估计的co-variance是0，不准确</p>
<p><img src="image-20220810133651002.png" alt="image-20220810133651002" style="zoom:50%;"></p>
<p><img src="image-20220810133656691.png" alt="image-20220810133656691" style="zoom:50%;"></p>
<p>右边的是把 $KL(p(z)||q(z))$ 作为目标函数</p>
<p>这种方法叫做 Expectation Propagation</p>
<p><img src="image-20220810133705089.png" alt="image-20220810133705089" style="zoom:50%;"></p>
<p>对 $q_j$ 做优化，得到的解析解是 $p(z)$ 对 $z_j$ 的边缘分布</p>
<p><img src="image-20220810133712125.png" alt="image-20220810133712125" style="zoom:50%;"></p>
<p>第三个等号到第四个等号将 $\int$ 分成两部分，对 $z_j$ 积分的，以及对除了 $z_j$ 以外积分的</p>
<p>记 $\int_{z_{-j}}p(z)dz_{-j}=F_j$</p>
<p><img src="image-20220810133721060.png" alt="image-20220810133721060" style="zoom:50%;"></p>
<p>$q_j(z_j)$ 作为概率密度函数，积分为1</p>
<p><img src="image-20220810133729180.png" alt="image-20220810133729180" style="zoom:50%;"></p>
<p>$\lambda q_j(z_j)=F_j(z_j)$，两边同时积分等于1，求得 $\lambda=1$，带回得到 $q^*_j(z_j)$ 的解析解</p>
<h4 id="期望推断和变分推断的区别"><a href="#期望推断和变分推断的区别" class="headerlink" title="期望推断和变分推断的区别"></a>期望推断和变分推断的区别</h4><p><img src="image-20220810133746404.png" alt="image-20220810133746404" style="zoom:50%;"></p>
<p>(a)(b)用的是VB，会under-estimate</p>
<p>(c)用的是EP，会over-estimate</p>
<p><img src="image-20220810133754054.png" alt="image-20220810133754054" style="zoom:50%;"></p>
<p>对于VB，凡是 $p(z)=0$ 的地方 $q(z)$ 都要为0，在图中就会避开 $p(z)$ 比较小的地方 ；对于 EP，凡是 $p(z)&gt;0$ 的地方 $q(z)$ 都要 &gt; 0，在图中就是区间拉得会比较大</p>
<h4 id="共轭先验"><a href="#共轭先验" class="headerlink" title="共轭先验"></a>共轭先验</h4><p><img src="image-20220810133810925.png" alt="image-20220810133810925" style="zoom:50%;"></p>
<p>贝叶斯统计的一个缺点就是贝叶斯公式计算起来比频率派的参数估计更加复杂，那么如何选取先验分布才能使得贝叶斯统计的过程变得更加容易计算，就是一个非常现实的问题。</p>
<p>贝叶斯统计为什么难以计算？一个最直接的困难是通常难以保证后验分布具有解析解（后验分布的密度函数具有解析解）</p>
<p>观察贝叶斯公式，分母是积分形式，那么不一定具有解析解，意味着整个后验分布不一定有解析解。观察式子，是否有解析解取决于模型和先验分布的选取。</p>
<p>那么是否只要选取了使后验分布具有解析解的模型和先验分布即可呢？不是。因为贝叶斯统计往往是一个不断收集数据并更新参数分布的迭代过程。之所以说是迭代过程，是因为数据通常是逐渐收集的，而不是一次性收集的。每当收集一定的实验数据后，都会更新参数的分布，也就是利用贝叶斯公式计算后验分布。如此一轮轮地迭代更新。除了第一轮，每轮都会把上一轮得到的后验分布设为新一轮中的先验分布，然后再去计算新的后验分布。</p>
<p>所以不仅要保证先验和模型带入贝叶斯公式后可以产生具有解析解的后验分布，还要保证在下一轮迭代中，把上一轮迭代产生的后验分布设为新的先验分布之后，得出的新的后验分布依然具有解析解。</p>
<p>想要实现这一点，一个直接的想法就是让先验分布和后验分布同属于一个参数化分布族，也就是让先验分布和后验分布的表达形式相同。这样不仅保证了每一轮计算得到的后验分布具有解析解，还保证了每一轮可以使用相同的计算公式计算后验分布。</p>
<p>那么如何让后验分布和先验分布有相同形式的表达式？</p>
<p>把在给定模型的情况下，先验分布的分布族和后验分布的分布族相同的现象称为共轭先验。 </p>
<p><img src="image-20220810133824136.png" alt="image-20220810133824136" style="zoom:50%;"></p>
<p>实际应用中，β分布常作为先验分布使用。当模型是伯努利分布或二项分布时，β分布都是这个模型的共轭先验。但β分布自身也是一个参数化分布族，有自己的参数α、β。那怎么区分模型的参数和先验分布的参数呢？</p>
<p>在贝叶斯统计中，通常把先验或后验分布的参数称为超参数。如果β分布作为先验分布，那么β分布的两个参数α、β就可以作为超参数，而模型的参数依然叫做参数。从而可以区分先验分布的参数和模型的参数。</p>
<p><img src="image-20220810133833220.png" alt="image-20220810133833220" style="zoom:50%;"></p>
<p><img src="image-20220810133839728.png" alt="image-20220810133839728" style="zoom:50%;"></p>
<p>PDF：概率密度函数，连续型变量；PMF：概率质量函数，离散型变量</p>
<p>直接套用贝叶斯公式</p>
<p>第二个正比于是因为 B(α，β) 与 θ 无关</p>
<p><img src="image-20220810133847814.png" alt="image-20220810133847814" style="zoom:50%;"></p>
<p>高斯分布通常在已知方差/均值二者之一的情况下容易找到共轭先验。高斯-高斯共轭就是在已知方差的情况下</p>
<p><img src="image-20220810133856033.png" alt="image-20220810133856033" style="zoom:50%;"></p>
<p>角标为s的都是模型的参数：$\mu_s,\sigma^2_s$；角标为p的都是先验的参数/超参数：$\mu_p,\sigma^2_p$</p>
<p>s是signal的首字母，也称 $\mu_s$ 为信号均值，$\sigma^2_s$ 为信号方差</p>
<p>p是prior的首字母，也称 $\mu_p$ 为先验均值，$\sigma^2_p$ 为先验方差</p>
<p>高斯-高斯共轭只适用于信号方差已知，信号均值未知的情况</p>
<p><img src="image-20220810133904701.png" alt="image-20220810133904701" style="zoom:50%;"></p>
<p>直接套用贝叶斯定理会比较麻烦。</p>
<p>利用引理</p>
<p>高斯-高斯共轭的设定中，所谓的后验分布其实就是 $\mu_s|x$ 的分布。所以想套用这个引理，只需要证明 $\mu_s$ 和 $x$ 所构成的随机向量服从二元高斯分布即可。</p>
<p>如何证明 $\mu_s$ 和 $x$ 所构成的随机向量服从二元高斯分布？</p>
<p>注意到如果 $\mu_s$ 和 $x$ 是独立的，那么它们所构成的向量显然是服从二元高斯分布的。因为互相独立的高斯随机变量的线性组合也是高斯随机变量。但问题是 $\mu_s$ 和 $x$ 并不是互相独立的。这里采用一些技巧，将 $\mu_s$ 和 $x$ 做了一些分解。</p>
<p>我们知道高斯分布的随机变量是可以拆解成 均值 + 标准差×标准高斯分布 的随机变量。拆解完 $\mu_s$ 和 $x$ 后，再去验证它们的线性组合是否服从高斯分布。这样最终套用多元高斯分布的定义，得到 $\mu_s$ 和 $x$ 所构成的随机向量服从二元高斯分布。之后再套用引理，就可以得到作为后验分布的高斯分布的均值和方差这两个参数。</p>
<p><img src="image-20220810133913747.png" alt="image-20220810133913747" style="zoom:50%;"></p>
<p><img src="image-20220810133919283.png" alt="image-20220810133919283" style="zoom:50%;"></p>
<p>$\mathbb{E}[\mu_s]=\mathbb{E}[\mu_p]+\mathbb{E}[\sigma_p\delta]$</p>
<p>$\mu_p$ 是一个常数，对它求期望就是它本身</p>
<p>求 Cov[x, $\mu_s$] 时：</p>
<p>由第一行连等式可得 $\mathbb{E}[x]=\mathbb{E}[\mu_s]=\mu_p$</p>
<p>$\sigma_s$ 和 $\mu_p$ 是常数，$\epsilon$ 和 $\mu_s$ 相互独立。因此 $\sigma_s\epsilon$ 和 $\mu_s-\mu_p$ 相互独立，求期望时可以用乘号分开</p>
<p><img src="image-20220810133930543.png" alt="image-20220810133930543" style="zoom:50%;"></p>
<p>$\delta,\epsilon$ 是相互独立的正态分布，那么相加也是正态分布</p>
<p><img src="image-20220810133939420.png" alt="image-20220810133939420" style="zoom:50%;"></p>
<h4 id="一元高斯分布（带数据）"><a href="#一元高斯分布（带数据）" class="headerlink" title="一元高斯分布（带数据）"></a>一元高斯分布（带数据）</h4><p><img src="image-20220810133952879.png" alt="image-20220810133952879" style="zoom:50%;"></p>
<p>D 是观测到的数据，$\sigma^2=\tau^{-1}$</p>
<p>$p(\mu|\tau)=\mathcal{N}(\mu|\mu_0,(\lambda_0\tau)^{-1})$ 指的是 $\mu$ 服从均值为 $\mu_0$，方差为 $(\lambda_0\tau)^{-1}$ 的高斯分布</p>
<p>共轭先验：<a target="_blank" rel="noopener" href="https://www.cnblogs.com/simayuhe/p/5143538.html">https://www.cnblogs.com/simayuhe/p/5143538.html</a></p>
<p>用mean field，假设 $q(\mu,\tau)=q_\mu(\mu)q_\tau(\tau)$</p>
<p><img src="image-20220810134004804.png" alt="image-20220810134004804" style="zoom:50%;"></p>
<p><img src="image-20220810134009370.png" alt="image-20220810134009370" style="zoom:50%;"></p>
<p>对<img src="image-20220810134020690.png" alt="image-20220810134020690" style="zoom:33%;">进行配方，配成高斯核的形式</p>
<p><img src="image-20220810134030483.png" alt="image-20220810134030483" style="zoom:50%;"></p>
<p><img src="image-20220810134035800.png" alt="image-20220810134035800" style="zoom:50%;"></p>
<p><img src="image-20220810134041386.png" alt="image-20220810134041386" style="zoom:50%;"></p>
<p>配成gamma核的形式</p>
<p>$q^<em>_\mu(\mu)$ 和 $q^</em>_\tau(\tau)$ 是相互关联的。$q^<em>_\mu(\mu)$ 的variance中有关于 $\tau$ 的期望，在 $q^</em>_\tau(\tau)$ 的表达式中有关于 $\mu$ 的期望。互相dependent。</p>
<p>可以相互迭代地求解</p>
<p><img src="image-20220810134051087.png" alt="image-20220810134051087" style="zoom:50%;"></p>
<p><img src="image-20220810134056654.png" alt="image-20220810134056654" style="zoom:50%;"></p>
<p><img src="image-20220810134101314.png" alt="image-20220810134101314" style="zoom:50%;"></p>
<p>假设这些参数都为0，其实是一个improper prior</p>
<p><img src="image-20220810134109272.png" alt="image-20220810134109272" style="zoom:50%;"></p>
<p>用gamma分布的性质可知 $\mathbb{E}(\tau)=\frac{a_n}{b_n}$ ，再可以和 $\mathbb{E}(\mu)$ 建立联系</p>
<p><img src="image-20220810134117124.png" alt="image-20220810134117124" style="zoom:50%;"></p>
<p>得到 $\mathbb{E}[\tau]$ 后，其他参数都可以得到解析解</p>
<h4 id="分类分布和多项式分布"><a href="#分类分布和多项式分布" class="headerlink" title="分类分布和多项式分布"></a>分类分布和多项式分布</h4><p><img src="image-20220810134137514.png" alt="image-20220810134137514" style="zoom:50%;"></p>
<p><img src="image-20220810134141683.png" alt="image-20220810134141683" style="zoom:50%;"></p>
<p><img src="image-20220810134146192.png" alt="image-20220810134146192" style="zoom:50%;"></p>
<p>伯努利：一个球，allocate到一个bin的概率是p，allocate到另一个bin的概率是1-p</p>
<p>categorical distribution</p>
<p><img src="image-20220810134154132.png" alt="image-20220810134154132" style="zoom:50%;"></p>
<p>另一种coding的方法：</p>
<p><img src="image-20220810134203710.png" alt="image-20220810134203710" style="zoom:50%;"></p>
<p><img src="image-20220810134207923.png" alt="image-20220810134207923" style="zoom:50%;"></p>
<p><img src="image-20220810134212495.png" alt="image-20220810134212495" style="zoom:50%;"></p>
<p><img src="image-20220810134217078.png" alt="image-20220810134217078" style="zoom:50%;"></p>
<p>观测到 $x_1,x_2,…,x_n$。对于每个 $x_i$，都是 $K$ 维的向量</p>
<p>$\prod_{i=1}^n\prod_{k=1}^K\theta_k^{x_{ik}}=\prod_{k=1}^K\theta_k^{\sum_ix_{ik}}$。指对于第k个bin，看里面有多少个小球，记 $m_k$</p>
<h4 id="狄利克雷分布-Dirichlet"><a href="#狄利克雷分布-Dirichlet" class="headerlink" title="狄利克雷分布 Dirichlet"></a>狄利克雷分布 Dirichlet</h4><p><img src="image-20220810134230933.png" alt="image-20220810134230933" style="zoom:50%;"></p>
<p>$\theta$ 是随机变量，$\alpha$ 是参数</p>
<p>k=3时，由于<img src="image-20220810134242345.png" alt="image-20220810134242345" style="zoom:33%;">θ的取值只能在灰色的平面内</p>
<p><img src="image-20220810134257121.png" alt="image-20220810134257121" style="zoom:50%;"></p>
<p>$\alpha$ 取不同的值，$\theta$ 的behavior不同</p>
<p>$\alpha_1,\alpha_2,\alpha_3$ 都为1，均匀分布；$\alpha_1,\alpha_2,\alpha_3$ 都接近于0，分布会sparse，趋近于边、端点，尤其是端点，如图<img src="image-20220810134308354.png" alt="image-20220810134308354" style="zoom:33%;">；$\alpha_1,\alpha_2,\alpha_3$都很大，相反，如图<img src="image-20220810134319747.png" alt="image-20220810134319747" style="zoom:33%;">；$\alpha$ 有一个特别大的话，会concentrate到对应的 $\theta$</p>
<p><img src="image-20220810134342950.png" alt="image-20220810134342950" style="zoom:50%;"></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/49401976">https://zhuanlan.zhihu.com/p/49401976</a></p>
<p><img src="image-20221111232411646.png" alt="image-20221111232411646"></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://seline02.github.io">Seline</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://seline02.github.io/2022/08/10/%E5%8F%98%E5%88%86%E6%8E%A8%E6%96%AD/">https://seline02.github.io/2022/08/10/%E5%8F%98%E5%88%86%E6%8E%A8%E6%96%AD/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://seline02.github.io" target="_blank">Seline's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%8F%98%E5%88%86%E6%8E%A8%E6%96%AD/">变分推断</a><a class="post-meta__tags" href="/tags/%E5%85%B1%E8%BD%AD%E5%85%88%E9%AA%8C/">共轭先验</a></div><div class="post_share"><div class="social-share" data-image="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/08/13/pytorch%E7%AC%94%E8%AE%B0/"><img class="prev-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">pytorch笔记</div></div></a></div><div class="next-post pull-right"><a href="/2022/08/08/transformer%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"><img class="next-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">transformer论文笔记</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Seline</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">37</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">9</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%91%E4%BC%BC%E6%8E%A8%E6%96%AD"><span class="toc-number">1.</span> <span class="toc-text">近似推断</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B9%B3%E5%9D%87%E5%9C%BA%E6%8E%A8%E6%96%AD"><span class="toc-number">2.</span> <span class="toc-text">平均场推断</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%9F%E6%9C%9B%E6%8E%A8%E6%96%AD%E5%92%8C%E5%8F%98%E5%88%86%E6%8E%A8%E6%96%AD%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number">3.</span> <span class="toc-text">期望推断和变分推断的区别</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B1%E8%BD%AD%E5%85%88%E9%AA%8C"><span class="toc-number">4.</span> <span class="toc-text">共轭先验</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%80%E5%85%83%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83%EF%BC%88%E5%B8%A6%E6%95%B0%E6%8D%AE%EF%BC%89"><span class="toc-number">5.</span> <span class="toc-text">一元高斯分布（带数据）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E7%B1%BB%E5%88%86%E5%B8%83%E5%92%8C%E5%A4%9A%E9%A1%B9%E5%BC%8F%E5%88%86%E5%B8%83"><span class="toc-number">6.</span> <span class="toc-text">分类分布和多项式分布</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%8B%84%E5%88%A9%E5%85%8B%E9%9B%B7%E5%88%86%E5%B8%83-Dirichlet"><span class="toc-number">7.</span> <span class="toc-text">狄利克雷分布 Dirichlet</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/11/17/%E5%80%BC%E8%BF%AD%E4%BB%A3%E4%B8%8E%E7%AD%96%E7%95%A5%E8%BF%AD%E4%BB%A3/" title="西瓜书-强化学习"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="西瓜书-强化学习"/></a><div class="content"><a class="title" href="/2022/11/17/%E5%80%BC%E8%BF%AD%E4%BB%A3%E4%B8%8E%E7%AD%96%E7%95%A5%E8%BF%AD%E4%BB%A3/" title="西瓜书-强化学习">西瓜书-强化学习</a><time datetime="2022-11-17T15:58:45.000Z" title="发表于 2022-11-17 23:58:45">2022-11-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/11/08/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AC%94%E8%AE%B0/" title="分布式笔记"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="分布式笔记"/></a><div class="content"><a class="title" href="/2022/11/08/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AC%94%E8%AE%B0/" title="分布式笔记">分布式笔记</a><time datetime="2022-11-08T06:01:22.000Z" title="发表于 2022-11-08 14:01:22">2022-11-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/10/15/Acoustic-Feature/" title="Acoustic Feature"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Acoustic Feature"/></a><div class="content"><a class="title" href="/2022/10/15/Acoustic-Feature/" title="Acoustic Feature">Acoustic Feature</a><time datetime="2022-10-15T15:45:04.000Z" title="发表于 2022-10-15 23:45:04">2022-10-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/10/10/%E6%98%93%E6%96%B9%E8%BE%BE%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/" title="易方达项目笔记"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="易方达项目笔记"/></a><div class="content"><a class="title" href="/2022/10/10/%E6%98%93%E6%96%B9%E8%BE%BE%E9%A1%B9%E7%9B%AE%E7%AC%94%E8%AE%B0/" title="易方达项目笔记">易方达项目笔记</a><time datetime="2022-10-10T10:10:13.000Z" title="发表于 2022-10-10 18:10:13">2022-10-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/10/05/PyTorch%E7%AC%94%E8%AE%B0%EF%BC%88%E6%9D%82%EF%BC%89/" title="PyTorch笔记（杂）"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="PyTorch笔记（杂）"/></a><div class="content"><a class="title" href="/2022/10/05/PyTorch%E7%AC%94%E8%AE%B0%EF%BC%88%E6%9D%82%EF%BC%89/" title="PyTorch笔记（杂）">PyTorch笔记（杂）</a><time datetime="2022-10-05T08:44:29.000Z" title="发表于 2022-10-05 16:44:29">2022-10-05</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By Seline</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>