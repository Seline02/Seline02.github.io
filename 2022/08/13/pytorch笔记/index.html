<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>pytorch笔记 | Seline's blog</title><meta name="keywords" content="PyTorch"><meta name="author" content="Seline"><meta name="copyright" content="Seline"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="张量创建Tensor  torch.tensor小写的接受实际的数据 大写的接受数据的维度（2，3），也可现有数据（[2,3]）（少用）   未初始化 数据很不规则，有可能非常大或非常小，一定要覆盖掉    torch.normal传10个均值 10个方差 最后还要reshape torch.full([10], 0)生成长为10，全为0的tensor  scaler shape传一个[]  ar">
<meta property="og:type" content="article">
<meta property="og:title" content="pytorch笔记">
<meta property="og:url" content="https://seline02.github.io/2022/08/13/pytorch%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="Seline&#39;s blog">
<meta property="og:description" content="张量创建Tensor  torch.tensor小写的接受实际的数据 大写的接受数据的维度（2，3），也可现有数据（[2,3]）（少用）   未初始化 数据很不规则，有可能非常大或非常小，一定要覆盖掉    torch.normal传10个均值 10个方差 最后还要reshape torch.full([10], 0)生成长为10，全为0的tensor  scaler shape传一个[]  ar">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">
<meta property="article:published_time" content="2022-08-13T06:17:35.000Z">
<meta property="article:modified_time" content="2022-08-15T07:58:04.854Z">
<meta property="article:author" content="Seline">
<meta property="article:tag" content="PyTorch">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://seline02.github.io/2022/08/13/pytorch%E7%AC%94%E8%AE%B0/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'pytorch笔记',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-08-15 15:58:04'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.2.0"><link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">13</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><hr/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Seline's blog</a></span><div id="menus"><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">pytorch笔记</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-08-13T06:17:35.000Z" title="发表于 2022-08-13 14:17:35">2022-08-13</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-08-15T07:58:04.854Z" title="更新于 2022-08-15 15:58:04">2022-08-15</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="pytorch笔记"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h2 id="张量"><a href="#张量" class="headerlink" title="张量"></a>张量</h2><h3 id="创建Tensor"><a href="#创建Tensor" class="headerlink" title="创建Tensor"></a>创建Tensor</h3><p><img src="image-20220813143630114.png" alt="image-20220813143630114" style="zoom:50%;"></p>
<p><img src="image-20220813142012231.png" alt="image-20220813142012231" style="zoom:50%;"></p>
<p>torch.tensor小写的接受实际的数据 大写的接受数据的维度（2，3），也可现有数据（[2,3]）（少用）</p>
<p><img src="image-20220813142027481.png" alt="image-20220813142027481" style="zoom:50%;"></p>
<p><img src="image-20220813142039795.png" alt="image-20220813142039795" style="zoom:50%;"></p>
<p>未初始化 数据很不规则，有可能非常大或非常小，一定要覆盖掉</p>
<p><img src="image-20220813144109711.png" alt="image-20220813144109711" style="zoom:50%;"></p>
<p><img src="image-20220813144115496.png" alt="image-20220813144115496" style="zoom:50%;"></p>
<p><img src="image-20220813144120705.png" alt="image-20220813144120705" style="zoom:50%;"></p>
<p>torch.normal传10个均值 10个方差 最后还要reshape</p>
<p>torch.full([10], 0)生成长为10，全为0的tensor</p>
<p><img src="image-20220813144128423.png" alt="image-20220813144128423" style="zoom:50%;"></p>
<p>scaler shape传一个[]</p>
<p><img src="image-20220813144145874.png" alt="image-20220813144145874" style="zoom:50%;"></p>
<p>arange(0,10)生成[0,10)不包含末尾的等差数列，默认以1来递增</p>
<p>range在pytorch中不建议使用，用arange代替</p>
<p><img src="image-20220813145439485.png" alt="image-20220813145439485" style="zoom:50%;"></p>
<p>和arange不同，linspace/logspace中的step表示<strong>生成几个数字</strong>而不是步长</p>
<p><img src="image-20220813145714726.png" alt="image-20220813145714726" style="zoom:50%;"></p>
<p><img src="image-20220813145720609.png" alt="image-20220813145720609" style="zoom:50%;"></p>
<h3 id="索引与切片"><a href="#索引与切片" class="headerlink" title="索引与切片"></a>索引与切片</h3><p><strong>需要注意的是：索引出来的结果与原数据共享内存，修改一个，另一个会跟着修改。如果不想修改，可以考虑使用copy()等方法</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">x = torch.rand(<span class="number">4</span>,<span class="number">3</span>)</span><br><span class="line"><span class="comment"># 取第二列</span></span><br><span class="line"><span class="built_in">print</span>(x[:, <span class="number">1</span>]) </span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([-<span class="number">0.0720</span>,  <span class="number">0.0666</span>,  <span class="number">1.0336</span>, -<span class="number">0.6965</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">y = x[<span class="number">0</span>,:]</span><br><span class="line">y += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line"><span class="built_in">print</span>(x[<span class="number">0</span>, :]) <span class="comment"># 源tensor也被改了了</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([<span class="number">3.7311</span>, <span class="number">0.9280</span>, <span class="number">1.2497</span>])</span><br><span class="line">tensor([<span class="number">3.7311</span>, <span class="number">0.9280</span>, <span class="number">1.2497</span>])</span><br></pre></td></tr></table></figure>
<p><img src="image-20220813150644560.png" alt="image-20220813150644560" style="zoom:50%;"></p>
<p>a[0,0,2,4]返回的是一个标量</p>
<p><img src="image-20220813151109470.png" alt="image-20220813151109470" style="zoom:50%;"></p>
<p><img src="image-20220813151210354.png" alt="image-20220813151210354" style="zoom:50%;"></p>
<p><img src="image-20220813151303893.png" alt="image-20220813151303893" style="zoom:50%;"></p>
<p>index_select的第一个参数是要采集的维度</p>
<p><img src="image-20220813151630940.png" alt="image-20220813151630940" style="zoom:50%;"></p>
<p><img src="image-20220813151746140.png" alt="image-20220813151746140" style="zoom:50%;"></p>
<p>…表示任意多的维度</p>
<p>a[0,…] = a[0]</p>
<p><img src="image-20220813152539157.png" alt="image-20220813152539157" style="zoom:50%;"></p>
<p>掩码用的不多，因为它会默认将数据打平</p>
<p>x.ge(0.5) ：ge指great equal，大于等于）0.5的位置置1</p>
<p><img src="image-20220813152852148.png" alt="image-20220813152852148" style="zoom:50%;"></p>
<p>take是先把所有的打平，再取打平后对应的元素</p>
<h3 id="维度变换"><a href="#维度变换" class="headerlink" title="维度变换"></a>维度变换</h3><p><img src="image-20220813153107459.png" alt="image-20220813153107459" style="zoom:50%;"></p>
<p><img src="image-20220813153242361.png" alt="image-20220813153242361" style="zoom:50%;"></p>
<p>张量的维度变换常见的方法有<code>torch.view()</code>和<code>torch.reshape()</code>，下面我们将介绍第一中方法<code>torch.view()</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">y = x.view(<span class="number">16</span>)</span><br><span class="line">z = x.view(-<span class="number">1</span>, <span class="number">8</span>) <span class="comment"># -1是指这一维的维数由其他维度决定</span></span><br><span class="line"><span class="built_in">print</span>(x.size(), y.size(), z.size())</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([<span class="number">4</span>, <span class="number">4</span>]) torch.Size([<span class="number">16</span>]) torch.Size([<span class="number">2</span>, <span class="number">8</span>])</span><br></pre></td></tr></table></figure>
<p>注: <code>torch.view()</code> 返回的新<code>tensor</code>与源<code>tensor</code><strong>共享内存</strong>(其实是同一个<code>tensor</code>)，更改其中的一个，另外一个也会跟着改变。(顾名思义，view()仅仅是改变了对这个张量的观察角度)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">x += <span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="built_in">print</span>(y) <span class="comment"># 也加了了1</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ <span class="number">1.3019</span>,  <span class="number">0.3762</span>,  <span class="number">1.2397</span>,  <span class="number">1.3998</span>],</span><br><span class="line">        [ <span class="number">0.6891</span>,  <span class="number">1.3651</span>,  <span class="number">1.1891</span>, -<span class="number">0.6744</span>],</span><br><span class="line">        [ <span class="number">0.3490</span>,  <span class="number">1.8377</span>,  <span class="number">1.6456</span>,  <span class="number">0.8403</span>],</span><br><span class="line">        [-<span class="number">0.8259</span>,  <span class="number">2.5454</span>,  <span class="number">1.2474</span>,  <span class="number">0.7884</span>]])</span><br><span class="line">tensor([ <span class="number">1.3019</span>,  <span class="number">0.3762</span>,  <span class="number">1.2397</span>,  <span class="number">1.3998</span>,  <span class="number">0.6891</span>,  <span class="number">1.3651</span>,  <span class="number">1.1891</span>, -<span class="number">0.6744</span>,</span><br><span class="line">         <span class="number">0.3490</span>,  <span class="number">1.8377</span>,  <span class="number">1.6456</span>,  <span class="number">0.8403</span>, -<span class="number">0.8259</span>,  <span class="number">2.5454</span>,  <span class="number">1.2474</span>,  <span class="number">0.7884</span>])</span><br></pre></td></tr></table></figure>
<p>上面我们说过torch.view()会改变原始张量，但是很多情况下，我们希望原始张量和变换后的张量互相不影响。为为了使创建的张量和原始张量不共享内存，我们需要使用第二种方法<code>torch.reshape()</code>， 同样可以改变张量的形状，但是此函数并不能保证返回的是其拷贝值，所以官方<strong>不推荐使用</strong>。推荐的方法是我们先用 <code>clone()</code> 创造一个<strong>张量副本</strong>然后再使用 <code>torch.view()</code>进行函数维度变换 。</p>
<p>注：使用 <code>clone()</code> 还有一个好处是会被记录在计算图中，即梯度回传到副本时也会传到源 Tensor 。</p>
<p><img src="image-20220813153940238.png" alt="image-20220813153940238" style="zoom:50%;"></p>
<p><img src="image-20220813154507078.png" alt="image-20220813154507078" style="zoom:50%;"></p>
<p>unsqueeze第一个参数：在哪一维插入新的一维</p>
<p>原来一共4维，第一个参数取值范围是[-5,5)。参数是0~4表示在第k维之前插入一个新的维度；参数是-5 ~ -1表示在第k维之后插入</p>
<p><img src="image-20220813154703233.png" alt="image-20220813154703233" style="zoom:50%;"></p>
<p>原先的shape是[2]</p>
<p><img src="image-20220813154923635.png" alt="image-20220813154923635" style="zoom:50%;"></p>
<p>在b的后面插入2维，在前面插入1维</p>
<p><img src="image-20220813155456767.png" alt="image-20220813155456767" style="zoom:50%;"></p>
<p><img src="image-20220813155853943.png" alt="image-20220813155853943" style="zoom:50%;"></p>
<p>expand实际上并没有增加数据，推荐这种操作，节约内存</p>
<p>repeat实实在在地增加了数据，1变到4时会把数据都拷贝一遍</p>
<p><img src="image-20220813160144046.png" alt="image-20220813160144046" style="zoom:50%;"></p>
<p>仅仅原来维度上是1的能够复制</p>
<p>-1表示保持原来的维度不变</p>
<p><img src="image-20220813160420473.png" alt="image-20220813160420473" style="zoom:50%;"></p>
<p>repeat的参数和expand的参数不一样，每个数表示对应维度要<strong>复制的次数</strong></p>
<p><img src="image-20220813160525001.png" alt="image-20220813160525001" style="zoom:50%;"></p>
<p>.t方法只适用于二维的矩阵</p>
<p><img src="image-20220813160734115.png" alt="image-20220813160734115" style="zoom:50%;"></p>
<p><img src="image-20220813161212603.png" alt="image-20220813161212603" style="zoom:50%;"></p>
<p>transpose接受要交换的两个维度</p>
<p>本来是一行行存储，维度交换后存储顺序会改变</p>
<p><code>contiguous()</code>函数使其变成连续存储</p>
<p>用all函数返回每一项是否都一样，返回0，说明a和a1有不一样的</p>
<p>view会导致维度顺序关系变模糊，所以需要人为跟踪</p>
<p><img src="image-20220813162009353.png" alt="image-20220813162009353" style="zoom:50%;"></p>
<p>用permute如果遇到contiguous的错误，仍需要用contiguous函数</p>
<h3 id="拼接与拆分"><a href="#拼接与拆分" class="headerlink" title="拼接与拆分"></a>拼接与拆分</h3><p><img src="image-20220813162158992.png" alt="image-20220813162158992" style="zoom:50%;"></p>
<p>split按长度进行拆分，chunk按数量进行拆分</p>
<p><img src="image-20220813162447003.png" alt="image-20220813162447003" style="zoom:50%;"></p>
<p><img src="image-20220813162600869.png" alt="image-20220813162600869" style="zoom:50%;"></p>
<p><img src="image-20220813162818291.png" alt="image-20220813162818291" style="zoom:50%;"></p>
<p>a1: (4,3,16,32)  a2: (4,3,16,32)  实际可以理解为a1保存了图片的上半部分，a2保存了图片的下半部分，可以上下拼起来 </p>
<p><img src="image-20220813163255922.png" alt="image-20220813163255922" style="zoom:50%;"></p>
<p>stack会创建一个新的维度</p>
<p><img src="image-20220813163342138.png" alt="image-20220813163342138" style="zoom:50%;"></p>
<p><img src="image-20220813164221049.png" alt="image-20220813164221049" style="zoom:50%;"></p>
<p>split可以接受长度的参数 <code>c.split(1, dim=0)</code> 表示拆分成每个单元的长度是1</p>
<p>长度不一样的话，也可以接受一个list，<code>c.split([1, 1], dim=0)</code> 表示拆成两个单元，长度分别为1和1</p>
<p><img src="image-20220813164358265.png" alt="image-20220813164358265" style="zoom:50%;"></p>
<p>chunk按数量拆分</p>
<h3 id="数学运算"><a href="#数学运算" class="headerlink" title="数学运算"></a>数学运算</h3><p><img src="image-20220813164436013.png" alt="image-20220813164436013" style="zoom:50%;"></p>
<p><img src="image-20220813164554822.png" alt="image-20220813164554822" style="zoom:50%;"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="comment"># 方式1</span></span><br><span class="line">y = torch.rand(<span class="number">4</span>, <span class="number">3</span>) </span><br><span class="line"><span class="built_in">print</span>(x + y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方式2</span></span><br><span class="line"><span class="built_in">print</span>(torch.add(x, y))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 方式3 in-place，原值修改</span></span><br><span class="line">y.add_(x) </span><br><span class="line"><span class="built_in">print</span>(y)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ <span class="number">2.8977</span>,  <span class="number">0.6581</span>,  <span class="number">0.5856</span>],</span><br><span class="line">        [-<span class="number">1.3604</span>,  <span class="number">0.1656</span>, -<span class="number">0.0823</span>],</span><br><span class="line">        [ <span class="number">2.1387</span>,  <span class="number">1.7959</span>,  <span class="number">1.5275</span>],</span><br><span class="line">        [ <span class="number">2.2427</span>, -<span class="number">0.3100</span>, -<span class="number">0.4826</span>]])</span><br><span class="line">tensor([[ <span class="number">2.8977</span>,  <span class="number">0.6581</span>,  <span class="number">0.5856</span>],</span><br><span class="line">        [-<span class="number">1.3604</span>,  <span class="number">0.1656</span>, -<span class="number">0.0823</span>],</span><br><span class="line">        [ <span class="number">2.1387</span>,  <span class="number">1.7959</span>,  <span class="number">1.5275</span>],</span><br><span class="line">        [ <span class="number">2.2427</span>, -<span class="number">0.3100</span>, -<span class="number">0.4826</span>]])</span><br><span class="line">tensor([[ <span class="number">2.8977</span>,  <span class="number">0.6581</span>,  <span class="number">0.5856</span>],</span><br><span class="line">        [-<span class="number">1.3604</span>,  <span class="number">0.1656</span>, -<span class="number">0.0823</span>],</span><br><span class="line">        [ <span class="number">2.1387</span>,  <span class="number">1.7959</span>,  <span class="number">1.5275</span>],</span><br><span class="line">        [ <span class="number">2.2427</span>, -<span class="number">0.3100</span>, -<span class="number">0.4826</span>]])</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="image-20220813164923013.png" alt="image-20220813164923013" style="zoom:50%;"></p>
<p>* 是element-wise相乘，即对应位置元素相乘</p>
<p>@是matmul的重载</p>
<p><img src="image-20220813172303564.png" alt="image-20220813172303564" style="zoom:50%;"></p>
<p>pytorch中w的第一个维度是channel_out即输出的维度，第二个维度是channel_in即输入的维度</p>
<p>对于二维以上的tensor相乘：</p>
<p><img src="image-20220813172515341.png" alt="image-20220813172515341" style="zoom:50%;"></p>
<p><code>mm</code>只限于2d的矩阵相乘</p>
<p><code>matmul</code>取最后两维进行运算</p>
<p>其实就是支持多个矩阵并行相乘</p>
<p>(4,3,28,64)  (4,1,64,32) 相乘之前会先进行broadcast</p>
<p><img src="image-20220813172940147.png" alt="image-20220813172940147" style="zoom:50%;"></p>
<p><img src="image-20220813173028086.png" alt="image-20220813173028086" style="zoom:50%;"></p>
<p><img src="image-20220813173443526.png" alt="image-20220813173443526" style="zoom:50%;"></p>
<p><code>a.trunc()</code> 裁成了整数部分，<code>a.frac()</code>裁成了小数部分</p>
<p><img src="image-20220813174207685.png" alt="image-20220813174207685" style="zoom:50%;"></p>
<p>clamp用于梯度的裁剪</p>
<p>当在网络中出现training不稳定的情况，打印一下梯度的模 <code>w.grad.norm(2)</code>。小于10比较合适</p>
<p><code>grad.clamp(10)</code>小于10的都要变成10</p>
<p>对w限幅是weight clipping；对w.grad限幅是gradient clipping</p>
<p>传一个参数是限制了最小值；传两个参数是限制了最小和最大值</p>
<h3 id="统计属性"><a href="#统计属性" class="headerlink" title="统计属性"></a>统计属性</h3><p><img src="image-20220813174308746.png" alt="image-20220813174308746" style="zoom:30%;"></p>
<p><img src="image-20220813174429402.png" alt="image-20220813174429402" style="zoom:30%;"></p>
<p><img src="image-20220813174441562.png" alt="image-20220813174441562" style="zoom:50%;"></p>
<p><img src="image-20220813180103505.png" alt="image-20220813180103505" style="zoom:50%;"></p>
<p><img src="image-20220813180457598.png" alt="image-20220813180457598" style="zoom:50%;"></p>
<p><code>a.prod()</code>是product，累乘</p>
<p><img src="image-20220813180819499.png" alt="image-20220813180819499" style="zoom:50%;"></p>
<p><code>a.argmax()</code>如果不给定参数，会把数据打平，再给出位置</p>
<p><img src="image-20220813181901965.png" alt="image-20220813181901965" style="zoom:50%;"></p>
<p>如果从[4,10]经过max或argmax得到[4]，但仍想得到[4,1]这样的二维矩阵，即和原来的dimention相同，加 <code>keepdim=True</code></p>
<p><img src="image-20220813182613125.png" alt="image-20220813182613125" style="zoom:50%;"></p>
<p>topk中设置<code>largest=False</code>就是选最小的那几个</p>
<p>kthvalue是选第k小</p>
<p><img src="image-20220813183246485.png" alt="image-20220813183246485" style="zoom:50%;"></p>
<p>返回的是byteTensor，dtype是unit8</p>
<p>比较是element-wise</p>
<p>如果要返回的是true/false，用<code>torch.equal(a,b)</code></p>
<h3 id="高阶操作"><a href="#高阶操作" class="headerlink" title="高阶操作"></a>高阶操作</h3><p><img src="image-20220813183314425.png" alt="image-20220813183314425" style="zoom:50%;"></p>
<p><img src="image-20220813183649239.png" alt="image-20220813183649239" style="zoom:50%;"></p>
<p>创建一个tensor，它的源头是x或y</p>
<p><img src="image-20220813183751198.png" alt="image-20220813183751198" style="zoom:50%;"></p>
<p>tensor的值大于0.5，对应位置取a对应的值，否则取b对应的</p>
<p><img src="image-20220813194647607.png" alt="image-20220813194647607" style="zoom:50%;"></p>
<p>gather是一个查表的操作，input是一张表 [dog; cat; whale]，index是索引 [1, 0, 1, 2]</p>
<p>索引1查到cat，0查到dog，1查到cat，2查到whale</p>
<p><img src="image-20220813194952233.png" alt="image-20220813194952233" style="zoom:50%;"></p>
<p>可以把0编号编到100，1编到101… 那么[100; 101; …109]就是一张表</p>
<p><img src="image-20220813195249743.png" alt="image-20220813195249743" style="zoom:50%;"></p>
<p>可以做成映射</p>
<h2 id="自动求导"><a href="#自动求导" class="headerlink" title="自动求导"></a>自动求导</h2><h3 id="激活函数与Loss的梯度"><a href="#激活函数与Loss的梯度" class="headerlink" title="激活函数与Loss的梯度"></a>激活函数与Loss的梯度</h3><p><img src="image-20220813202857889.png" alt="image-20220813202857889" style="zoom:50%;"></p>
<p><img src="image-20220813203153126.png" alt="image-20220813203153126" style="zoom:50%;"></p>
<p>Tanh在rnn中用的比较多</p>
<p><img src="image-20220813203237105.png" alt="image-20220813203237105" style="zoom:50%;"></p>
<p><img src="image-20220813203249641.png" alt="image-20220813203249641" style="zoom:50%;"></p>
<p><img src="image-20220813203334864.png" alt="image-20220813203334864" style="zoom:50%;"></p>
<p><img src="image-20220813203340945.png" alt="image-20220813203340945" style="zoom:50%;"></p>
<p><img src="image-20220813203412499.png" alt="image-20220813203412499" style="zoom:50%;"></p>
<p><img src="image-20220813203606468.png" alt="image-20220813203606468" style="zoom:50%;"></p>
<p><img src="image-20220813203839334.png" alt="image-20220813203839334" style="zoom:50%;"></p>
<p>要注意是否有开根号</p>
<p>mse是不开根号的，如果用L2-norm来写就是 <code>torch.norm(y-pred, 2).pow(2)</code></p>
<p><img src="image-20220814130111561.png" alt="image-20220814130111561" style="zoom:50%;"></p>
<p><img src="image-20220814130249972.png" alt="image-20220814130249972" style="zoom:50%;"></p>
<p>relu一定程度上解决了sigmoid梯度弥散的情况</p>
<p>且梯度为1，串行传播，不会出现倍增、备减的情况</p>
<p><img src="image-20220814130406440.png" alt="image-20220814130406440" style="zoom:50%;"></p>
<p><img src="image-20220814130437209.png" alt="image-20220814130437209" style="zoom:50%;"></p>
<p><img src="image-20220814130543659.png" alt="image-20220814130543659" style="zoom:50%;"></p>
<p>SELU是两个函数的合并，使得曲线光滑</p>
<p><img src="image-20220814130605153.png" alt="image-20220814130605153" style="zoom:50%;"></p>
<p>也是一个平滑的版本</p>
<p><img src="image-20220813212920728.png" alt="image-20220813212920728" style="zoom:50%;"></p>
<p><code>w.requires_grad_()</code>后因为图没有更新（图是计算一步，更新一步的） 所以要重新求mse，才能再求梯度</p>
<p>也可以在初始化时就设置为要求梯度w=torch.tensor([1], requires_grad=True)</p>
<p><img src="image-20220813212931405.png" alt="image-20220813212931405" style="zoom:50%;"></p>
<p>可以用<code>torch.autograd.grad</code>求梯度，会返回一个list</p>
<p>也可以直接在loss节点上调用backward，但后一种不会直接返回梯度信息，即不会返回list之类的，会赋在每一个变量上，用w.grad看</p>
<p><img src="image-20220813212939861.png" alt="image-20220813212939861" style="zoom:50%;"></p>
<p>softmax:</p>
<p><img src="image-20220813212952044.png" alt="image-20220813212952044" style="zoom:50%;"></p>
<p><img src="image-20220813212956743.png" alt="image-20220813212956743" style="zoom:50%;"></p>
<p><img src="image-20220813213002092.png" alt="image-20220813213002092" style="zoom:50%;"></p>
<p><img src="image-20220813213008464.png" alt="image-20220813213008464" style="zoom:50%;"></p>
<p>dim=…[batch, feature] 希望在feature维度上做softmax操作，要设置 <code>dim=0</code></p>
<p>使用了一次<code>p.backward()</code>后，图的信息会被清除掉，再调用一次会报错</p>
<p>设置retain_graph=True后图不会被清除，即<code>p.backward(retain_graph=True)</code>，调用了backward()后还可以再调用backward()</p>
<p><code>torch.autograd.grad()</code>的第一个参数必须是一个标量，如p[1],p[2]</p>
<p>i 和 j 相等时，梯度是正的，其他是负的</p>
<h3 id="2D函数优化实例"><a href="#2D函数优化实例" class="headerlink" title="2D函数优化实例"></a>2D函数优化实例</h3><p><img src="image-20220814102542178.png" alt="image-20220814102542178" style="zoom:50%;"></p>
<p><img src="image-20220814122226447.png" alt="image-20220814122226447" style="zoom:50%;"></p>
<p><img src="image-20220814122508477.png" alt="image-20220814122508477" style="zoom:50%;"></p>
<p><img src="image-20220813213017927.png" alt="image-20220813213017927" style="zoom:50%;"></p>
<p>调用<code>optimizer = torch.optim.Adam([x], lr=1e-3)</code>和<code>optimizer.step()</code>会自动地更新 $x^{‘}=x-0.001\nabla x,y^{‘}=y-0.001\nabla y$</p>
<h2 id="熵，交叉熵"><a href="#熵，交叉熵" class="headerlink" title="熵，交叉熵"></a>熵，交叉熵</h2><p><img src="image-20220814124139336.png" alt="image-20220814124139336" style="zoom:50%;"></p>
<p>cross entropy一开始梯度信息大，但MSE梯度求导起来更简单</p>
<p><img src="image-20220814124253676.png" alt="image-20220814124253676" style="zoom:50%;"></p>
<p>softmax和cross entropy分开的话会出现数据不稳定的情况，因此不建议自己分开处理</p>
<p><img src="image-20220814124556776.png" alt="image-20220814124556776" style="zoom:50%;"></p>
<p>pytorch中的cross_entropy已经把softmax和log打包在一起了，因此必须传入logits</p>
<p>如果要自己计算，用nll_loss，但传入的必须是经过softmax和log的</p>
<h2 id="多分类问题实战"><a href="#多分类问题实战" class="headerlink" title="多分类问题实战"></a>多分类问题实战</h2><p><img src="image-20220814124810934.png" alt="image-20220814124810934" style="zoom:50%;"></p>
<p><img src="image-20220814125121962.png" alt="image-20220814125121962" style="zoom:50%;"></p>
<p>注意w是输入的维度写在后，输出的维度写在前</p>
<p>一般没有经过激活函数的叫做logits</p>
<p><img src="image-20220814125448553.png" alt="image-20220814125448553" style="zoom:50%;"></p>
<p><img src="image-20220814125859683.png" alt="image-20220814125859683" style="zoom:50%;"></p>
<p>训练时遇到梯度为0时除了可能learning rate过大，还可能是初始化的问题，可以用<code>torch.nn.init.kaiming_normal_(w1)</code></p>
<h2 id="激活函数与GPU加速"><a href="#激活函数与GPU加速" class="headerlink" title="激活函数与GPU加速"></a>激活函数与GPU加速</h2><p><img src="image-20220814131335585.png" alt="image-20220814131335585" style="zoom:50%;"></p>
<p>data.to(device) 搬到gpu上</p>
<p>loss层、data、module都搬到gpu上。可以用<code>.to(device)</code>（新版本方法）或<code>.cuda()</code>（老版本方法，只能搬到GPU上）</p>
<p>如果是搬模块，返回的还是原来，原地更新（inplace）；但是data（tensor）不一样，返回的东西是完全不同的</p>
<h2 id="MNIST测试"><a href="#MNIST测试" class="headerlink" title="MNIST测试"></a>MNIST测试</h2><p><img src="image-20220814132133905.png" alt="image-20220814132133905" style="zoom:50%;"></p>
<p><img src="image-20220814132640985.png" alt="image-20220814132640985" style="zoom:50%;"></p>
<p>[4, 10]，要对10那个维度做softmax，因此<code>dim=1</code></p>
<p><img src="image-20220814132741792.png" alt="image-20220814132741792" style="zoom:50%;"></p>
<p><img src="image-20220814132834945.png" alt="image-20220814132834945" style="zoom:50%;"></p>
<h2 id="Visdom可视化"><a href="#Visdom可视化" class="headerlink" title="Visdom可视化"></a>Visdom可视化</h2><p><img src="image-20220814133425476.png" alt="image-20220814133425476" style="zoom:50%;"></p>
<p>pytorch是动态图</p>
<p><img src="image-20220814134104810.png" alt="image-20220814134104810" style="zoom:50%;"></p>
<ul>
<li><p>建立一个SummaryWriter的实例</p>
</li>
<li><p>比如可以监听一个数据<code>dummy_s1[0]</code>，n_iter是迭代的次数</p>
</li>
<li><p>问题是tensorboard只能抽取numpy的数据。因此要先将tensor转化到cpu上，再转化成numpy数据</p>
</li>
</ul>
<p><img src="image-20220814134150404.png" alt="image-20220814134150404" style="zoom:50%;"></p>
<p>visdom可以直接接受image类的tensor，转化成numpy的过程自动帮忙做好了。但是对于直线，只能接受numpy类型数据</p>
<p><img src="image-20220814134402597.png" alt="image-20220814134402597" style="zoom:50%;"></p>
<p><img src="image-20220814134523314.png" alt="image-20220814134523314" style="zoom:50%;"></p>
<ul>
<li><p>visdom本质是一个web服务器，向web服务器丢数据，就会帮你渲染到网页上去</p>
</li>
<li><p>要确保程序运行前就开启了visdom</p>
</li>
</ul>
<p><img src="image-20220814134743346.png" alt="image-20220814134743346" style="zoom:50%;"></p>
<p>如果遇到错误，卸载，从官网重新安装</p>
<p><img src="image-20220814135014154.png" alt="image-20220814135014154" style="zoom:50%;"></p>
<p>打开</p>
<p><img src="image-20220814140246216.png" alt="image-20220814140246216" style="zoom:50%;"></p>
<ul>
<li><p>常见的功能：画一条曲线（acc/loss）</p>
</li>
<li><p>创建Visdom实例——创建一条直线——把最新数据添加到直线上</p>
</li>
<li><p>创建直线时，传入的第一个参数是Y，第二个参数是X</p>
</li>
<li><p>visdom每个大的窗口叫做environment，可以理解为一个工程，不指定的话，默认是main这个大的窗口</p>
</li>
<li>用<code>win=&#39;train_loss&#39;</code>指定小窗口，train_loss是它的ID。如果不存在，会自动创建</li>
<li>可以给定额外的信息，比如通过<code>opts=dict(title=&#39;train loss&#39;)</code>把窗口的名字命名为train loss，方便识别</li>
<li>通过第三行的创建后，只有1个点(0,0)</li>
<li><code>[global_step]</code> 是x坐标，代表时间戳；<code>[loss.item()]</code>转化成numpy类型数据才能传给直线；<code>update=&#39;append&#39;</code>指将新点添加到旧点的后面，否则会把之前的都覆盖掉</li>
</ul>
<p><img src="image-20220814140327288.png" alt="image-20220814140327288" style="zoom:50%;"></p>
<p><img src="image-20220814140455339.png" alt="image-20220814140455339" style="zoom:50%;"></p>
<ul>
<li>multi-traces 多条曲线</li>
<li><code>legend=[&#39;loss&#39;, &#39;acc.&#39;]</code>代表y1和y2的label</li>
</ul>
<p><img src="image-20220814140517831.png" alt="image-20220814140517831" style="zoom:50%;"></p>
<p>数据范围不一样，看上去就不方便</p>
<p><img src="image-20220814140727528.png" alt="image-20220814140727528" style="zoom:50%;"></p>
<ul>
<li>visdom也提供可视化的功能</li>
<li>如果用tensorboard，必须要通过<code>.cpu().numpy()</code>转化成numpy格式的数据再传进去，但是visdom可以直接使用tensor</li>
</ul>
<p><img src="image-20220814140747231.png" alt="image-20220814140747231" style="zoom:50%;"></p>
<h2 id="过拟合-amp-欠拟合"><a href="#过拟合-amp-欠拟合" class="headerlink" title="过拟合&amp;欠拟合"></a>过拟合&amp;欠拟合</h2><p><img src="image-20220814141148885.png" alt="image-20220814141148885" style="zoom:50%;"></p>
<p><img src="image-20220814141240860.png" alt="image-20220814141240860" style="zoom:50%;"></p>
<p><img src="image-20220814141405738.png" alt="image-20220814141405738" style="zoom:50%;"></p>
<p><img src="image-20220814141456987.png" alt="image-20220814141456987" style="zoom:50%;"></p>
<p>次方增加，模型的表达能力变强</p>
<p><img src="image-20220814141542408.png" alt="image-20220814141542408" style="zoom:33%;"></p>
<p><img src="image-20220814141603169.png" alt="image-20220814141603169" style="zoom:33%;"></p>
<p><img src="image-20220814141702697.png" alt="image-20220814141702697" style="zoom:33%;"></p>
<h2 id="Train-Val-Test划分"><a href="#Train-Val-Test划分" class="headerlink" title="Train-Val-Test划分"></a>Train-Val-Test划分</h2><p><img src="image-20220814141752618.png" alt="image-20220814141752618" style="zoom:50%;"></p>
<p><img src="image-20220814141850138.png" alt="image-20220814141850138" style="zoom:50%;"></p>
<p>val set用来选择参数，test set不可以</p>
<p><img src="image-20220814142113903.png" alt="image-20220814142113903" style="zoom:50%;"></p>
<p><img src="image-20220814142311039.png" alt="image-20220814142311039" style="zoom:50%;"></p>
<p><img src="image-20220814142320415.png" alt="image-20220814142320415" style="zoom:50%;"></p>
<h2 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h2><p><img src="image-20220814143846292.png" alt="image-20220814143846292" style="zoom:50%;"></p>
<p><img src="image-20220814143948528.png" alt="image-20220814143948528" style="zoom:50%;"></p>
<p><img src="image-20220814144347491.png" alt="image-20220814144347491" style="zoom:50%;"></p>
<p>regularization后可能退化成更小次方的表达式</p>
<p><img src="image-20220814144418481.png" alt="image-20220814144418481" style="zoom:50%;"></p>
<p><img src="image-20220814144434329.png" alt="image-20220814144434329" style="zoom:50%;"></p>
<p>$\lambda$ 是超参数，需要人为调整</p>
<p><img src="image-20220814144721297.png" alt="image-20220814144721297" style="zoom:50%;"></p>
<ul>
<li><p>设置<code>weight_decay=0.01</code>即设置 $\lambda=0.01$ </p>
</li>
<li><p>但如果没有overfitting，会导致网络的性能急剧下降</p>
</li>
</ul>
<p><img src="image-20220814144920287.png" alt="image-20220814144920287" style="zoom:50%;"></p>
<ul>
<li><p>1范数在pytorch中没有较好的支持，因此要手动地对所有参数进行迭代加到regularization_loss中</p>
</li>
<li><p><code>loss = classify_loss + 0.01 * regularization_loss</code></p>
</li>
</ul>
<h2 id="动量与学习率衰减"><a href="#动量与学习率衰减" class="headerlink" title="动量与学习率衰减"></a>动量与学习率衰减</h2><p><img src="image-20220814150517788.png" alt="image-20220814150517788" style="zoom:50%;"></p>
<p><img src="image-20220814150746425.png" alt="image-20220814150746425" style="zoom:50%;"></p>
<p><img src="image-20220814150827207.png" alt="image-20220814150827207" style="zoom:50%;"></p>
<p>no momentum没有考虑历史的效应，在局部极小值上就停止下来</p>
<p><img src="image-20220814151007211.png" alt="image-20220814151007211" style="zoom:50%;"></p>
<p>从局部极小值冲出来了</p>
<p><img src="image-20220814151130994.png" alt="image-20220814151130994" style="zoom:50%;"></p>
<p>Adam没有momentum参数，因为内置了momentum的机制</p>
<p>常见的momentum：0.9</p>
<p><img src="image-20220814151228947.png" alt="image-20220814151228947" style="zoom:50%;"></p>
<p><img src="image-20220814151240069.png" alt="image-20220814151240069" style="zoom:50%;"></p>
<p>lr太大可能越来越远，或者不收敛；lr太小更新慢</p>
<p><img src="image-20220814151420153.png" alt="image-20220814151420153" style="zoom:50%;"></p>
<p>前期大一点，更新快一点，后面慢一点</p>
<p><img src="image-20220814151436248.png" alt="image-20220814151436248" style="zoom:50%;"></p>
<p>两种learning rate decay的方法：</p>
<p><img src="image-20220814152120148.png" alt="image-20220814152120148" style="zoom:50%;"></p>
<ul>
<li><p>loss下降到一定程度，就不动了</p>
</li>
<li><p>Plateau：高原，即到达了平坦的地方，需要适当减小learning rate</p>
</li>
<li><p>目标是要减小loss，因此设置参数<code>&#39;min&#39;</code></p>
</li>
<li><p>耐心值 patience，若等于10，连续调用10次loss都没有减小，就会减小learning rate</p>
</li>
<li>有一个减小的因子，每次乘这个因子</li>
</ul>
<p><img src="image-20220814152349460.png" alt="image-20220814152349460" style="zoom:50%;"></p>
<ul>
<li><p>每多少个epoch把learning rate步进为原来的多少（gamma）</p>
</li>
<li><p>一般把<code>step_size</code>设置为1k或者10k等</p>
</li>
</ul>
<h2 id="Early-stopping，dropout"><a href="#Early-stopping，dropout" class="headerlink" title="Early stopping，dropout"></a>Early stopping，dropout</h2><p><img src="image-20220814152441844.png" alt="image-20220814152441844" style="zoom:50%;"></p>
<p><img src="image-20220814152624777.png" alt="image-20220814152624777" style="zoom:50%;"></p>
<p><img src="image-20220814152736167.png" alt="image-20220814152736167" style="zoom:50%;"></p>
<ul>
<li>在validation曲线的最高值stop，依赖于经验值、预估值</li>
</ul>
<p><img src="image-20220814153150441.png" alt="image-20220814153150441" style="zoom:50%;"></p>
<ul>
<li><p>dropout使connect的数量少一点</p>
</li>
<li><p>每一个连接有一定概率被断掉</p>
</li>
</ul>
<p><img src="image-20220814153200173.png" alt="image-20220814153200173" style="zoom:50%;"></p>
<p><img src="image-20220814153504539.png" alt="image-20220814153504539" style="zoom:50%;"></p>
<ul>
<li><p>加Dropout层</p>
</li>
<li><p>并不是每一层中间有可能断掉，而是层与层之间，输出与输入之间有可能断掉，而不是直连</p>
</li>
</ul>
<p><img src="image-20220814153544015.png" alt="image-20220814153544015" style="zoom:50%;"></p>
<p>pytorch和tensorflow之间的dropout参数有区别</p>
<p><img src="image-20220814154948721.png" alt="image-20220814154948721" style="zoom:50%;"></p>
<p>test时要通过<code>net_dropped_eval()</code>切换行为，用上所有连接</p>
<p><img src="image-20220814155157239.png" alt="image-20220814155157239" style="zoom:50%;"></p>
<ul>
<li><p>stochastic意思是随机，但其实不是随机</p>
</li>
<li><p>符合一个分布 不是真正的random  P() 比如符合一个0均值的正态分布</p>
</li>
<li>deterministic是给一个x，输出固定的f(x)</li>
</ul>
<p><img src="image-20220814155434038.png" alt="image-20220814155434038" style="zoom:50%;"></p>
<p><img src="image-20220814155439664.png" alt="image-20220814155439664" style="zoom:50%;"></p>
<ul>
<li><p>从整个dataset中sample出batch的过程是stochastic的</p>
</li>
<li><p>stochastic gradient descent指在一个batch上对梯度求平均再更新，而不是求整个dataset梯度的平均</p>
</li>
</ul>
<p><img src="image-20220814155818928.png" alt="image-20220814155818928" style="zoom:50%;"></p>
<p><img src="image-20220814155829994.png" alt="image-20220814155829994" style="zoom:50%;"></p>
<h2 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h2><h3 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h3><p><img src="image-20220814160037960.png" alt="image-20220814160037960" style="zoom:50%;"></p>
<p>每一点表示灰度值，一般将0~255变到0 ~1</p>
<p><img src="image-20220814160107220.png" alt="image-20220814160107220" style="zoom:50%;"></p>
<p><img src="image-20220814160357536.png" alt="image-20220814160357536" style="zoom:50%;"></p>
<p><img src="image-20220814160429578.png" alt="image-20220814160429578" style="zoom:50%;"></p>
<p><img src="image-20220814160557253.png" alt="image-20220814160557253" style="zoom:50%;"></p>
<p>局部相关性</p>
<p><img src="image-20220814160834102.png" alt="image-20220814160834102" style="zoom:50%;"></p>
<p><img src="image-20220814160947970.png" alt="image-20220814160947970" style="zoom:50%;"></p>
<p>对应位置元素相乘再累加的操作叫做卷积操作</p>
<p><img src="image-20220814163002320.png" alt="image-20220814163002320" style="zoom:50%;"></p>
<p>t 是offset，$y(t)$ 是 $h(\tau)$ 经过偏移和 $x(\tau)$ 的积分运算</p>
<p><img src="image-20220814163145170.png" alt="image-20220814163145170" style="zoom:50%;"></p>
<p><img src="image-20220814163341861.png" alt="image-20220814163341861" style="zoom:50%;"></p>
<p>锐化</p>
<p><img src="image-20220814163355198.png" alt="image-20220814163355198" style="zoom:50%;"></p>
<p>模糊</p>
<p><img src="image-20220814163406213.png" alt="image-20220814163406213" style="zoom:50%;"></p>
<p>边缘检测</p>
<p><img src="image-20220814163506484.png" alt="image-20220814163506484" style="zoom:50%;"></p>
<p><img src="image-20220814163750713.png" alt="image-20220814163750713" style="zoom:50%;"></p>
<p><img src="image-20220814164407387.png" alt="image-20220814164407387" style="zoom:50%;"></p>
<p><img src="image-20220814164514533.png" alt="image-20220814164514533" style="zoom:50%;"></p>
<p>不同的kernel，不同的观察角度</p>
<p><img src="image-20220814164658099.png" alt="image-20220814164658099" style="zoom:50%;"></p>
<p><img src="image-20220814164911325.png" alt="image-20220814164911325" style="zoom:50%;"></p>
<ul>
<li><p>input_channels 指的是输入的通道有几个，黑白的是1，彩色的是3</p>
</li>
<li><p>kernel channel指的是用了多少个核</p>
</li>
<li><p>stride：步长，一次移动几格</p>
</li>
</ul>
<p><img src="image-20220814174052088.png" alt="image-20220814174052088" style="zoom:50%;"></p>
<p><img src="image-20220814174700922.png" alt="image-20220814174700922" style="zoom:50%;"></p>
<ul>
<li><p>输入是[b, 3, 28, 28]，每个kernel是[3 (channel，和输入的3个通道对应起来), 3, 3]</p>
</li>
<li><p>每一个kernel上有一个偏置</p>
</li>
<li><p>一般将kernel的个数叫做kernel的channel</p>
</li>
<li><p>Filter = kernel = weight</p>
</li>
<li><p><img src="image-20220814174553913.png" alt="image-20220814174553913" style="zoom:25%;">这些和输入对应位置相乘相加后要再全部加起来，而不是分三个</p>
</li>
</ul>
<h3 id="卷积神经网络-1"><a href="#卷积神经网络-1" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h3><p><img src="image-20220814175203342.png" alt="image-20220814175203342" style="zoom:50%;"></p>
<p>k的第二维对应的是输入有几个channel，第一维是指生成的输出有几个channel，也即有几个kernel</p>
<p><img src="image-20220814175421868.png" alt="image-20220814175421868" style="zoom:50%;"></p>
<ul>
<li><p>stack</p>
</li>
<li><p>特征不停地提取的过程</p>
</li>
<li><p>堆叠式 从底层特征（边缘颜色）到高层特征（有没有某个物体）的抽取</p>
</li>
</ul>
<p><img src="image-20220814194153079.png" alt="image-20220814194153079" style="zoom:50%;"></p>
<ul>
<li><p><code>nn.Conv2d(1, 3, kernel_size=3, stride=1, padding=0)</code>第一个参数1是input channel，可以推测输入是[b,1,28,28]，第二个参数3指有几个kernel</p>
</li>
<li><p><code>layer.forward(x)</code>完成卷积的前向运算</p>
</li>
<li><p><code>stride=2</code> <code>padding=1</code>直接折半</p>
</li>
<li><p>__call__中封装了一些pytorch的hooks，调用<code>layer(x)</code>自动调用__call__。如果要使用这些hooks，必须使用<code>layer(x)</code>，而不是直接forward方法</p>
</li>
</ul>
<p><img src="image-20220814195632657.png" alt="image-20220814195632657" style="zoom:50%;"></p>
<p>weight=kernel</p>
<p><img src="image-20220814200024825.png" alt="image-20220814200024825" style="zoom:50%;"></p>
<ul>
<li><p><code>F.conv2d()</code>比<code>nn.Conv2d()</code>低阶，前者是函数，后者是一个类</p>
</li>
<li><p>x和w不匹配会出现错误</p>
</li>
</ul>
<h3 id="池化层与采样"><a href="#池化层与采样" class="headerlink" title="池化层与采样"></a>池化层与采样</h3><p><img src="image-20220814200054864.png" alt="image-20220814200054864" style="zoom:50%;"></p>
<p><img src="image-20220814200139800.png" alt="image-20220814200139800" style="zoom:50%;"></p>
<p><img src="image-20220814200328876.png" alt="image-20220814200328876" style="zoom:50%;"></p>
<p><img src="image-20220814200711921.png" alt="image-20220814200711921" style="zoom:50%;"></p>
<p><img src="image-20220814200930376.png" alt="image-20220814200930376" style="zoom:50%;"></p>
<ul>
<li><p>resnet5中采用的是subsampling（隔行采样，隔列采样），而从AlexNet之后用的是pooling（每个窗口中取最大/平均…）</p>
</li>
<li><p>但都是降维的操作</p>
</li>
</ul>
<p><img src="image-20220814201131928.png" alt="image-20220814201131928" style="zoom:50%;"></p>
<p><code>nn.MaxPool2d(2, stride=2)</code>，第一个参数是window的大小，即2×2，和stride=2搭配就是减半</p>
<p><img src="image-20220814201423518.png" alt="image-20220814201423518" style="zoom:50%;"></p>
<p>向上采样，图像的放大 可视化更好看出物体</p>
<p><img src="image-20220814201728000.png" alt="image-20220814201728000" style="zoom:50%;"></p>
<p><code>F.interpolate(x, scale_factor=2, mode=&#39;nearest&#39;)</code>插值的函数，第二个参数是要放大的倍数2，用的插值的方法是nearest</p>
<p><img src="image-20220814201852933.png" alt="image-20220814201852933" style="zoom:50%;"></p>
<p><img src="image-20220814202214776.png" alt="image-20220814202214776" style="zoom:50%;"></p>
<p>conv2d后batchnorm、pooling、relu的次序不定</p>
<p><img src="image-20220814202407777.png" alt="image-20220814202407777" style="zoom:50%;"></p>
<p><code>layer=nn.ReLU(inplace=True)</code>一般都会把inplace设置为True，原地更新，节省内存</p>
<h3 id="BatchNorm"><a href="#BatchNorm" class="headerlink" title="BatchNorm"></a>BatchNorm</h3><p><img src="image-20220814203531190.png" alt="image-20220814203531190" style="zoom:50%;"></p>
<ul>
<li><p>希望把输入的值控制在一个有效的范围之内，比如输入的值在-100 ~ 100，w更杂乱无章，直接送到sigmoid函数中可能出现梯度弥散的现象</p>
</li>
<li><p>希望送到下一层之前先做normalize的操作，先把值变换到比如以0为均值，$\sigma$ 为方差。使其落到0的附近，在小范围内变动。下一层优化起来就会变得方便</p>
</li>
</ul>
<p><img src="image-20220814210514077.png" alt="image-20220814210514077" style="zoom:50%;"></p>
<ul>
<li><p>$x_1$ 在一个小的区间，$x_2$ 在比较大的区间，$w_2$ 稍微变动就会使Loss急剧变化</p>
</li>
<li><p>图中就是 $w_1$ 变化，等高线不怎么变化，$w_2$ 变化，等高线变化明显，搜索时会比较曲折</p>
</li>
<li><p>如果 $w_1,w_2$ 范围一样，搜索时不管从哪个点出发，搜索快捷、稳定</p>
</li>
</ul>
<p><img src="image-20220814212642619.png" alt="image-20220814212642619" style="zoom:50%;"></p>
<ul>
<li><p>全局缩放。希望在0附近，方差比较小地变动</p>
</li>
<li><p>对图片：对RGB通道分别做normalize。图片每个点在[0,1]范围，我们希望以0为均值，在0附近。统计了imageNet的RGB通道的均值</p>
</li>
<li><p>对一张图片做normalize，比如R通道，就是 $x^{‘}_{r}=\frac{x_r-0.485}{0.229}$</p>
</li>
</ul>
<p><img src="image-20220814213228186.png" alt="image-20220814213228186" style="zoom:50%;"></p>
<ul>
<li><p>HeKaiming：Group Norm</p>
</li>
<li><p>Batch Norm：每个channel上所有实例所有feature的均值，只保留了channel维度  </p>
</li>
<li><p>[6,3,784] -&gt; [3]      [N, C, H*W] -&gt; [C]</p>
</li>
<li><p>Layer Norm：每个实例的均值   [N, C, H*W] -&gt; [N]</p>
</li>
<li><p>Instance Norm： [N, C, H*W] -&gt; [N,  C]</p>
</li>
</ul>
<p><img src="image-20220814214826622.png" alt="image-20220814214826622" style="zoom:50%;"></p>
<ul>
<li><p>(6, 3, 784)：6张图片，3个channel，每张图片一个784的向量</p>
</li>
<li><p>$z^1,z^2,z^3$ 分别是3个channel上的数据，分别对每个channel即 $z^1,z^2,z^3$  做统计，得到 $\mu,\sigma$，都是[3]的shape</p>
</li>
<li><p>$\widetilde{z}^i=\frac{z^i-\mu}{\sigma}\sim\mathcal{N}(0,1)$，$\widehat{z}^i=\gamma\bigodot\widetilde{z}^i+\beta\sim\mathcal{N}(\beta,\gamma)$</p>
</li>
<li>$\mu,\sigma$ 是根据当前的batch统计出来的，不需要参与到back propagate中的，它有历史的记录。</li>
<li>running- $\mu$ 和 running- $\sigma^2$  代表所有train数据统计出来的均值和方差，是全局的；$\mu,\sigma$ 代表当前batch统计出来的均值和方差。</li>
<li>但 $\gamma,\beta$ 是学出来的，需要梯度信息的</li>
</ul>
<p><img src="image-20220814215318712.png" alt="image-20220814215318712" style="zoom:50%;"></p>
<ul>
<li>28×28变成784，即变成1维的feature</li>
<li><p><code>nn.BatchNorm1d(16)</code>中的16表示channel的数量，处理的是1d的数据</p>
</li>
<li><p><code>torch.rand(100,16,784)</code>这里用的是0到1的均匀分布，均值是0.5</p>
</li>
</ul>
<p><img src="image-20220814221134928.png" alt="image-20220814221134928" style="zoom:50%;"></p>
<ul>
<li><p>由于有除0的误差，在分母会加一个 $\epsilon$，比如 $10^{-8}$</p>
</li>
<li><p>根据当前一轮batch的 $\mu,\sigma^2$ 更新 running-$\mu$, running-$\sigma^2$</p>
</li>
<li><p>back propagate的时候 $\beta,\gamma$ 会自动地更新</p>
</li>
</ul>
<p><img src="image-20220814221446265.png" alt="image-20220814221446265" style="zoom:50%;"></p>
<ul>
<li><p><code>layer=nn.BatchNorm2d(16)</code>后，<code>layer.weight</code>对应的是 $\gamma$，<code>layer.bias</code>对应的是 $\beta$</p>
</li>
<li><p>目前只能查看全局的 running-mean 和 running-var，对于局部的均值和方差没有接口</p>
</li>
</ul>
<p><img src="image-20220814221904938.png" alt="image-20220814221904938" style="zoom:50%;"></p>
<ul>
<li><p><code>vars(layer)</code>把当前layer的全部参数打印出来</p>
</li>
<li><p>‘running_mean’, ‘running_var’, ‘weight’, ‘bias’ 都是[16]的形状</p>
</li>
<li><p><code>affine</code>参数指 $\gamma,\beta$ 参数是否需要自动学习，如果设置为false，weight就是0，bias就是1，不会变换，不会自动更新</p>
</li>
</ul>
<p><img src="image-20220814222357586.png" alt="image-20220814222357586" style="zoom:50%;"></p>
<ul>
<li>和dropout一样，batch normalization这个layer在train和test的行为不一样</li>
<li>在test的时候统计 $\mu,\sigma^2$ 是没有意义的，因为只有一个batch。</li>
<li><p>它取得不是当前batch的 $\mu,\sigma^2$，而是把全局的 running_mean, running_var 赋给它</p>
</li>
<li><p>test的时候没有back propagate，$\beta,\gamma$ 是不需要更新的</p>
</li>
<li><p>要调用 <code>layer.eval()</code>切换成test模式</p>
</li>
</ul>
<p><img src="image-20220814222605202.png" alt="image-20220814222605202" style="zoom:50%;"></p>
<ul>
<li><p>虚线都是使用了batch normalize，收敛的速度变快，精度也提升</p>
</li>
<li><p>左边没有使用batchNorm</p>
</li>
</ul>
<p><img src="image-20220814222832556.png" alt="image-20220814222832556" style="zoom:50%;"></p>
<ul>
<li><p>因为不再处于sigmoid函数的饱和区域，因此收敛更快</p>
</li>
<li><p>更稳定</p>
</li>
<li><p>使用了batchNorm后，lr可以设置的范围大些，超参数的调整也没有那么敏感</p>
</li>
</ul>
<h3 id="经典CNN-LeNet5-AlexNet-VGG-GoogleNet"><a href="#经典CNN-LeNet5-AlexNet-VGG-GoogleNet" class="headerlink" title="经典CNN-LeNet5,AlexNet,VGG,GoogleNet"></a>经典CNN-LeNet5,AlexNet,VGG,GoogleNet</h3><p><img src="image-20220814223906729.png" alt="image-20220814223906729" style="zoom:50%;"></p>
<p><img src="image-20220814224109709.png" alt="image-20220814224109709" style="zoom:50%;"></p>
<p><img src="image-20220814224458482.png" alt="image-20220814224458482" style="zoom:50%;"></p>
<p>创新：max pooling, ReLU, dropout</p>
<p><img src="image-20220814224724824.png" alt="image-20220814224724824" style="zoom:50%;"></p>
<p>窗口变小，计算量变小，精度也好</p>
<p><img src="image-20220814224924385.png" alt="image-20220814224924385" style="zoom:50%;"></p>
<p>1×1的卷积核，输入输出大小一样，channel会改变</p>
<p><img src="image-20220814225622109.png" alt="image-20220814225622109" style="zoom:50%;"></p>
<ul>
<li><p>Filter concatenation：3×3 max pooling得到的是[32,7,7]的，为了大小匹配，1×1 3×3 5×5 convolutions时将stride设置为2，也都得到[32,7,7]的。再四个部分concat，channel总数变成 32×4 </p>
</li>
<li><p>各种不同类型的kernel的concat。每个kernel的感受视野不同。</p>
</li>
</ul>
<p><img src="image-20220814225736332.png" alt="image-20220814225736332" style="zoom:50%;"></p>
<p><img src="image-20220814225906064.png" alt="image-20220814225906064" style="zoom:50%;"></p>
<h3 id="ResNet与DenseNet"><a href="#ResNet与DenseNet" class="headerlink" title="ResNet与DenseNet"></a>ResNet与DenseNet</h3><p><img src="image-20220815112317750.png" alt="image-20220815112317750" style="zoom:50%;"></p>
<ul>
<li><p>传到最前面几层，梯度接近0</p>
</li>
<li><p>网络很深 误差会有积累 有梯度爆炸 梯度弥散的情况</p>
</li>
<li><p>先22层的网络 再8层的网络 要保证30层的网络再差也能退化到和22层一样</p>
</li>
<li><p>加一个短路层 shortcut 梯度反向传播时，本来要经过8层的网络，会衰减。有捷径时，梯度不衰减，求导后为1，乘1不变</p>
</li>
<li><p>每隔多少层加一个shortcut   单元堆叠</p>
</li>
<li><p>conv-relu-conv-relu 为一个单元，两头加一个短接线</p>
</li>
</ul>
<p><img src="image-20220815112712719.png" alt="image-20220815112712719" style="zoom:50%;"></p>
<ul>
<li><p>unit用2~3层的卷积层再加一个shortcut比较合适</p>
</li>
<li><p>shortcut的起点终点大小要一样 因为要做element-wise的相加 channel个数要一样</p>
</li>
</ul>
<p><img src="image-20220815113235700.png" alt="image-20220815113235700" style="zoom:50%;"></p>
<ul>
<li>加了shortcut更加loss平滑 更加容易找到最优解</li>
</ul>
<p><img src="image-20220815113341018.png" alt="image-20220815113341018" style="zoom:50%;"></p>
<p><img src="image-20220815113502768.png" alt="image-20220815113502768" style="zoom:50%;"></p>
<p><img src="image-20220815113539970.png" alt="image-20220815113539970" style="zoom:50%;"></p>
<p>残差解释：</p>
<p>如果只有2个卷积层 x到x’ 模拟了 x’=H(x) 的mapping</p>
<p>中间的小mapping叫F(x) 再加x 就是原来的H(x) mapping</p>
<p>中间的F(x)学习的是H(x)-x</p>
<p><img src="image-20220815113816092.png" alt="image-20220815113816092" style="zoom:50%;"></p>
<ul>
<li><p>ResNet计算量小</p>
</li>
<li><p>VGG计算量大 较少采用小卷积核 效果比ResNet差</p>
</li>
</ul>
<p><img src="image-20220815115239652.png" alt="image-20220815115239652" style="zoom:50%;"></p>
<ul>
<li><p>ResNet是由基本单元（ResBlk）堆叠而成的</p>
</li>
<li><p>如果输入输出的channel不一致的话，从输入到输出用1×1的卷积，并使其变成和输出一致的channel数量</p>
</li>
</ul>
<p><img src="image-20220815115429043.png" alt="image-20220815115429043" style="zoom:50%;"></p>
<ul>
<li><p>拓展：每一层和前面的每一层都可以接触/短接</p>
</li>
<li><p>做的是concat channel会越来越大</p>
</li>
</ul>
<h3 id="卷积神经网络实战"><a href="#卷积神经网络实战" class="headerlink" title="卷积神经网络实战"></a>卷积神经网络实战</h3><p>lenet5.py：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Lenet5</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    for cifar dataset</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Lenet5, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.conv_unit = nn.Sequential(</span><br><span class="line">            <span class="comment"># x: [b, 3, 32, 32] =&gt; [b, 6,...]</span></span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">6</span>, kernel_size=<span class="number">5</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>),</span><br><span class="line">            nn.AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>),</span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, kernel_size=<span class="number">5</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>),</span><br><span class="line">            nn.AvgPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>),</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># flatten</span></span><br><span class="line">        <span class="comment"># fc unit</span></span><br><span class="line">        self.fc_unit = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">16</span>*<span class="number">5</span>*<span class="number">5</span>, <span class="number">120</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">120</span>, <span class="number">84</span>),</span><br><span class="line">            nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param x: [b, 3, 32, 32]</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        batchsz = x.size(<span class="number">0</span>)</span><br><span class="line">        <span class="comment"># [b, 3, 32, 32] =&gt; [b, 16, 5, 5]</span></span><br><span class="line">        x = self.conv_unit(x)</span><br><span class="line">        <span class="comment"># [b, 16, 5, 5] =&gt; [b, 16*5*5]</span></span><br><span class="line">        x = x.view(batchsz, <span class="number">16</span>*<span class="number">5</span>*<span class="number">5</span>)</span><br><span class="line">        <span class="comment"># [b, 16*5*5] =&gt; [b, 10]</span></span><br><span class="line">        logits = self.fc_unit(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment">## [b, 10], 在10的那一维做softmax，因此dim=1</span></span><br><span class="line">        <span class="comment"># pred = F.softmax(logits, dim=1)</span></span><br><span class="line">        <span class="comment"># loss = self.criteon(logits, y)</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> logits</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line"></span><br><span class="line">    net = Lenet5()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># [b, 3, 32, 32]</span></span><br><span class="line">    tmp = torch.randn(<span class="number">2</span>, <span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>)</span><br><span class="line">    out = net(tmp)</span><br><span class="line">    <span class="comment"># [b, 16, 5, 5]</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;lenet_out:&#x27;</span>, out.shape)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># use Cross Entropy Loss</span></span><br><span class="line">    <span class="comment"># self.criteon = nn.MSELoss()</span></span><br><span class="line">    <span class="comment"># self.criteon = nn.CrossEntropyLoss()</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<p>main.py：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, optim</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> lenet5 <span class="keyword">import</span> Lenet5</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    batchsz = <span class="number">32</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># transform用来对数据做一些变换，数据类型要转化成tensor</span></span><br><span class="line">    <span class="comment"># 只是转化为每次取一张的loader</span></span><br><span class="line">    cifar_train = datasets.CIFAR10(<span class="string">&#x27;cifar&#x27;</span>, <span class="literal">True</span>, transform=transforms.Compose([</span><br><span class="line">        transforms.Resize((<span class="number">32</span>, <span class="number">32</span>)),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        <span class="comment">#transforms.Normalize(mean=[0.485, 0.456, 0.406],</span></span><br><span class="line">        <span class="comment">#                     std=[0.229, 0.224, 0.225])  # 在0的附近分布</span></span><br><span class="line">    ]), download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># DataLoader 使一次加载多个</span></span><br><span class="line">    cifar_train = DataLoader(cifar_train, batch_size=batchsz, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    cifar_test = datasets.CIFAR10(<span class="string">&#x27;cifar&#x27;</span>, <span class="literal">False</span>, transform=transforms.Compose([</span><br><span class="line">        transforms.Resize((<span class="number">32</span>, <span class="number">32</span>)),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        <span class="comment"># transforms.Normalize(mean=[0.485, 0.456, 0.406],</span></span><br><span class="line">        <span class="comment">#                       std=[0.229, 0.224, 0.225])</span></span><br><span class="line">    ]), download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># DataLoader 使一次加载多个</span></span><br><span class="line">    cifar_test = DataLoader(cifar_test, batch_size=batchsz, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    x, label = <span class="built_in">iter</span>(cifar_train).<span class="built_in">next</span>()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;x:&#x27;</span>, x.shape, <span class="string">&#x27;label:&#x27;</span>, label.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    device = torch.device(<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line">    model = Lenet5().to(device)</span><br><span class="line">    criteon = nn.CrossEntropyLoss().to(device)  <span class="comment"># 自带了softmax</span></span><br><span class="line">    optimizer = optim.Adam(model.parameters(), lr=<span class="number">1e-3</span>)</span><br><span class="line">    <span class="built_in">print</span>(model)  <span class="comment"># 打印模型的结构</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line"></span><br><span class="line">        model.train()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> batchidx, (x, label) <span class="keyword">in</span> <span class="built_in">enumerate</span>(cifar_train):</span><br><span class="line">            <span class="comment"># [b, 3, 32, 32], [b]</span></span><br><span class="line">            x, label = x.to(device), label.to(device)</span><br><span class="line"></span><br><span class="line">            logits = model(x)</span><br><span class="line">            <span class="comment"># logits: [b, 10] 给出每个维度的probability</span></span><br><span class="line">            <span class="comment"># label: [b] 不需要经过one-hot</span></span><br><span class="line">            loss = criteon(logits, label)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># backprop</span></span><br><span class="line">            optimizer.zero_grad()  <span class="comment"># 每次back propagate时不清零的话不是写新的梯度，而是把梯度累加到原来的上面</span></span><br><span class="line">            loss.backward()  <span class="comment"># 计算梯度</span></span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># loss：tensor scaler 标量，用item()转化成标量</span></span><br><span class="line">        <span class="built_in">print</span>(epoch, loss.item())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        model.<span class="built_in">eval</span>()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            <span class="comment"># test</span></span><br><span class="line">            total_correct = <span class="number">0</span></span><br><span class="line">            total_num = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> x, label <span class="keyword">in</span> cifar_test:</span><br><span class="line">                x, label = x.to(device), label.to(device)</span><br><span class="line"></span><br><span class="line">                logits = model(x)  <span class="comment"># 这里forward是不需要构建计算图的，因此包在no_grad里面</span></span><br><span class="line">                <span class="comment"># [b]</span></span><br><span class="line">                pred = logits.argmax(dim=<span class="number">1</span>)</span><br><span class="line">                <span class="comment"># [b] vs [b]</span></span><br><span class="line">                total_correct += torch.eq(pred, label).<span class="built_in">float</span>().<span class="built_in">sum</span>().item()</span><br><span class="line">                total_num += x.size(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">            acc = total_correct / total_num</span><br><span class="line">            <span class="built_in">print</span>(epoch, acc)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<h3 id="ResNet实战"><a href="#ResNet实战" class="headerlink" title="ResNet实战"></a>ResNet实战</h3><p>resnet.py：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResBlk</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    resnet block</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, ch_in, ch_out, stride=<span class="number">1</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param ch_in:</span></span><br><span class="line"><span class="string">        :param ch_out:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(ResBlk, self).__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># we add stride support for resbok, which is distinct from tutorials.</span></span><br><span class="line">        self.conv1 = nn.Conv2d(ch_in, ch_out, kernel_size=<span class="number">3</span>, stride=stride, padding=<span class="number">1</span>)</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(ch_out)</span><br><span class="line">        self.conv2 = nn.Conv2d(ch_out, ch_out, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(ch_out)</span><br><span class="line"></span><br><span class="line">        self.extra = nn.Sequential()</span><br><span class="line">        <span class="keyword">if</span> ch_out != ch_in:</span><br><span class="line">            <span class="comment"># [b, ch_in, h, w] =&gt; [b, ch_out, h, w]</span></span><br><span class="line">            self.extra = nn.Sequential(</span><br><span class="line">                nn.Conv2d(ch_in, ch_out, kernel_size=<span class="number">1</span>, stride=stride),</span><br><span class="line">                nn.BatchNorm2d(ch_out)</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param x: [b, ch, h, w]</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        out = F.relu(self.bn1(self.conv1(x)))</span><br><span class="line">        out = self.bn2(self.conv2(out))</span><br><span class="line">        <span class="comment"># short cut.</span></span><br><span class="line">        <span class="comment"># extra module: [b, ch_in, h, w] =&gt; [b, ch_out, h, w]</span></span><br><span class="line">        <span class="comment"># element-wise add:</span></span><br><span class="line">        out = self.extra(x) + out</span><br><span class="line">        out = F.relu(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResNet18</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(ResNet18, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.conv1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">3</span>, padding=<span class="number">0</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">64</span>)</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># followed 4 blocks</span></span><br><span class="line">        <span class="comment"># [b, 64, h, w] =&gt; [b, 128, h ,w]</span></span><br><span class="line">        self.blk1 = ResBlk(<span class="number">64</span>, <span class="number">128</span>, stride=<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># [b, 128, h, w] =&gt; [b, 256, h, w]</span></span><br><span class="line">        self.blk2 = ResBlk(<span class="number">128</span>, <span class="number">256</span>, stride=<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># # [b, 256, h, w] =&gt; [b, 512, h, w]</span></span><br><span class="line">        self.blk3 = ResBlk(<span class="number">256</span>, <span class="number">512</span>, stride=<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># # [b, 512, h, w] =&gt; [b, 512, h, w]</span></span><br><span class="line">        self.blk4 = ResBlk(<span class="number">512</span>, <span class="number">512</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        self.outlayer = nn.Linear(<span class="number">512</span> * <span class="number">1</span> * <span class="number">1</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param x:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        x = F.relu(self.conv1(x))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># [b, 64, h, w] =&gt; [b, 1024, h, w]</span></span><br><span class="line">        x = self.blk1(x)</span><br><span class="line">        x = self.blk2(x)</span><br><span class="line">        x = self.blk3(x)</span><br><span class="line">        x = self.blk4(x)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># print(&#x27;after conv:&#x27;, x.shape) #[b, 512, 2, 2]</span></span><br><span class="line">        <span class="comment"># [b, 512, h, w] =&gt; [b, 512, 1, 1]  h*w个像素，最终只会得到一个像素</span></span><br><span class="line">        x = F.adaptive_avg_pool2d(x, [<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">        <span class="comment"># print(&#x27;after pool:&#x27;, x.shape)</span></span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), -<span class="number">1</span>)  <span class="comment"># 打平</span></span><br><span class="line">        x = self.outlayer(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    blk = ResBlk(<span class="number">64</span>, <span class="number">128</span>, stride=<span class="number">4</span>)</span><br><span class="line">    tmp = torch.randn(<span class="number">2</span>, <span class="number">64</span>, <span class="number">32</span>, <span class="number">32</span>)</span><br><span class="line">    out = blk(tmp)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;block:&#x27;</span>, out.shape)</span><br><span class="line"></span><br><span class="line">    x = torch.randn(<span class="number">2</span>, <span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>)</span><br><span class="line">    model = ResNet18()</span><br><span class="line">    out = model(x)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;resnet:&#x27;</span>, out.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<h2 id="nn-Module"><a href="#nn-Module" class="headerlink" title="nn.Module"></a>nn.Module</h2><p><img src="image-20220815123344197.png" alt="image-20220815123344197" style="zoom:50%;"></p>
<ul>
<li>nn.Module是所有网络层次类的父类。线性层、卷积层其实都是继承自它，只是因为是用的比较多，官方已经写好了。自己实现的话，要继承自它</li>
</ul>
<p><img src="image-20220815123401213.png" alt="image-20220815123401213" style="zoom:50%;"></p>
<ul>
<li>可以嵌套，nn.Module中可以嵌套nn.Module</li>
</ul>
<p><img src="image-20220815123410980.png" alt="image-20220815123410980" style="zoom:50%;"></p>
<p><img src="image-20220815123416603.png" alt="image-20220815123416603" style="zoom:50%;"></p>
<ul>
<li>只要是继承自nn.Module，都可以写进 nn.Sequential</li>
<li><code>self.net(x)</code>自动完成forward操作</li>
</ul>
<p><img src="image-20220815123425116.png" alt="image-20220815123425116" style="zoom:50%;"></p>
<ul>
<li>nn.Module会对网络中的参数有效地管理</li>
<li><code>net.parameters()</code>得到一个迭代器，再通过<code>list(net.parameters())</code>转化为列表，每个参数作为一个元素。可以用这个方法把参数都传到优化器中</li>
<li><p><code>net.named_parameters()</code>返回一个带名字的参数字典，比如第0层的weight<code>0:weight</code></p>
</li>
<li><p>w定义输出维度在前面</p>
</li>
</ul>
<p><img src="image-20220815123434781.png" alt="image-20220815123434781" style="zoom:50%;"></p>
<ul>
<li>直接的子节点（直系亲属）叫做children，所有的子节点叫做modules</li>
</ul>
<p><img src="image-20220815123445285.png" alt="image-20220815123445285" style="zoom:50%;"></p>
<p>根节点是net类，里面使用了Sequential，里面又使用了BasicNet,ReLU,Linear</p>
<p><img src="image-20220815123454177.png" alt="image-20220815123454177" style="zoom:50%;"></p>
<ul>
<li>module包含了它本身</li>
</ul>
<p><img src="image-20220815123505928.png" alt="image-20220815123505928" style="zoom:50%;"></p>
<ul>
<li><p><code>net.to(device)</code>返回的net的引用和原来一样</p>
</li>
<li><p>但data搬到GPU上，返回的不是一个东西</p>
</li>
</ul>
<p><img src="image-20220815123514976.png" alt="image-20220815123514976" style="zoom:50%;"></p>
<ul>
<li>ckpt：checkpoint，网络训练时的中间状态</li>
<li>train前先检查有没有checkpoint，如果有，将参数加载进网络<code>net.load_state_dict(torch.load(&#39;ckpt.mdl&#39;))</code></li>
</ul>
<p><img src="image-20220815123524381.png" alt="image-20220815123524381" style="zoom:50%;"></p>
<ul>
<li><p>dropout、batch normalization在test和train的表现不一样，要对nn.module的行为进行切换</p>
</li>
<li><p>调用根节点切换状态，子节点的module状态都会被切换</p>
</li>
<li><p>test里面 没有test方法，只有eval方法</p>
</li>
</ul>
<p><img src="image-20220815123532819.png" alt="image-20220815123532819" style="zoom:50%;"></p>
<ul>
<li><p>nn.Sequential中必须是一个类，比如nn.ReLU是一个类，F.relu是一个函数</p>
</li>
<li><p>自己实现一个继承自nn.Module的Flatten类，就可以把它放到Sequential容器中，否则需要在两个Sequential中间断开，单独处理打平。有了Flatten类后只需要一个Sequential，可以一次地forward</p>
</li>
<li><p>Flatten不需要接受任何参数，因为只要保留第一维batch size，其他打平</p>
</li>
<li><p>也可以自己定义一个reshape类</p>
</li>
</ul>
<p><img src="image-20220815123541924.png" alt="image-20220815123541924" style="zoom:50%;"></p>
<ul>
<li>定义torch.tensor不会自动加到nn.parameters中去，必须要require grad，否则调用<code>nn.parameters()</code>不会有这个参数</li>
<li><p>nn.Parameter这个类可以把tensor进行包装，加到参数中</p>
</li>
<li><p>nn.parameters()（小写）返回的是一个list</p>
</li>
</ul>
<h2 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h2><p><img src="image-20220815130246239.png" alt="image-20220815130246239" style="zoom:50%;"></p>
<p><img src="image-20220815130251155.png" alt="image-20220815130251155" style="zoom:50%;"></p>
<p><img src="image-20220815130256656.png" alt="image-20220815130256656" style="zoom:50%;"></p>
<p>怎么针对有限的数据做优化：减少网络参数量，加正则化，数据增强</p>
<p><img src="image-20220815130305353.png" alt="image-20220815130305353" style="zoom:50%;"></p>
<p><img src="image-20220815130310254.png" alt="image-20220815130310254" style="zoom:50%;"></p>
<p><img src="image-20220815130317689.png" alt="image-20220815130317689" style="zoom:50%;"></p>
<ul>
<li>翻转</li>
</ul>
<p><img src="image-20220815130328545.png" alt="image-20220815130328545" style="zoom:50%;"></p>
<ul>
<li><code>transforms.RandomHorizontalFlip()</code> 有个random，可能做，可能不做</li>
</ul>
<p><img src="image-20220815130343118.png" alt="image-20220815130343118" style="zoom:50%;"></p>
<p><img src="image-20220815130348286.png" alt="image-20220815130348286" style="zoom:50%;"></p>
<ul>
<li><code>transforms.RandomRotation([90, 180, 270])</code>指在这三个角度中随机挑一个旋转，可以再加一个0°，有可能不旋转</li>
</ul>
<p><img src="image-20220815130359907.png" alt="image-20220815130359907" style="zoom:50%;"></p>
<ul>
<li>缩放，从中心点往外</li>
</ul>
<p><img src="image-20220815130410216.png" alt="image-20220815130410216" style="zoom:50%;"></p>
<p><img src="image-20220815130415028.png" alt="image-20220815130415028" style="zoom:50%;"></p>
<ul>
<li>随机裁剪、旋转组合比较多</li>
</ul>
<p><img src="image-20220815130425496.png" alt="image-20220815130425496" style="zoom:50%;"></p>
<ul>
<li><p>transform是torchvision这个包提供的，（面向视觉领域）</p>
</li>
<li><p>Compose类似于Sequential，打包操作</p>
</li>
</ul>
<p><img src="image-20220815130433688.png" alt="image-20220815130433688" style="zoom:50%;"></p>
<ul>
<li>加高斯噪声</li>
</ul>
<p><img src="image-20220815130442434.png" alt="image-20220815130442434" style="zoom:50%;"></p>
<ul>
<li>input的variance比较小，因此train的performance也不会很好</li>
</ul>
<h2 id="CIFAR10数据集"><a href="#CIFAR10数据集" class="headerlink" title="CIFAR10数据集"></a>CIFAR10数据集</h2><p><img src="image-20220815130851181.png" alt="image-20220815130851181" style="zoom:50%;"></p>
<ul>
<li><p>CIFAR10：10大类，每一类6000张照片。一共60000张，50000张做training，10000张做test</p>
</li>
<li><p>CIFAR100：还要再细分</p>
</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://seline02.github.io">Seline</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://seline02.github.io/2022/08/13/pytorch%E7%AC%94%E8%AE%B0/">https://seline02.github.io/2022/08/13/pytorch%E7%AC%94%E8%AE%B0/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://seline02.github.io" target="_blank">Seline's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/PyTorch/">PyTorch</a></div><div class="post_share"><div class="social-share" data-image="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/08/15/RNN-LSTM/"><img class="prev-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">RNN, LSTM</div></div></a></div><div class="next-post pull-right"><a href="/2022/08/10/%E5%8F%98%E5%88%86%E6%8E%A8%E6%96%AD/"><img class="next-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">变分推断</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/08/16/AE-VAE/" title="AE-VAE"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-08-16</div><div class="title">AE-VAE</div></div></a></div><div><a href="/2022/08/15/RNN-LSTM/" title="RNN, LSTM"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-08-15</div><div class="title">RNN, LSTM</div></div></a></div><div><a href="/2022/08/16/%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E9%9B%86-%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/" title="自定义数据集, 迁移学习"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-08-16</div><div class="title">自定义数据集, 迁移学习</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Seline</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">13</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%A0%E9%87%8F"><span class="toc-number">1.</span> <span class="toc-text">张量</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9B%E5%BB%BATensor"><span class="toc-number">1.1.</span> <span class="toc-text">创建Tensor</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%B4%A2%E5%BC%95%E4%B8%8E%E5%88%87%E7%89%87"><span class="toc-number">1.2.</span> <span class="toc-text">索引与切片</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%B4%E5%BA%A6%E5%8F%98%E6%8D%A2"><span class="toc-number">1.3.</span> <span class="toc-text">维度变换</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8B%BC%E6%8E%A5%E4%B8%8E%E6%8B%86%E5%88%86"><span class="toc-number">1.4.</span> <span class="toc-text">拼接与拆分</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E5%AD%A6%E8%BF%90%E7%AE%97"><span class="toc-number">1.5.</span> <span class="toc-text">数学运算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%9F%E8%AE%A1%E5%B1%9E%E6%80%A7"><span class="toc-number">1.6.</span> <span class="toc-text">统计属性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%AB%98%E9%98%B6%E6%93%8D%E4%BD%9C"><span class="toc-number">1.7.</span> <span class="toc-text">高阶操作</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC"><span class="toc-number">2.</span> <span class="toc-text">自动求导</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E4%B8%8ELoss%E7%9A%84%E6%A2%AF%E5%BA%A6"><span class="toc-number">2.1.</span> <span class="toc-text">激活函数与Loss的梯度</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2D%E5%87%BD%E6%95%B0%E4%BC%98%E5%8C%96%E5%AE%9E%E4%BE%8B"><span class="toc-number">2.2.</span> <span class="toc-text">2D函数优化实例</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%86%B5%EF%BC%8C%E4%BA%A4%E5%8F%89%E7%86%B5"><span class="toc-number">3.</span> <span class="toc-text">熵，交叉熵</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%E5%AE%9E%E6%88%98"><span class="toc-number">4.</span> <span class="toc-text">多分类问题实战</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E4%B8%8EGPU%E5%8A%A0%E9%80%9F"><span class="toc-number">5.</span> <span class="toc-text">激活函数与GPU加速</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MNIST%E6%B5%8B%E8%AF%95"><span class="toc-number">6.</span> <span class="toc-text">MNIST测试</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Visdom%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="toc-number">7.</span> <span class="toc-text">Visdom可视化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%87%E6%8B%9F%E5%90%88-amp-%E6%AC%A0%E6%8B%9F%E5%90%88"><span class="toc-number">8.</span> <span class="toc-text">过拟合&amp;欠拟合</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Train-Val-Test%E5%88%92%E5%88%86"><span class="toc-number">9.</span> <span class="toc-text">Train-Val-Test划分</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Regularization"><span class="toc-number">10.</span> <span class="toc-text">Regularization</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8A%A8%E9%87%8F%E4%B8%8E%E5%AD%A6%E4%B9%A0%E7%8E%87%E8%A1%B0%E5%87%8F"><span class="toc-number">11.</span> <span class="toc-text">动量与学习率衰减</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Early-stopping%EF%BC%8Cdropout"><span class="toc-number">12.</span> <span class="toc-text">Early stopping，dropout</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">13.</span> <span class="toc-text">卷积神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF"><span class="toc-number">13.1.</span> <span class="toc-text">卷积</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-1"><span class="toc-number">13.2.</span> <span class="toc-text">卷积神经网络</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B1%A0%E5%8C%96%E5%B1%82%E4%B8%8E%E9%87%87%E6%A0%B7"><span class="toc-number">13.3.</span> <span class="toc-text">池化层与采样</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#BatchNorm"><span class="toc-number">13.4.</span> <span class="toc-text">BatchNorm</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%8F%E5%85%B8CNN-LeNet5-AlexNet-VGG-GoogleNet"><span class="toc-number">13.5.</span> <span class="toc-text">经典CNN-LeNet5,AlexNet,VGG,GoogleNet</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ResNet%E4%B8%8EDenseNet"><span class="toc-number">13.6.</span> <span class="toc-text">ResNet与DenseNet</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E6%88%98"><span class="toc-number">13.7.</span> <span class="toc-text">卷积神经网络实战</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ResNet%E5%AE%9E%E6%88%98"><span class="toc-number">13.8.</span> <span class="toc-text">ResNet实战</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#nn-Module"><span class="toc-number">14.</span> <span class="toc-text">nn.Module</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA"><span class="toc-number">15.</span> <span class="toc-text">数据增强</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#CIFAR10%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">16.</span> <span class="toc-text">CIFAR10数据集</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/08/31/%E5%89%8D%E7%AB%AF%E8%AF%AD%E8%A8%80/" title="前端语言"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="前端语言"/></a><div class="content"><a class="title" href="/2022/08/31/%E5%89%8D%E7%AB%AF%E8%AF%AD%E8%A8%80/" title="前端语言">前端语言</a><time datetime="2022-08-31T08:10:05.000Z" title="发表于 2022-08-31 16:10:05">2022-08-31</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/08/29/%E8%AF%AD%E9%9F%B3-%E8%83%8C%E6%99%AF%E7%9F%A5%E8%AF%86/" title="语音-背景知识"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="语音-背景知识"/></a><div class="content"><a class="title" href="/2022/08/29/%E8%AF%AD%E9%9F%B3-%E8%83%8C%E6%99%AF%E7%9F%A5%E8%AF%86/" title="语音-背景知识">语音-背景知识</a><time datetime="2022-08-29T12:41:13.000Z" title="发表于 2022-08-29 20:41:13">2022-08-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/08/25/Wav2vec/" title="Wav2vec"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Wav2vec"/></a><div class="content"><a class="title" href="/2022/08/25/Wav2vec/" title="Wav2vec">Wav2vec</a><time datetime="2022-08-25T02:54:04.000Z" title="发表于 2022-08-25 10:54:04">2022-08-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/08/25/CA-MSER-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" title="CA-MSER 论文笔记"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CA-MSER 论文笔记"/></a><div class="content"><a class="title" href="/2022/08/25/CA-MSER-%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" title="CA-MSER 论文笔记">CA-MSER 论文笔记</a><time datetime="2022-08-25T02:08:50.000Z" title="发表于 2022-08-25 10:08:50">2022-08-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/08/21/Proximal-Policy-Optimization/" title="Proximal Policy Optimization"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Proximal Policy Optimization"/></a><div class="content"><a class="title" href="/2022/08/21/Proximal-Policy-Optimization/" title="Proximal Policy Optimization">Proximal Policy Optimization</a><time datetime="2022-08-21T10:48:01.000Z" title="发表于 2022-08-21 18:48:01">2022-08-21</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By Seline</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>