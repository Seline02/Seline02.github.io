<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Data Mining 阅读笔记 | Seline's blog</title><meta name="author" content="Seline"><meta name="copyright" content="Seline"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="第二章 数据预处理 2.1 简介 收集到的数据很可能是非结构化的，需要从其中提取特征，因此需要数据预处理。 数据预处理的几个步骤：  特征提取和可移植性  数据有多个来源，需要集成到单个数据库；有些算法只能使用特定的数据类型，而数据可能包含不同类型的数据，因此需要数据类型的可移植性   数据清洗  删除&#x2F;插补条目   数据消减、选择和转换  数据量减少：通过采样&#x2F;降维 特征选择：和具体问题高度相关">
<meta property="og:type" content="article">
<meta property="og:title" content="Data Mining 阅读笔记">
<meta property="og:url" content="https://seline02.github.io/2022/09/24/Data-Mining-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="Seline&#39;s blog">
<meta property="og:description" content="第二章 数据预处理 2.1 简介 收集到的数据很可能是非结构化的，需要从其中提取特征，因此需要数据预处理。 数据预处理的几个步骤：  特征提取和可移植性  数据有多个来源，需要集成到单个数据库；有些算法只能使用特定的数据类型，而数据可能包含不同类型的数据，因此需要数据类型的可移植性   数据清洗  删除&#x2F;插补条目   数据消减、选择和转换  数据量减少：通过采样&#x2F;降维 特征选择：和具体问题高度相关">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">
<meta property="article:published_time" content="2022-09-24T11:35:08.000Z">
<meta property="article:modified_time" content="2022-09-28T11:20:23.418Z">
<meta property="article:author" content="Seline">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://seline02.github.io/2022/09/24/Data-Mining-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Data Mining 阅读笔记',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-09-28 19:20:23'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.2.0"><link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">31</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">9</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><hr/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Seline's blog</a></span><div id="menus"><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Data Mining 阅读笔记</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-09-24T11:35:08.000Z" title="发表于 2022-09-24 19:35:08">2022-09-24</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-09-28T11:20:23.418Z" title="更新于 2022-09-28 19:20:23">2022-09-28</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Data Mining 阅读笔记"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="第二章-数据预处理">第二章 数据预处理</h1>
<h2 id="2-1-简介">2.1 简介</h2>
<p>收集到的数据很可能是非结构化的，需要从其中提取特征，因此需要数据预处理。</p>
<p>数据预处理的几个步骤：</p>
<ul>
<li>特征提取和可移植性
<ul>
<li>数据有多个来源，需要集成到单个数据库；有些算法只能使用特定的数据类型，而数据可能包含不同类型的数据，因此需要数据类型的可移植性</li>
</ul>
</li>
<li>数据清洗
<ul>
<li>删除/插补条目</li>
</ul>
</li>
<li>数据消减、选择和转换
<ul>
<li>数据量减少：通过采样/降维</li>
<li>特征选择：和具体问题高度相关</li>
</ul>
</li>
</ul>
<h2 id="2-2-特征提取和可移植性">2.2 特征提取和可移植性</h2>
<p>收集到的数据是原始、非结构化的（raw, unstructed)，需要转换成统一的形式</p>
<h3 id="2-2-1-特征提取">2.2.1 特征提取</h3>
<p>在某些情况下，特征提取与数据类型可移植性的概念密切相关，其中一种类型的低级特征可能转换为另一种类型的高级特征。特征提取的性质取决于数据应用的领域：</p>
<ul>
<li>**传感器数据：**传感器数据通常以大量的低电平信号（low-level signals）收集。有时使用小波变换或傅里叶变换将低电平信号转换为更高级的特征。</li>
<li><strong>图像数据：</strong>
<ul>
<li>原始形式：图像数据被表示为像素</li>
<li>稍高级别：可以使用颜色直方图来表示图像不同部分的特征（直方图只能描述颜色的分布，不能描述数据几何上的信息）</li>
<li>视觉词袋：类比NLP中的词袋模型。用来表示图像的含义。</li>
<li>图像处理中的一个挑战是数据量大</li>
</ul>
</li>
<li><strong>Web日志</strong>：Web日志通常以预先指定的格式表示为文本字符串。由于这些日志中的字段被明确指定和分隔，因此将Web访问日志转换为分类和数字属性的多维表示相对比较容易。</li>
<li><strong>网络流量</strong>：网络数据包的特征用于分析入侵等。可以从这些数据包中提取各种特征，例如传输的字节数、使用的网络协议等。</li>
<li><strong>文档数据</strong>：文档数据通常是原始和非结构化的。一种方法是删除停用词，词干提取（stemming），并使用词袋模型表示。也可以使用实体抽取。</li>
</ul>
<p>命名实体识别是信息提取的重要子任务。可以用来理解句子和复杂事件的结构。也可以用于填充更传统的关系元素数据库或者更容易分析的原子实体序列。</p>
<h3 id="2-2-2-数据类型可移植性">2.2.2 数据类型可移植性</h3>
<p>数据类型的混合也限制了分析人员使用现成的工具进行处理的能力。在某些情况下移植数据类型确实会丢失表达能力和准确性。理想情况下，最好根据特定的数据类型组合来定制算法以优化结果，但这是耗时的。</p>
<p>数字数据类型是数据挖掘算法中最简单和研究最广泛的数据类型，所以研究如何将不同数据类型转换为数字数据类型尤其有用。</p>
<h4 id="2-2-2-1-数字到分类数据：离散化">2.2.2.1 数字到分类数据：离散化</h4>
<p>离散化过程将数字属性的范围划分为φ个范围。然后，根据原始属性所在的范围，假定该属性包含从1到φ的φ个不同分类标注值。例如，考虑年龄属性。人们可以创建范围[0,10]，[11,20]，[21,30]等等。范围[11,20]中任何记录的符号值为“2”，范围[21,30]中记录的符号值为“3”。由于这些是符号值，因此在值“2”和“3”之间不会进行排序。此外，一个范围内的变化在离散化之后是不可区分的。因此，离散化过程的确会失去一些挖掘过程的信息。</p>
<p>离散化的一个挑战是数据可能在不同的时间间隔内不均匀分布。例如工资，使用相同大小的范围可能对区分不同数据段不是很有帮助。</p>
<p>离散化过程可以根据应用特定目标以各种方式执行：</p>
<p>放回/不放回</p>
<h4 id="3-2-1-2-高维数据的影响">3.2.1.2 高维数据的影响</h4>
<img src="image-20220927192124598.png" alt="image-20220927192124598" style="zoom:50%;">
<p>反映从原点出发的最大距离和最小距离之间差异的程度</p>
<h4 id="3-2-1-3-局部不相关特征的影响">3.2.1.3 局部不相关特征的影响</h4>
<p>The additive effffects of the natural variations in the many attribute values may be quite signifificant.没理解</p>
<p>对于一个包含糖尿病患者的集合，特定的某些属性对于距离的计算更加重要，例如血糖水平。另一方面，对于包含癫痫病患者的集合，另一组特征会更加重要。</p>
<p>这里需要理解的关键点是，和距离计算相关的几个特定特征可能有时会对于被比较的特定对象对非常敏感。在预处理过程中全局地筛选特征子集不能解决这个问题，因为特征是否相关是由被考虑的对象对<em>局部地</em>决定的。全局来说，所有特征可能都是相关的。 （没理解）</p>
<p>当许多特征不相关时，不相关特征的加性噪声效果有时可能会表现为距离值的集中。在任意情况下，这样的不相关的特征总是会在距离计算中引入误差。因为高维数据集经常包含各种特征，许多是不相关的，像L2−范数这样使用平方和的方式计算距离，其加性效果会非常具有破坏性。</p>
<h4 id="3-2-1-4-不同-l-p-范数的影响">3.2.1.4 不同 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mi>p</mi></msub><mo>−</mo></mrow><annotation encoding="application/x-tex">L_p-</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord">−</span></span></span></span>范数的影响</h4>
<p>无穷范数：表示两个对象最不相似的那个维度。研究相似度的问题，如果两个对象在999个属性上有相似的值，那么这两个对象应该被定义为非常相似。但是，单独的一个不相关的属性，如果两个对象在这个属性上相差很多，那么在无穷范数L∞的度量下，这两个对象的距离会被拉的很远。换句话说，局部的相似的属性被无穷范数L∞忽视了。总体上，对于较大的pp值，Lp−范数都是这样：不相关的属性被强调了。</p>
<h4 id="3-2-1-5-基于匹配的相似度计算">3.2.1.5 基于匹配的相似度计算</h4>
<p>由于不相关特征的噪声变化，一对语义相似的对象可能包含不相似的特征值（在沿着该维度的一个标准偏差的水平）。（比如有一个服从于高斯分布的噪声？）</p>
<p>欧几里德度量（通常是Lp−范数）通过使用属性值差异的平方和来达到完全相反的效果。结果，来自不相关属性的“噪声”分量主宰了计算并掩盖了大量相关属性的相似效应。无穷范数是一个极端的例子</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">d</span></span></span></span> 维样本，每个维度 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span></span></span></span>，样本被均分成 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>k</mi><mi>d</mi></msub></mrow><annotation encoding="application/x-tex">k_d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 份</p>
<img src="image-20220927204351968.png" alt="image-20220927204351968" style="zoom:50%;">
<p>这种方法忽略了遥远维度上的不相似程度，因为它常常受噪声支配。</p>
<p>关于d的kd的选择确保了对于低维应用，它通过使用大部分维度而与Lp−范数有一些相似之处;而对于高维应用，它通过在匹配属性上使用相似性来表现类似于类似于文本域的相似性函数。距离函数也被证明对原型最近邻分类应用更有效。（低维的话，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>k</mi><mi>d</mi></msub></mrow><annotation encoding="application/x-tex">k_d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 设小一点，极端一点，设为样本数，那么肯定在同一个桶中，那么一对数据的每个维度都会被计算相似度，类似于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">L_p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span> 范数；高维的话，有些维度噪声大，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>k</mi><mi>d</mi></msub></mrow><annotation encoding="application/x-tex">k_d</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03148em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> 设大一点，那么只要在某个维度上差异比较大，就不会在一个桶中，这个就不会被计算相似度）</p>
<h4 id="3-2-1-6-数据分布的影响">3.2.1.6 数据分布的影响</h4>
<img src="image-20220927210601133.png" alt="image-20220927210601133" style="zoom:50%;">
<p>图中A,B到O是等距的，但OA轴方差大，OB轴方差小，从统计上来说OA的距离应该小于OB</p>
<p>马氏距离：只需要将变量<code>按照主成分进行旋转</code>，让维度间相互<strong>独立</strong>，然后进行<code>标准化</code>，让维度<strong>同分布</strong>就OK了</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/46626607">https://zhuanlan.zhihu.com/p/46626607</a></p>
<h4 id="3-2-1-7-非线性分布：isomap">3.2.1.7 非线性分布：ISOMAP</h4>
<img src="image-20220927214157086.png" alt="image-20220927214157086" style="zoom:50%;">
<p>从欧式距离来说AB更接近，但从全局的数据分布来说不是</p>
<p>直观的基本原理是，只有短暂的点到点跳转才能准确测量该点生成过程中的微小变化。因此，点到点跳跃的总和反映了比点之间的直线距离更准确地从一点到另一（远）点的总变化（距离）。这种距离被称为测地距离。</p>
<p>隐含的假设是，非线性分布是符合<em>局部</em>欧几里得的，但<em>总体来说</em>是非欧几里得的</p>
<p>embedding还没看</p>
<p>先用ISOMAP，再用MDS低维嵌入？</p>
<p>通常，高维数据沿着非线性低维形状排列，这也称为<em>流形</em>。这些流形可以被“扁平化”成为一种新的表示形式，可以有效地使用公制距离。</p>
<h4 id="3-2-1-8-局部数据分布的影响">3.2.1.8 局部数据分布的影响</h4>
<img src="image-20220927224217256.png" alt="image-20220927224217256" style="zoom:50%;">
<p>CD和AB分别的绝对距离一样，但考虑到局部的数据分布，CD的距离应该大于AB</p>
<img src="image-20220927225053444.png" alt="image-20220927225053444" style="zoom:50%;">
<p>所在轴的方差不同，实际上CD间的距离应该比AB间的距离大（可用马氏距离）</p>
<p>Shared Nearest-Neighbor Similarity（针对的是图a的问题，局部数据分布不同）：这个度量是局部敏感的，因为它取决于公共<em>邻居</em>的数量，而不取决于距离的绝对值。</p>
<p>Shared nearest-neighbor methods can be used to defifine a similarity graph：两个点如果有至少一个共享邻居的话，它们之间就连一条边。基于相似图的方法几乎总是局部敏感的，因为它们局限于k−最近邻分布。</p>
<p>Generic Methods：使用各种聚类方法将数据划分为局部区域。在对中的每个对象属于不同区域的情况下，可以使用全局分布，或者可以使用两个局部区域来计算平均值。如果是同一个区域，用局部的马氏距离。另一个问题是算法的第一步（分区过程）本身需要一个用于聚类的距离的概念。</p>
<h4 id="3-2-1-9-计算考虑">3.2.1.9 计算考虑</h4>
<p>For example, methods such as ISOMAP are computationally expensive and hard to implement for very large data sets because these methods scale with at least the <strong>square of the data size</strong>. 例如，像ISOMAP这样的方法计算起来很复杂，而且对于非常大的数据集很难实现，因为这些方法至少按照数据大小的平方进行缩放。     为什么？</p>
<p>新样本不好映射到低维空间（西瓜书）</p>
<h3 id="3-2-2-分类数据">3.2.2 分类数据</h3>
<p>Distance functions are naturally computed as functions of value difffferences along dimensions in <strong>numeric data</strong>, which is ordered. 这个有序指的是空间上的顺序？</p>
<p>分类数据：二值化</p>
<p>对于分类数据的情况，使用相似性函数而不是距离函数更常见，因为离散值可以更自然地匹配。</p>
<img src="image-20220927234301659.png" alt="image-20220927234301659" style="zoom:50%;">
<p>最简单的选择是当xi=yi时将S(xi,yi)设置为1，否则设置0。这也被称为重叠(overlap)(overlap)度量。这一措施的主要缺点是它没有考虑不同属性之间的相对频率。</p>
<p>这一措施的主要缺点是它没有考虑不同属性之间的相对频率。</p>
<p>例如，考虑一个分类属性，其中99％的记录属性值为“正常”，其余记录为“癌症”或“糖尿病”。显然，如果两个记录对这个变量有一个“正常”的值，那么这并没有提供关于相似性的统计意义上的重要信息，因为大多数的对都可能只是碰巧显示了这个模式。但是，如果这两个记录具有与此相匹配的“癌症”或“糖尿病”值，那么它提供了相似性的重要统计证据。这个论点与之前关于全局数据分布重要性的论点类似。<strong>异常的异同在统计上比那些常见的更重要。</strong></p>
<p>在分类数据的情况下，数据集的<em>总体统计特性</em>应该用于计算相似性。这类似于使用马氏距离如何使用全局统计数据更准确地计算相似性。这个想法是，对一个分类属性的异常值的匹配应该比经常出现的值的权重更大。</p>
<p>类似于文本中的IDF（逆文档频率），分类数据用逆出现频率（inverse occurrence frequency）来度量</p>
<img src="image-20220928105318845.png" alt="image-20220928105318845" style="zoom:50%;">
<p>变体：Goodall measure</p>
<p>a higher similarity value is assigned to a match when the value is infrequent</p>
<img src="image-20220928111345131.png" alt="image-20220928111345131" style="zoom:50%;">
<h3 id="3-2-3-混合定量和分类数据">3.2.3 混合定量和分类数据</h3>
<img src="image-20220928112037998.png" alt="image-20220928112037998" style="zoom:50%;">
<p>缺少邻域知识的前提下（不知道哪一种数据更重要）， <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">λ</span></span></span></span> 可以取全部属性中数值型属性的占比</p>
<p>此外，数值数据中的接近度通常使用距离函数而不是相似度函数来计算。但是，距离值也可以转换为相似度值。对于dist的距离值，常用的方法是使用产生相似度值为1/(1+dist)的核映射（不懂）</p>
<p>normalization：</p>
<img src="image-20220928113942957.png" alt="image-20220928113942957" style="zoom:50%;">
<h2 id="3-3-文本相似性度量">3.3 文本相似性度量</h2>
<p>只用 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mi>p</mi></msub><mo>−</mo></mrow><annotation encoding="application/x-tex">L_p-</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mord">−</span></span></span></span> 范数来度量文本之间的距离，会受文本长度的影响</p>
<p>可以用余弦相似度，计算两个文档之间的角度</p>
<img src="image-20220928132923078.png" alt="image-20220928132923078" style="zoom:50%;">
<p>上述措施仅使用属性之间的原始频率。可用全局统计量改进。例如，如果两个文档匹配一个不常见的单词，则它比两个文档匹配一个常见单词的情况更具有相似性。</p>
<p>方法一：逆文档频率：inverse document frequency <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><msub><mi>d</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">id_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord mathdefault">i</span><span class="mord"><span class="mord mathdefault">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></p>
<img src="image-20220928133156159.png" alt="image-20220928133156159" style="zoom:50%;">
<p>随着第 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span></span></span></span> 个词在文档中出现频率增加而减小</p>
<p>方法二：在相似性计算之前，可以对频率应用一个如平方根或对数的衰减函数f(⋅)。确保单个词的过度存在不会影响相似性度量。</p>
<img src="image-20220928133617475.png" alt="image-20220928133617475" style="zoom:50%;">
<p>因此，可以如下定义第i个词的归一化频率h(xi):</p>
<img src="image-20220928133757784.png" alt="image-20220928133757784" style="zoom:50%;">
<img src="image-20220928133840356.png" alt="image-20220928133840356" style="zoom:50%;">
<h3 id="3-3-1-二进制和集合数据">3.3.1 二进制和集合数据</h3>
<p>Jaccard 系数：稀疏二进制数据集。它可以被认为是文本数据的一个特殊情况，其中词频是0或1。</p>
<img src="image-20220928140112020.png" alt="image-20220928140112020" style="zoom:50%;">
<p>非对称，比起0值更让注重1值</p>
<p>M11表示A和B对应位都是1的属性的数量</p>
<p>M10表示A中为1，B中对应位为0的总数量</p>
<p>M01表示A中为0，B中对应位为1的总数量</p>
<p>M00表示对应位都为0的总数量</p>
<img src="https://img-blog.csdn.net/20180119101008236?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMjgzNjM1NA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="img" style="zoom:80%;">
<img src="image-20220928140248374.png" alt="image-20220928140248374" style="zoom:50%;">
<p>这个式子和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mo stretchy="false">(</mo><mover accent="true"><mi>X</mi><mo>ˉ</mo></mover><mo separator="true">,</mo><mover accent="true"><mi>Y</mi><mo>ˉ</mo></mover><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">J(\bar{X},\bar{Y})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.07011em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.09618em;">J</span><span class="mopen">(</span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8201099999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span></span></span><span style="top:-3.25233em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.16666em;"><span class="mord">ˉ</span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8201099999999999em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.22222em;">Y</span></span></span><span style="top:-3.25233em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;"><span class="mord">ˉ</span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span> 第一个等号后的式子一样</p>
<h2 id="3-4-时间相似性度量">3.4 时间相似性度量</h2>
<p>离散序列数据并不总是具有时序性的，因为上下文属性可能表示位置</p>
<ol start="2">
<li>Temporal (contextual) attribute translation: 没看懂</li>
</ol>
<h4 id="3-4-1-2-l-p-范数">3.4.1.2 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mi>p</mi></msub></mrow><annotation encoding="application/x-tex">L_p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.969438em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">p</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span>-范数</h4>
<p>在p=2的特殊情况下，如果在表示中保留了大部分较大的小波系数，则可以用小波表示获得精确的距离计算。（不懂）</p>
<h4 id="3-4-1-4-基于窗口的方法">3.4.1.4  基于窗口的方法</h4>
<p>对于长时间序列，全局匹配变得越来越不可能。唯一合理的选择是使用窗口来测量分段的相似度。（长时间序列点对点匹配太复杂，所以换成窗口对窗口匹配？）</p>
<h3 id="3-4-2-离散序列相似性度量">3.4.2 离散序列相似性度量</h3>
<p>离散序列数据的应用领域通常是一对一映射不存在的。</p>
<h4 id="3-4-2-2-最长的公共子序列">3.4.2.2 最长的公共子序列</h4>
<p>长度较长的子序列表示字符串之间的匹配程度更高。</p>
<p>与编辑距离不同，最长的公共子序列（LCSS）是一个相似性函数，因为较高的值表示较大的相似性。</p>
<h2 id="3-5-图的相似性度量">3.5 图的相似性度量</h2>
<h3 id="3-5-1-单个图中两个节点之间的相似性">3.5.1 单个图中两个节点之间的相似性</h3>
<p>通常，<em>距离</em>函数与成本一起工作，而<em>相似</em>函数与权重一起工作。</p>
<h4 id="3-5-1-1-基于结构距离的测量">3.5.1.1 基于结构距离的测量</h4>
<p>基于结构距离的测量不会显著增加一对节点之间路径的多样性，因为它们只关注原始结构距离。（没有考虑一对节点之间是否有多条路径（路径数越多越相关））</p>
<h4 id="3-5-1-2-随机行走相似度">3.5.1.2 随机行走相似度</h4>
<p>此外，在任何给定的节点处，允许以被称为<em>重新启动概率</em>的概率“跳回”到源节点s。这将导致严重偏向源节点的概率分布。与s更类似的节点访问的概率较高。这种方法将很好地适应图3.10所示的情况，因为将更频繁地访问B。</p>
<p>PageRank/SimRank没看</p>
<h3 id="3-5-2-两个图之间的相似性">3.5.2 两个图之间的相似性</h3>
<p>图同构问题：NP-hard</p>
<h2 id="3-7-总结">3.7 总结</h2>
<p>The determination of time-series and discrete-sequence similarity measures is closely related because the latter can be considered the categorical version of the former.</p>
<p>不懂</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://seline02.github.io">Seline</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://seline02.github.io/2022/09/24/Data-Mining-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">https://seline02.github.io/2022/09/24/Data-Mining-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://seline02.github.io" target="_blank">Seline's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/09/26/Back-Propagation/"><img class="prev-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Back Propagation</div></div></a></div><div class="next-post pull-right"><a href="/2022/09/24/%E6%8E%A7%E5%88%B6%E7%90%86%E8%AE%BA%E9%83%A8%E5%88%86%E7%AC%94%E8%AE%B0/"><img class="next-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">控制理论部分网课笔记</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Seline</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">31</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">9</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">1.</span> <span class="toc-text">第二章 数据预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1-%E7%AE%80%E4%BB%8B"><span class="toc-number">1.1.</span> <span class="toc-text">2.1 简介</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2-%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%E5%92%8C%E5%8F%AF%E7%A7%BB%E6%A4%8D%E6%80%A7"><span class="toc-number">1.2.</span> <span class="toc-text">2.2 特征提取和可移植性</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-1-%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96"><span class="toc-number">1.2.1.</span> <span class="toc-text">2.2.1 特征提取</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-2-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E5%8F%AF%E7%A7%BB%E6%A4%8D%E6%80%A7"><span class="toc-number">1.2.2.</span> <span class="toc-text">2.2.2 数据类型可移植性</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-2-1-%E6%95%B0%E5%AD%97%E5%88%B0%E5%88%86%E7%B1%BB%E6%95%B0%E6%8D%AE%EF%BC%9A%E7%A6%BB%E6%95%A3%E5%8C%96"><span class="toc-number">1.2.2.1.</span> <span class="toc-text">2.2.2.1 数字到分类数据：离散化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-1-2-%E9%AB%98%E7%BB%B4%E6%95%B0%E6%8D%AE%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-number">1.2.2.2.</span> <span class="toc-text">3.2.1.2 高维数据的影响</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-1-3-%E5%B1%80%E9%83%A8%E4%B8%8D%E7%9B%B8%E5%85%B3%E7%89%B9%E5%BE%81%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-number">1.2.2.3.</span> <span class="toc-text">3.2.1.3 局部不相关特征的影响</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-1-4-%E4%B8%8D%E5%90%8C-l-p-%E8%8C%83%E6%95%B0%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-number">1.2.2.4.</span> <span class="toc-text">3.2.1.4 不同 Lp−L_p-Lp​−范数的影响</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-1-5-%E5%9F%BA%E4%BA%8E%E5%8C%B9%E9%85%8D%E7%9A%84%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%AE%A1%E7%AE%97"><span class="toc-number">1.2.2.5.</span> <span class="toc-text">3.2.1.5 基于匹配的相似度计算</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-1-6-%E6%95%B0%E6%8D%AE%E5%88%86%E5%B8%83%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-number">1.2.2.6.</span> <span class="toc-text">3.2.1.6 数据分布的影响</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-1-7-%E9%9D%9E%E7%BA%BF%E6%80%A7%E5%88%86%E5%B8%83%EF%BC%9Aisomap"><span class="toc-number">1.2.2.7.</span> <span class="toc-text">3.2.1.7 非线性分布：ISOMAP</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-1-8-%E5%B1%80%E9%83%A8%E6%95%B0%E6%8D%AE%E5%88%86%E5%B8%83%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-number">1.2.2.8.</span> <span class="toc-text">3.2.1.8 局部数据分布的影响</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-1-9-%E8%AE%A1%E7%AE%97%E8%80%83%E8%99%91"><span class="toc-number">1.2.2.9.</span> <span class="toc-text">3.2.1.9 计算考虑</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-2-%E5%88%86%E7%B1%BB%E6%95%B0%E6%8D%AE"><span class="toc-number">1.2.3.</span> <span class="toc-text">3.2.2 分类数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-3-%E6%B7%B7%E5%90%88%E5%AE%9A%E9%87%8F%E5%92%8C%E5%88%86%E7%B1%BB%E6%95%B0%E6%8D%AE"><span class="toc-number">1.2.4.</span> <span class="toc-text">3.2.3 混合定量和分类数据</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-3-%E6%96%87%E6%9C%AC%E7%9B%B8%E4%BC%BC%E6%80%A7%E5%BA%A6%E9%87%8F"><span class="toc-number">1.3.</span> <span class="toc-text">3.3 文本相似性度量</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-1-%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%92%8C%E9%9B%86%E5%90%88%E6%95%B0%E6%8D%AE"><span class="toc-number">1.3.1.</span> <span class="toc-text">3.3.1 二进制和集合数据</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-4-%E6%97%B6%E9%97%B4%E7%9B%B8%E4%BC%BC%E6%80%A7%E5%BA%A6%E9%87%8F"><span class="toc-number">1.4.</span> <span class="toc-text">3.4 时间相似性度量</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-4-1-2-l-p-%E8%8C%83%E6%95%B0"><span class="toc-number">1.4.0.1.</span> <span class="toc-text">3.4.1.2 LpL_pLp​-范数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-4-1-4-%E5%9F%BA%E4%BA%8E%E7%AA%97%E5%8F%A3%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-number">1.4.0.2.</span> <span class="toc-text">3.4.1.4  基于窗口的方法</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-2-%E7%A6%BB%E6%95%A3%E5%BA%8F%E5%88%97%E7%9B%B8%E4%BC%BC%E6%80%A7%E5%BA%A6%E9%87%8F"><span class="toc-number">1.4.1.</span> <span class="toc-text">3.4.2 离散序列相似性度量</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-4-2-2-%E6%9C%80%E9%95%BF%E7%9A%84%E5%85%AC%E5%85%B1%E5%AD%90%E5%BA%8F%E5%88%97"><span class="toc-number">1.4.1.1.</span> <span class="toc-text">3.4.2.2 最长的公共子序列</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-5-%E5%9B%BE%E7%9A%84%E7%9B%B8%E4%BC%BC%E6%80%A7%E5%BA%A6%E9%87%8F"><span class="toc-number">1.5.</span> <span class="toc-text">3.5 图的相似性度量</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-5-1-%E5%8D%95%E4%B8%AA%E5%9B%BE%E4%B8%AD%E4%B8%A4%E4%B8%AA%E8%8A%82%E7%82%B9%E4%B9%8B%E9%97%B4%E7%9A%84%E7%9B%B8%E4%BC%BC%E6%80%A7"><span class="toc-number">1.5.1.</span> <span class="toc-text">3.5.1 单个图中两个节点之间的相似性</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-5-1-1-%E5%9F%BA%E4%BA%8E%E7%BB%93%E6%9E%84%E8%B7%9D%E7%A6%BB%E7%9A%84%E6%B5%8B%E9%87%8F"><span class="toc-number">1.5.1.1.</span> <span class="toc-text">3.5.1.1 基于结构距离的测量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-5-1-2-%E9%9A%8F%E6%9C%BA%E8%A1%8C%E8%B5%B0%E7%9B%B8%E4%BC%BC%E5%BA%A6"><span class="toc-number">1.5.1.2.</span> <span class="toc-text">3.5.1.2 随机行走相似度</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-5-2-%E4%B8%A4%E4%B8%AA%E5%9B%BE%E4%B9%8B%E9%97%B4%E7%9A%84%E7%9B%B8%E4%BC%BC%E6%80%A7"><span class="toc-number">1.5.2.</span> <span class="toc-text">3.5.2 两个图之间的相似性</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-7-%E6%80%BB%E7%BB%93"><span class="toc-number">1.6.</span> <span class="toc-text">3.7 总结</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/09/29/AI%E7%AE%97%E6%B3%95%E5%B7%A5%E7%A8%8B%E5%B8%88%E6%89%8B%E5%86%8C%E7%AC%94%E8%AE%B0/" title="AI算法工程师手册笔记"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="AI算法工程师手册笔记"/></a><div class="content"><a class="title" href="/2022/09/29/AI%E7%AE%97%E6%B3%95%E5%B7%A5%E7%A8%8B%E5%B8%88%E6%89%8B%E5%86%8C%E7%AC%94%E8%AE%B0/" title="AI算法工程师手册笔记">AI算法工程师手册笔记</a><time datetime="2022-09-29T07:15:39.000Z" title="发表于 2022-09-29 15:15:39">2022-09-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/09/28/%E5%B0%8F%E6%B3%A2%E5%8F%98%E6%8D%A2/" title="小波变换"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="小波变换"/></a><div class="content"><a class="title" href="/2022/09/28/%E5%B0%8F%E6%B3%A2%E5%8F%98%E6%8D%A2/" title="小波变换">小波变换</a><time datetime="2022-09-28T14:32:01.000Z" title="发表于 2022-09-28 22:32:01">2022-09-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/09/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B9%B3%E5%8F%B0%E5%8F%8A%E5%BA%94%E7%94%A8%E7%AC%94%E8%AE%B0/" title="深度学习平台及应用笔记"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="深度学习平台及应用笔记"/></a><div class="content"><a class="title" href="/2022/09/26/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B9%B3%E5%8F%B0%E5%8F%8A%E5%BA%94%E7%94%A8%E7%AC%94%E8%AE%B0/" title="深度学习平台及应用笔记">深度学习平台及应用笔记</a><time datetime="2022-09-26T12:20:09.000Z" title="发表于 2022-09-26 20:20:09">2022-09-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/09/26/Back-Propagation/" title="Back Propagation"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Back Propagation"/></a><div class="content"><a class="title" href="/2022/09/26/Back-Propagation/" title="Back Propagation">Back Propagation</a><time datetime="2022-09-26T10:43:54.000Z" title="发表于 2022-09-26 18:43:54">2022-09-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/09/24/Data-Mining-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" title="Data Mining 阅读笔记"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Data Mining 阅读笔记"/></a><div class="content"><a class="title" href="/2022/09/24/Data-Mining-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" title="Data Mining 阅读笔记">Data Mining 阅读笔记</a><time datetime="2022-09-24T11:35:08.000Z" title="发表于 2022-09-24 19:35:08">2022-09-24</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By Seline</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>