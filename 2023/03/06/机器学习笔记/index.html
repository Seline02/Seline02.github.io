<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>机器学习笔记 | Seline's blog</title><meta name="author" content="Seline"><meta name="copyright" content="Seline"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="第一章 绪论 假设空间 学习过程是在所有假设组成的空间中进行搜索的过程 目标：找到与训练集“匹配”的假设   版本空间：与训练集一致的假设集合 归纳偏好：机器学习算法在学习过程中对某种类型假设的偏好 任何一个有效的机器学习算法必有其偏好 奥卡姆剃刀原则：若有多个假设与观察一致，则选最简单的那个 NFL 定理：一个算法 $\mathcal{E}_a$ 若在某些问题上比另一个算法 $\mathcal{">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习笔记">
<meta property="og:url" content="https://seline02.github.io/2023/03/06/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="Seline&#39;s blog">
<meta property="og:description" content="第一章 绪论 假设空间 学习过程是在所有假设组成的空间中进行搜索的过程 目标：找到与训练集“匹配”的假设   版本空间：与训练集一致的假设集合 归纳偏好：机器学习算法在学习过程中对某种类型假设的偏好 任何一个有效的机器学习算法必有其偏好 奥卡姆剃刀原则：若有多个假设与观察一致，则选最简单的那个 NFL 定理：一个算法 $\mathcal{E}_a$ 若在某些问题上比另一个算法 $\mathcal{">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">
<meta property="article:published_time" content="2023-03-06T08:49:45.000Z">
<meta property="article:modified_time" content="2023-07-05T07:35:24.828Z">
<meta property="article:author" content="Seline">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://seline02.github.io/2023/03/06/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '机器学习笔记',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-07-05 15:35:24'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.2.0"><link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">25</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><hr/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Seline's blog</a></span><div id="menus"><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">机器学习笔记</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-03-06T08:49:45.000Z" title="发表于 2023-03-06 16:49:45">2023-03-06</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-07-05T07:35:24.828Z" title="更新于 2023-07-05 15:35:24">2023-07-05</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="机器学习笔记"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="第一章-绪论"><a href="#第一章-绪论" class="headerlink" title="第一章 绪论"></a>第一章 绪论</h1><ul>
<li>假设空间<ul>
<li>学习过程是在所有假设组成的空间中进行搜索的过程</li>
<li>目标：找到与训练集“匹配”的假设</li>
</ul>
</li>
<li>版本空间：与训练集一致的假设集合</li>
<li>归纳偏好：机器学习算法在学习过程中对某种类型假设的偏好<ul>
<li>任何一个有效的机器学习算法必有其偏好</li>
<li>奥卡姆剃刀原则：若有多个假设与观察一致，则选最简单的那个</li>
<li>NFL 定理：一个算法 $\mathcal{E}_a$ 若在某些问题上比另一个算法 $\mathcal{E}_b$ 好，必存在另一些问题，$\mathcal{E}_b$ 比 $\mathcal{E}_a$ 好<ul>
<li>前提：所有“问题”出现的机会相同、或所有问题同等重要</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="第二章-模型评估与选择"><a href="#第二章-模型评估与选择" class="headerlink" title="第二章 模型评估与选择"></a>第二章 模型评估与选择</h1><h3 id="2-1-经验误差与过拟合"><a href="#2-1-经验误差与过拟合" class="headerlink" title="2.1 经验误差与过拟合"></a>2.1 经验误差与过拟合</h3><ul>
<li>学习器<strong>在训练集上的误差</strong>称为“训练误差”或“经验误差”，<strong>在新样本上的误差</strong>称为“泛化误差”</li>
<li>机器学习面临的问题通常是NP难甚至更难，而有效的学习算法必然是在多项式时间内运行完成，若可彻<strong>底避免过拟合</strong>，则通过<strong>经验误差最小化</strong>就能获得<strong>最优解</strong>，这就意味着我们<strong>构造性地证明了“P=NP”</strong>；因此，只要相信“P≠NP”，过拟合就不可避免</li>
</ul>
<h3 id="2-2-评估方法"><a href="#2-2-评估方法" class="headerlink" title="2.2 评估方法"></a>2.2 评估方法</h3><ul>
<li><p>留出法</p>
<ul>
<li>留出法（hold-out）：直接将数据集 $D$ 划分为两个<strong>互斥的集合</strong>，其中一个集合作为训练集 $S$，另一个作为测试集 $T$</li>
<li>分层采样：保留<strong>类别比例</strong>的采样方式</li>
</ul>
</li>
<li><p>使用留出法时，一般要采用若干次随机划分、重复进行实验评估后取平均值作为留出法的评估结果。同时可得估计结果的标准差</p>
<ul>
<li><strong>“偏差-方差”窘境</strong>：<ul>
<li><strong>测试集小</strong>时，评估结果的<strong>方差较大</strong>；<strong>训练集小</strong>时，评估结果的<strong>偏差较大</strong></li>
</ul>
</li>
</ul>
</li>
<li><p>交叉验证法</p>
<ul>
<li>将数据集划分成 $k$ 个<strong>大小相似的互斥子集</strong>，每个子集尽可能保持<strong>数据分布的一致性</strong>，即从 $D$ 中<strong>分层采样</strong>得到</li>
<li>为减小因划分不同而引入的差别，$k$ 折交叉验证通常要随机使用不同的<strong>划分重复 $p$ 次</strong>，最终评估结果是 $p$ 次 $k$ 折交叉验证结果的<strong>均值</strong>，如“10次10折交叉验证”</li>
<li>“10次10折交叉验证法”与“100次留出法”都是进行了100次训练/测试</li>
<li>特例：留一法（LOO），$k=m$。<strong>实际评估的模型</strong>与<strong>期望评估</strong>的用 $D$ 训练出的模型很相似。因此，留一法的评估结果往往被认为比较准确。但计算开销大。</li>
</ul>
</li>
<li><p>自助法（bootstrapping）</p>
<ul>
<li>可重复采样/有放回采样，使训练集大小和数据集大小一样</li>
<li>始终不被采到的概率 $\lim_{m\rightarrow ∞}(1-\frac{1}{m})^m\rightarrow \frac{1}{e}=0.368$</li>
<li>$D’$ 作训练集，$D\backslash D’$ 作测试集，<strong>实际评估的模型</strong>与<strong>期望评估</strong>的模型都使用 $m$ 个数据样本</li>
<li>约 $1/3$ 没在训练集出现的用于测试，测试结果称“<strong>包外估计</strong>”</li>
<li>常用于集成学习产生基分类器；但改变初始数据集分布，引入估计偏差</li>
</ul>
</li>
<li><p><strong>数据量足够</strong>：留出法/交叉验证法；<strong>数据集小、难以划分训练/测试集</strong>：自助法</p>
</li>
<li><p>模型选择完成后，学习算法和参数配置已选定，此时应该用数据集 $D$ （训练集+验证集）重新训练模型。这个模型在训练过程中使用了所有 $m$ 个样本，这才是最终模型</p>
</li>
<li><p><strong>算法参数</strong>：人为指定，候选；<strong>模型参数</strong>：学习来产生多个候选模型（神经网络在不同轮数停止训练）</p>
</li>
</ul>
<h3 id="2-3-性能度量"><a href="#2-3-性能度量" class="headerlink" title="2.3 性能度量"></a>2.3 性能度量</h3><ul>
<li>查准率 $P$（准确率，precision）：被学习器预测为<strong>正例</strong>的样例中有多大比例是<strong>真正例</strong>。（挑出的西瓜中有多少比例是好瓜）<ul>
<li>$P=\frac{TP}{TP+FP}$</li>
</ul>
</li>
<li>查全率 $R$（召回率，recall）：所有<strong>正例</strong>当中有多大比例被学习器预测为<strong>正例</strong>。（所有好瓜中有多少比例被挑了出来）<ul>
<li>$R=\frac{TP}{TP+FN}$</li>
</ul>
</li>
<li>查准率和查全率是一对矛盾的度量。</li>
<li><strong>P-R曲线</strong>常是<strong>非单调、不平滑的</strong>，在很多局部有上下波动。通常<strong>不会</strong>取到(1,0)点，此时所有样本判为正例，且正例占比为0. 起点是（0，0）</li>
<li>一个学习器的P-R曲线被另一个学习器的曲线完全包住，可断言后者性能优于前者</li>
<li>平衡点 BEP（break-event point），查准率=查全率时的取值。综合考虑查准率、查全率的性能度量</li>
<li>F1度量：$F1=\frac{2×P×R}{P+R}=\frac{2×TP}{样例总数+TP-TN}$<ul>
<li>基于调和平均：$\frac{1}{F_1}=\frac{1}{2}\cdot(\frac{1}{P}+\frac{1}{R})$。调和平均倾向于靠近两数中较小的那一个，<strong>更重视较小值</strong>。高 F1，能保证精确率和召回率都比较高</li>
<li>$F_\beta$ 加权调和平均：$\frac{1}{F_\beta}=\frac{1}{1+\beta^2}\cdot(\frac{1}{P}+\frac{\beta^2}{R})$。$\beta&gt;1$ 时查全率有更大影响；$\beta&lt;1$ 时查准率有更大影响</li>
</ul>
</li>
<li>macro：先在各混淆矩阵上分别计算出查准率和查全率。记为 $(P_1,R_1),(P_2,R_2),..,(P_n,R_n)$，<strong>再计算平均值</strong><ul>
<li>宏查准率：$macro-P=\frac{1}{n}\sum_{i=1}^n P_i$</li>
<li>宏查全率：$macro-R=\frac{1}{n}\sum_{i=1}^n R_i$</li>
<li>宏F1：$macro-F1=\frac{2×macro-P×macro-R}{macro-P+macro-R}$ </li>
</ul>
</li>
<li>micro：先将各混淆矩阵的对应元素进行<strong>平均</strong>，得到 $TP,FP,TN,FN$ 的平均值，分别记为 $\overline{TP},\overline{FP},\overline{TN},\overline{FN}$，再基于这些平均值计算“微…”<ul>
<li>微查准率：$micro-P=\frac{\overline{TP}}{\overline{TP}+\overline{FP}}$</li>
<li>微查全率：$micro-R=\frac{\overline{TP}}{\overline{TP}+\overline{FN}}$</li>
<li>微F1：$micro-F1=\frac{2×micro-P×micro-R}{micro-P+micro-R}$</li>
</ul>
</li>
</ul>
<ul>
<li><p>截断点，根据分类阈值</p>
<ul>
<li>若更重视”查准率“，可选择排序中靠前的位置进行截断</li>
</ul>
</li>
<li><p>ROC纵轴是”真正例率“，横轴是”假正例率“</p>
<ul>
<li>TPR真正例率，$TPR=\frac{TP}{TP+FN}$，等于查全率（分母是所有正例数量）</li>
<li>FPR假正例率，$FPR=\frac{FP}{TN+FP}$，所有<strong>反例</strong>中有多大比例被预测为<strong>正例</strong>（分母是所有负例数量）</li>
</ul>
</li>
<li><p>ROC曲线</p>
<ul>
<li>点(0,1)对应于将所有正例排在所有反例之前的”理想模型“；点(0,0)是起始点，将分类阈值设为一个不可能取到的超大值，如1；对角线是随机猜测</li>
</ul>
</li>
<li>非减<ul>
<li>变分类阈值时，若新增 $i$ 个假正例，相应的 $x$ 轴坐标就增加 $\frac{i}{m^-}$；若新增 $j$ 个真正例，相应的 $y$ 轴坐标就增加 $\frac{j}{m^+}$</li>
</ul>
</li>
<li>$l_{rank}=\frac{1}{m^+m^-}\sum_{x^+\in D^+}\sum_{x^-\in D^-}(\mathbb{I}(f(x^+)&lt;f(x^-))+\frac{1}{2}\mathbb{I}(f(x^+)=f(x^-)))$。考虑每一对正反例，正例预测值小于反例，则记一个”罚分“，若相等，记0.5个”罚分“。<ul>
<li>$l_{rank}$ 对应的是<strong>ROC曲线之上的面积</strong>；AUC是ROC曲线下的面积，$AUC=1-l_{rank}$ 。</li>
</ul>
</li>
<li>$l_{rank}$ 指从测试集中随机抽取正反例对儿，模型 $f(x)$ ”排序错误“的概率；AUC是…,”排序正确“的概率<ul>
<li>若一个正例在ROC曲线上对应标记点的坐标为(x,y)，则 $x$ 恰是<strong>排序在其之前的反例所占的比例</strong>，即<strong>假正例率</strong></li>
</ul>
</li>
<li>在样本不均衡下，ROC曲线仍能较好评价分类器性能。纵轴只考虑正例，横轴只考虑负例。比如负样本的数量增加到原来的10倍，那TPR不受影响，FPR的各项也是成比例的增加，并不会有太大的变化。<ul>
<li>曲线”包住“可判断哪个学习器优于哪个；也可用AUC（曲线下面积）</li>
</ul>
</li>
</ul>
<ul>
<li>AUC-PR指标比AUC-ROC更具区分性。人们可能会观察到许多分类器的AUC-ROC分数彼此都非常接近，AUC-PR可能是一个更好的评估指标</li>
</ul>
<h3 id="2-5-偏差与方差"><a href="#2-5-偏差与方差" class="headerlink" title="2.5 偏差与方差"></a>2.5 偏差与方差</h3><ul>
<li>偏差-方差分解：用来解释学习算法泛化性能</li>
<li>测试样本 $x$，令 $y_D$ 是 $x$ 在数据集中标记，$y$ 是 $x$ 真实标记；</li>
</ul>
<p>​        $f(x;D)$：训练集 $D$ 上学得模型 $f$ 在 $x$ 上的预测输出；</p>
<p>​        回归任务中，期望预测：$\overline{f}(x)=\mathbb{E}_D[f(x;D)]$；</p>
<p>​        样本数相同的不同训练集产生的方差：$var(x)=\mathbb{E}_D[(f(x;D)-\overline{f}(x))^2]$；</p>
<p>​        噪声是 $\epsilon^2=\mathbb{E}_D[(y_D-y)^2]$，假设噪声期望为0，$\mathbb{E}_D[y_D-y]=0$；</p>
<p>​        偏差（bias）：期望输出与<strong>真实标记</strong>的差别，$bias^2(x)=(\overline{f}(x)-y)^2$；</p>
<p>​        对算法的期望泛化误差进行分解：</p>
<script type="math/tex; mode=display">
\begin{align}
E(f;D)&=\mathbb{E}_D[(f(x;D)-y_D)^2]\\
&= \mathbb{E}_D[(f(x;D)-\overline{f}(x))^2]+(\overline{f}(x)-y)^2+\mathbb{E}_D[(y_D-y)^2]\\
&= bias^2(x)+var(x)+\epsilon^2\\
&=偏差+方差+噪声
\end{align}</script><ul>
<li><strong>偏差</strong>：度量了学习算法的期望预测与<strong>真实结果</strong>的偏离程度<ul>
<li>刻画了学习<strong>算法本身的拟合能力</strong></li>
</ul>
</li>
<li><strong>方差</strong>：度量了同样大小的<strong>训练集的变动</strong>所导致的学习性能的变化<ul>
<li>刻画了<strong>数据扰动</strong>所造成的影响</li>
</ul>
</li>
<li><strong>噪声</strong>：表达了在当前任务上任何学习算法所能达到的<strong>期望泛化误差的下界</strong><ul>
<li>刻画了学习问题本身的难度</li>
</ul>
</li>
<li>偏差-方差分解说明，泛化性能是由<strong>学习算法的能力</strong>、<strong>数据的充分性</strong>、<strong>学习任务本身的难度</strong>所共同决定的</li>
<li><img src="image-20230323113034795.png" alt="image-20230323113034795" style="zoom:50%;"><ul>
<li>偏差-方差窘境</li>
<li>训练不足：拟合能力不强，训练数据扰动不能使学习器显著变化，<strong>偏差主导</strong>泛化错误率；</li>
<li>训练加深，训练数据扰动被学习器学到，<strong>方差主导</strong>泛化错误率；</li>
<li>训练充足后，拟合能力强，训练数据轻微扰动会使学习器显著变化；若训练数据<strong>自身的、非全局特性</strong>被学习器学到，则发生<strong>过拟合</strong></li>
</ul>
</li>
<li>偏置与数据无关，是由模型（的复杂度）决定的（如线性多项式、7阶多项式）</li>
<li>方差 $Var_D(f(x;D))$ 和抽样得到的训练集以及模型两者都有关系</li>
<li>集成方法可以减少偏置和方差</li>
<li>如何降低overfitting？<ul>
<li>正则化 regularization</li>
<li>为什么正则化能防止过拟合？<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/20700829">https://www.zhihu.com/question/20700829</a><ul>
<li>正则化缩小了模型空间，保留了较简单的模型进行挑选</li>
<li>PAC（没看）</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="第三章-线性模型"><a href="#第三章-线性模型" class="headerlink" title="第三章 线性模型"></a>第三章 线性模型</h1><h3 id="3-2-线性回归"><a href="#3-2-线性回归" class="headerlink" title="3.2 线性回归"></a>3.2 线性回归</h3><ul>
<li>若将无序属性连续化，则会不恰当地引入序关系，对后续处理如距离计算等造成误导</li>
<li><p>最小二乘法：基于<strong>均方误差最小化</strong>来进行模型求解</p>
<ul>
<li>加平方的意义：① 平方可以消除误差正负方向上的差异，单纯的只比较长度。② 二次函数方便求导（和绝对值函数相比）</li>
</ul>
</li>
<li><img src="image-20230306180736841.png" alt="image-20230306180736841" style="zoom:50%;"></li>
<li><p>什么是凸函数？（西瓜书上的定义</p>
<ul>
<li>对实数集上的函数，可通过求二阶导数来判别：若二阶导数在区间上<strong>非负</strong>，则称为凸函数；若二阶导数在区间上恒大于0，则称为严格凸函数</li>
</ul>
</li>
<li>对 $w^TAw$ 求导是 $(A+A^T)w$，后面要跟一个 $w$</li>
<li><p>$\hat{w}=argmin_{w}L(w)=(X^TX)^{-1}X^TY=X^{+}Y$</p>
<ul>
<li>$(X^TX)^{-1}X^T$ 称为伪逆</li>
<li>对于非满秩的样本集合，需要对 $X$ 用奇异值分解（SVD），得 $X=U\Sigma V^T$，$X^{+}=V\Sigma^{-1}U^T$</li>
</ul>
</li>
<li><p>几何解释：由样本张成一个 $d$ 维空间，并使 $Y$ 到该空间的距离越近越好。$Y$ 到该空间的投影即误差最小的预测值</p>
<ul>
<li>$Y$ 与其投影之差应与此张成的空间垂直，$X^T\cdot(Y-Xw)=0$，$w=(X^TX)^{-1}X^TY$</li>
</ul>
</li>
</ul>
<ul>
<li>最小二乘估计中隐藏的假设条件：噪声符合高斯分布<ul>
<li>$y=w^Tx+\epsilon$，$\epsilon\sim \mathcal{N}(0,\sigma^2)$，用MLE（极大似然估计），表达式和最小二乘一样</li>
</ul>
</li>
</ul>
<ul>
<li>权重先验也为高斯分布的MAP（最大后验估计）：先验 $w\sim\mathcal{N}(0,\sigma_0^2)$<ul>
<li>$\hat{w}=argmax_w p(w|Y)=argmax_w \log p(Y|w)p(w)=argmin_w[(y-w^Tx)^2+\frac{\sigma^2}{\sigma_0^2}w^Tw]$</li>
<li>这里假设噪声也是高斯分布</li>
</ul>
</li>
</ul>
<ul>
<li>$f(\hat{x_i})=\hat{x_i}^T(X^TX)^{-1}X^Ty$，当属性/变量数超过样例数，$X^TX$ 不满秩，可解出多个 $\hat{w}$，都能使均方误差最小化。选择哪一个解作为输出，将由学习算法的<strong>归纳偏好</strong>决定，常见的做法是引入<strong>正则化</strong>项。</li>
</ul>
<ul>
<li><strong>对数线性回归</strong>，试图让 $e^{w^Tx+b}$ 逼近 $y$. $\ln y=w^Tx+b$ 在形式上仍是线性回归，但实质上已是在求取输入空间到输出空间的<strong>非线性函数映射</strong></li>
<li>广义线性模型：考虑单调可微函数 $g(\cdot)$，令 $y=g^{-1}(w^Tx+b)$。$g(\cdot)$ 是联系函数。对数线性回归是广义线性模型在 $g(\cdot)=\ln(\cdot)$ 时的特例<ul>
<li>广义线性模型的参数估计常通过<strong>加权最小二乘法</strong>或<strong>极大似然法</strong>进行</li>
</ul>
</li>
</ul>
<h3 id="3-3-对数几率回归"><a href="#3-3-对数几率回归" class="headerlink" title="3.3 对数几率回归"></a>3.3 对数几率回归</h3><ul>
<li><p>英文：logistic regression</p>
</li>
<li><p>上面用线性模型进行回归学习，如果要做的是分类任务，用广义线性模型，只需找一个单调可微函数将分类任务的真实标记 $y$ 与线性回归模型的预测值联系起来</p>
</li>
<li><p>分类任务中，为解决阶跃函数作 $g^{-}(\cdot)$ 不可微，用<strong>对数几率函数</strong> $y=\frac{1}{1+e^{-z}}$ 作为 $g^{-}(\cdot)$</p>
</li>
<li>$y=\frac{1}{1+e^{-(w^Tx+b)}}$，变形为 $\ln \frac{y}{1-y}=w^Tx+b$。正例和反例可能性的比值是 $\frac{y}{1-y}$ 称为“<strong>几率</strong>”，反映 $x$ 作为正例的相对可能性</li>
<li><p>$\ln\frac{p(y=1|x)}{p(y=0|x)}=w^Tx+b$</p>
<ul>
<li>$p(y=1|x)=\frac{e^{w^Tx+b}}{1+e^{w^Tx+b}}$；$p(y=0|x)=\frac{1}{1+e^{w^Tx+b}}$</li>
</ul>
</li>
<li><p><strong>对数几率回归</strong>：用<strong>线性回归模型的预测结果</strong>去逼近<strong>真实标记的对数几率</strong></p>
<ul>
<li>一种分类学习方法</li>
<li>优点：直接对分类可能性建模，<strong>无需</strong>事先假设<strong>数据分布</strong>，避免假设分布不准确带来的问题</li>
<li>不仅预测“类别”，而且可得<strong>近似概率预测</strong></li>
<li>对率函数是任意阶可导的凸函数</li>
</ul>
</li>
<li>用极大似然法，对率回归模型最大化“对数似然” $l(w,b)=\sum_{i=1}^{m}\ln p(y_i|x_i;w,b)$</li>
</ul>
<p><img src="image-20230306200019051.png" alt="image-20230306200019051" style="zoom:50%;"></p>
<p>​    <img src="image-20230306200230854.png" alt="image-20230306200230854" style="zoom:50%;"></p>
<ul>
<li>用牛顿法，迭代解更新公式 $\beta’=\beta-(\frac{\partial^2 l(\beta)}{\partial \beta\partial \beta^T})^{-1}\frac{\partial l(\beta)}{\partial\beta}$</li>
<li>南瓜书 3.3.2/3.3.3<ul>
<li>梯度下降法和牛顿法都是迭代求解算法，但在选取第 $t+1$ 个点 $x^{t+1}$ 时所用的策略不同，即迭代公式不同</li>
<li>梯度下降法<ul>
<li>梯度下降法利用“<strong>梯度指向的方向是函数值增大速度最快的方向</strong>”这一特性，每次迭代时朝着梯度的反方向进行，进而实现函数值越迭代越小</li>
<li>每次选取 $x^{t+1}$ 时，只要求通过泰勒公式在 $x^t$ 的邻域内找到一个函数值比其更小的点即可</li>
<li>需要判断当前点是否使得函数取到了最小值。可以预先设定一个极小的阈值 $\epsilon$，当某次迭代造成的函数值波动已经小于 $\epsilon$ 时，即 $|f(x^{t+1})-f(x^t)|&lt;\epsilon$，便可以近似地认为此时 $f(x^{t+1})$ 取到了最小值</li>
</ul>
</li>
<li>牛顿法则期望在此基础上，$x^{t+1}$ 还必须是 $x^t$ 的邻域内的极小值点。对泰勒二阶展示求导 $x^{t+1}=x^t-[\nabla^2 f(x^t)]^{-1}\nabla f(x^t)$。<ul>
<li>牛顿法每次迭代要算<strong>Hessian矩阵的逆矩阵</strong>，计算量大；改成求计算量更低的近似逆矩阵，即“拟牛顿法”</li>
<li>多元函数取到极值点的必要条件是其梯度等于零向量，迭代公式是根据极值点的必要条件推导而得，因此并不保证一定是极小值点</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="3-4-线性判别分析"><a href="#3-4-线性判别分析" class="headerlink" title="3.4 线性判别分析"></a>3.4 线性判别分析</h3><ul>
<li><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/peghoty/p/3798536.html">https://www.cnblogs.com/peghoty/p/3798536.html</a></p>
</li>
<li><p>有监督</p>
</li>
<li><p>LDA与Fisher判别分析稍有不同，LDA假设了各类样本的协方差矩阵相同且满秩</p>
</li>
<li><p>线性判别分析（Linear Discriminant Analysis, LDA），线性学习方法，<strong>分类/降维</strong></p>
<ul>
<li><p>思想：给定训练样例集，设法将样例投影到一条直线上，使得<strong>同类样例的投影点</strong>尽可能<strong>接近</strong>、<strong>异类样例的投影点</strong>尽可能<strong>远离</strong>；（类间散度尽可能大，类内散度尽可能小）</p>
<p>在<strong>对新样本进行分类</strong>时，将其投影到同样的这条直线上，再根据投影点的位置来确定新样本的类别</p>
</li>
<li><p>监督降维方法</p>
</li>
</ul>
</li>
<li><p>利用 Lagrange 乘子法，可将<strong>带约束的极值问题</strong>转化为<strong>无约束极值问题</strong>来进行求解</p>
</li>
</ul>
<h3 id="3-5-多分类学习"><a href="#3-5-多分类学习" class="headerlink" title="3.5 多分类学习"></a>3.5 多分类学习</h3><ul>
<li>多分类任务的基本思路是“拆解法”，即将多分类任务拆为若干个二分类任务求解。<ul>
<li>关键是如何对多分类任务进行拆分，以及如何对多个分类器进行集成</li>
</ul>
</li>
<li><p>拆分策略</p>
<ul>
<li>一对一（One vs. One）<ul>
<li>将 $N$ 个类别两两配对，产生 $\frac{N(N-1)}{2}$ 个二分类任务（每对训练时一正一反）</li>
<li>测试时，样本提交给所有分类器，得到 $\frac{N(N-1)}{2}$ 个分类结果，投票产生最终结果</li>
</ul>
</li>
<li>一对多（One vs. Rest）<ul>
<li>每次将一个类的样例作为正例、所有其他类的样例作为反例来训练 $N$ 个分类器</li>
<li>测试时若仅有一个分类器预测为正类，则对应的类别标记作为最终分类结果；若有多个分类器预测为正类，通常考虑各分类器的预测置信度，选择<strong>置信度最大</strong>的类别标记作为分类结果</li>
</ul>
</li>
<li>多对多（MvM）<ul>
<li>每次将若干个类作为正类，若干个其他类作为反类</li>
<li>最常用 MvM 技术：<strong>纠错输出码</strong>（ECOC, error correcting output codes）<ul>
<li><strong>编码：</strong>对 $N$ 个类别做 $M$ 次划分，每次划分将一部分类别划为正类，一部分划为反类，形成一个二分类训练集。一共产生 $M$ 个训练集，可训练出 $M$ 个分类器</li>
<li><strong>解码：</strong>$M$ 个分类器分别对测试样本进行预测，预测标记组成一个编码。将这个预测编码与每个类别各自的编码进行比较，返回其中距离最小的类别作为最终预测结果</li>
</ul>
</li>
<li>编码矩阵：二元码、三元码（正、反类+停用类）</li>
<li>海明距离（有几个数不同）、欧式距离</li>
<li>对同一个学习任务，ECOC 编码越长，纠错能力越强；但所需训练的分类器越多，计算、存储开销都会增大</li>
</ul>
</li>
</ul>
</li>
<li><p>OvO的存储开销和测试时间开销通常比OvR更大。在<strong>类别很多</strong>时，OvO的训练时间开销通常比OvR更小</p>
</li>
<li>对 OvR、MvM 来说，由于对每类进行了相同的处理，其拆解出的二分类任务中类别不平衡的影响会相互抵消，因此通常不需专门处理</li>
</ul>
<h3 id="3-6-类别不平衡问题"><a href="#3-6-类别不平衡问题" class="headerlink" title="3.6 类别不平衡问题"></a>3.6 类别不平衡问题</h3><ul>
<li>分类器决策规则为：若 $\frac{y}{1-y}&gt;1$ 时，预测为正例<ul>
<li>类别不平衡学习的一个基本策略：再缩放（rescaling）$\frac{y’}{1-y’}=\frac{y}{1-y}× \frac{m^-}{m^+}$</li>
<li>基于的假设是“训练集是真实样本总体的无偏采样”，但往往不成立</li>
</ul>
</li>
<li>三种做法<ul>
<li>对训练集中的反例“欠采样”</li>
<li>对训练集中的正例“过采样”</li>
<li>直接基于原始训练集进行学习，预测时将上面的式子嵌入到其决策过程中，称为“阈值移动”</li>
</ul>
</li>
<li>过采样<ul>
<li><strong>SMOTE</strong>：通过对训练集里的正例进行<strong>插值</strong>来产生额外的正例<ul>
<li>算法的基本思想是对每个少数类样本 $x_i$ ，从它的最近邻中随机选择一个样本 $\hat{x}_i$ （ $\hat{x}_i$ 是少数类中的一个样本，默认用1表示），然后在 $x_i$ 和 $\hat{x}_i$ 之间的连线上随机选择一点作为新合成的少数类样本。<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/346945838">https://zhuanlan.zhihu.com/p/346945838</a></li>
</ul>
</li>
</ul>
</li>
<li>欠采样<ul>
<li><strong>EasyEnsemble</strong>：利用集成学习机制，将反例划分为若干个集合供不同学习器使用，这样对每个学习器来看都进行了欠采样，但在全局来看却不会丢失重要信息<ul>
<li>通过重复组合正样本与随机抽样的同样数量的负样本，训练若干数量分类器进行集成学习</li>
</ul>
</li>
</ul>
</li>
<li><p>“再缩放”也是“代价敏感学习”的基础。在代价敏感学习中将 $\frac{y’}{1-y’}=\frac{y}{1-y}× \frac{m^-}{m^+}$ 中的 $\frac{m^-}{m^+}$ 用 $\frac{cost^+}{cost^-}$ 代替即可，其中 $cost^+$ 是将<strong>正例误分为反例的代价</strong>，$cost^-$ 是将<strong>反例误分为正例的代价</strong></p>
</li>
<li><p>非均等代价和类别不平衡虽然都可借助“再缩放”技术，但两者本质不同。需注意的是类别不平衡学习中通常是较小类的代价更高，否则无需进行特殊处理</p>
</li>
</ul>
<h1 id="第4章-决策树"><a href="#第4章-决策树" class="headerlink" title="第4章 决策树"></a>第4章 决策树</h1><h3 id="4-1-基本流程"><a href="#4-1-基本流程" class="headerlink" title="4.1 基本流程"></a>4.1 基本流程</h3><ul>
<li>叶结点对应于决策结果，其他每个结点则对应于一个属性测试</li>
<li>基本流程遵循“分而治之”策略</li>
<li><p>三种情形会导致递归返回</p>
<ul>
<li>当前结点包含的样本全属于<strong>同一类别</strong>，无需划分</li>
<li><p>当前<strong>属性集为空</strong>，或是所有样本在<strong>所有属性上取值相同</strong>，无法划分</p>
<ul>
<li>把当前结点标记为叶结点，并将其类别设定为<strong>该结点所含样本最多的类别</strong>（利用当前结点的<strong>后验分布</strong>）</li>
</ul>
</li>
<li><p>当前结点包含的<strong>样本集为空</strong>，不能划分</p>
<ul>
<li>把当前结点标记为叶结点，但将其类别设定为其<strong>父结点所含样本最多的类别</strong>（把<strong>父结点的样本分布作为当前结点的先验分布</strong>）</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="4-2-划分选择"><a href="#4-2-划分选择" class="headerlink" title="4.2 划分选择"></a>4.2 划分选择</h3><ul>
<li>熵：对可能产生的信息量的期望（信息量 $-\log_2p(x)$）</li>
<li><strong>信息熵</strong>：随机变量的不确定性。度量样本集合纯度。假定当前样本集合 $D$ 中第 $k$ 类样本所占的比例为 $p_k$ （$k=1,2,…,|\mathcal{Y}|$），则 $D$ 的信息熵定义为 $Ent(D)=-\sum_{k=1}^{|\mathcal{Y}|}p_k\log_2p_k$<ul>
<li>最小值 0，最大值 $\log_2|\mathcal{Y}|$。（用拉格朗日乘子法）</li>
<li>值越小，纯度越高</li>
</ul>
</li>
<li><strong>信息增益 / 互信息</strong>：已知一个随机变量的信息后另一个随机变量的<strong>不确定性减少的程度</strong>（可粗略地看成相似程度或者相关程度） <ul>
<li>定义为<strong>信息熵和条件熵的差</strong>：$I(Y;X)=Ent(Y)-Ent(Y|X)=\sum_{x,y}p(x,y)\log_2\frac{p(x,y)}{p(x)p(y)}=D_{KL}(p(x,y)||p(x)p(y))$</li>
<li>书中：考虑到不同的分支结点所包含的样本数不同，给分支结点赋予权重 $\frac{|D^v|}{|D|}$，即样本数越多的分支结点影响越大，可计算出用属性 $a$ 对样本集 $D$ 进行划分所获得的“信息增益”：$Gain(D,a)=Ent(D)-\sum_{v=1}^V\frac{|D^v|}{|D|}Ent(D^v)$ </li>
</ul>
</li>
<li><strong>条件熵</strong>：在已知一个随机变量的条件下，另一个随机变量的<strong>不确定性</strong>。<ul>
<li>在已知 $X$ 的条件下，随机变量 $Y$ 的条件熵为 $Ent(Y|X)=\sum_{i=1}^n p_i Ent(Y|X=x_i)$。其中 $p_i=P(X=x_i)$</li>
</ul>
</li>
<li><p>$ID3$ <strong>决策树学习算法</strong>就是以<strong>信息增益</strong>为准则来选择划分属性：$a_*=\arg\max_{a\in A}Gain(D,a)$</p>
</li>
<li><p>信息增益的<strong>缺点</strong>：对可取值数目较多的属性有所偏好</p>
</li>
</ul>
<ul>
<li>$C4.5$ <strong>决策树算法</strong>，使用“<strong>增益率</strong>”来选择最优划分属性（避免信息增益的缺点）</li>
<li>增益率：$Gain_ratio(D,a)=\frac{Gain(D,a)}{IV(a)}$<ul>
<li>$IV(a)=-\sum_{v=1}^V \frac{|D^v|}{|D|}\log_2\frac{|D^v|}{|D|}$，称为属性 $a$ 的固有值(intrinsic value)，属性 $a$ 的可能取值数目越多（即 $V$ 越大），则 $IV(a)$ 的值通常会越大</li>
</ul>
</li>
<li>增益率准则可对<u>取值数目较少的属性有所偏好</u>，因此 $C4.5$ 算法<u>并不是</u>直接选择增益率最大的候选划分属性，而是使用了一个启发式：先从候选划分属性中找出<u>信息增益高于平均水平的属性</u>，再从中选择<u>增益率最高的</u></li>
</ul>
<ul>
<li>$CART$ 决策树使用“<strong>基尼指数</strong>”来选择划分属性。（Classification and Regression Tree，<strong>分类和回归任务</strong>都可用，是<strong>二叉树</strong>）</li>
<li>数据集 $D$ 的纯度可用基尼值来度量：$Gini(D)=\sum_{k=1}^{|\mathcal{Y}|}\sum_{k’\not=k}p_kp_{k’}=1-\sum_{k=1}^{|\mathcal{Y}|}p_k^2$<ul>
<li>$Gini(D)$ 反映了从数据集 $D$ 中随机抽取两个样本，其类别标记不一致的概率</li>
<li>$Gini(D)$ <strong>越小</strong>，则数据集 $D$ 的<strong>纯度越高</strong></li>
</ul>
</li>
<li>属性 $a$ 的基尼指数定义为 $Gini_index(D,a)=\sum_{v=1}^V\frac{|D^v|}{|D|}Gini(D^v)$</li>
<li>在候选属性集合 $A$ 中，选择那个使得<strong>划分后<u>基尼指数最小</u></strong>的属性作为最优划分属性，即 $a_*=\arg\min_{a\in A}Gini_index(D,a)$</li>
</ul>
<ul>
<li>ID3：信息增益</li>
<li>C4.5：启发式+增益率</li>
<li>CART：基尼指数+二分法对连续属性进行处理+处理缺失值（下面提到的方法）</li>
</ul>
<h3 id="4-3-剪枝处理"><a href="#4-3-剪枝处理" class="headerlink" title="4.3 剪枝处理"></a>4.3 剪枝处理</h3><ul>
<li>剪枝，防止过拟合</li>
<li><strong>预剪枝</strong>：在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化性能提升，则<u>停止划分并将当前结点标记为叶结点</u></li>
<li><strong>后剪枝</strong>：先从训练集生成一棵完整的决策树，然后自底向上地对<u>非叶节点</u>进行考察，若将该结点对应的子树替换为叶结点能带来决策树泛化性能提升，则将该子树替换为叶结点</li>
<li>用留出法，预留一部分数据用作“验证集”以进行性能评估</li>
<li>仅有一层划分的决策树，称为“决策树桩”</li>
<li>预剪枝<ul>
<li>优点：降低过拟合风险，显著减少决策树的训练时间开销和测试时间开销</li>
<li>缺点：有些分支当前划分不能提升泛化性能，但后续划分可能提高性能。基于“贪心”，可能有<strong>欠拟合风险</strong></li>
</ul>
</li>
<li>后剪枝<ul>
<li>优点：欠拟合风险小，<u>泛化性能</u>往往优于预剪枝决策树</li>
<li>缺点：后剪枝在生成完全决策树后进行的，要自底向上地对树中的所有非叶结点进行逐一考察，因此训练时间开销比未剪枝决策树和预剪枝决策树都要大得多</li>
</ul>
</li>
</ul>
<h3 id="4-4-连续与缺失值"><a href="#4-4-连续与缺失值" class="headerlink" title="4.4 连续与缺失值"></a>4.4 连续与缺失值</h3><ul>
<li>连续值处理</li>
<li>连续属性离散化<ul>
<li>$C4.5$ 决策树中：用<strong>二分法</strong>对<strong>连续属性</strong>进行处理</li>
<li>给定样本集 $D$ 和连续属性 $a$，假定 $a$ 在 $D$ 上出现了 $n$ 个不同的取值，考察包含 $n-1$ 个元素的候选划分点集合 $T_a=\{\frac{a^i+a^{i+1}}{2}|1\leq i\leq n-1\}$</li>
</ul>
</li>
<li>与离散属性不同，若当前结点划分属性为连续属性，该属性<u>还可作为</u>其后代结点的划分属性</li>
</ul>
<ul>
<li>缺失值处理</li>
<li><strong>问题一</strong>：如何在属性值缺失的情况下进行<u>划分属性选择</u>？<ul>
<li>对属性 $a$，$\rho$ 表示无缺失值样本所占的比例，$\tilde{p}_k$ 表示<u>无缺失值样本中</u>第 $k$ 类所占的比例，$\tilde{r}_v$ 表示<u>无缺失值样本中</u>在属性 $a$ 上取值 $a^v$ 的样本所占的比例</li>
<li>$Gain(D,a)=\rho× Gain(\tilde{D},a)=\rho× (Ent(\tilde{D})-\sum_{v=1}^V\tilde{r}_v Ent(\tilde{D}^v))$</li>
<li>$Ent(\tilde{D})=-\sum_{k=1}^{|\mathcal{Y}|}\tilde{p}_k\log_2\tilde{p}_k$</li>
</ul>
</li>
<li><strong>问题二</strong>：给定划分属性，若样本在该属性上的值缺失，<u>如何对样本进行划分</u>？<ul>
<li>若样本 $x$ 在划分属性 $a$ 上的取值已知，则将 $x$ 划入与其取值对应的子结点，且<u>样本权值</u>在子结点中保持为 $w_x$</li>
<li>若样本 $x$ 在划分属性 $a$ 上的取值未知，则将 $x$ 同时划入所有子结点，且样本权值在与属性值 $a^v$ 对应的子结点中调整为 $\tilde{r}_v\cdot w_x$；直观来看，就是让一个样本以不同的概率划入到不同的子结点中去</li>
</ul>
</li>
</ul>
<h3 id="4-5-多变量决策树"><a href="#4-5-多变量决策树" class="headerlink" title="4.5 多变量决策树"></a>4.5 多变量决策树</h3><ul>
<li><p>若我们把每个属性视为坐标空间中的一个坐标轴，则 $d$ 个属性描述的样本就对应了 $d$ 维空间中的一个数据点。决策树形成的分类边界特点：<strong>轴平行</strong></p>
</li>
<li><p>多变量决策树</p>
<ul>
<li>实现斜划分，用斜的划分边界</li>
<li>非叶结点不再是仅对某个属性，而是对<strong>属性的线性组合</strong>进行测试</li>
<li>与传统的“单变量决策树”不同，在多变量决策树的学习过程中，不是为每个非叶结点寻找一个最优划分属性，而是<strong>试图建立一个合适的线性分类器</strong></li>
</ul>
</li>
</ul>
<h1 id="第五章-神经网络"><a href="#第五章-神经网络" class="headerlink" title="第五章 神经网络"></a>第五章 神经网络</h1><h3 id="5-1-神经元模型"><a href="#5-1-神经元模型" class="headerlink" title="5.1 神经元模型"></a>5.1 神经元模型</h3><ul>
<li>M-P神经元模型：$y=f(\sum_{i=1}^nw_ix_i-\theta)$</li>
<li>10个神经元两两连接，则有100个参数：90个连接权和10个阈值<ul>
<li>看成有向完全图，每一个神经元都拥有来自其他9个神经元的权重 和 1个阈值</li>
</ul>
</li>
</ul>
<h3 id="5-2-感知机与多层网络"><a href="#5-2-感知机与多层网络" class="headerlink" title="5.2 感知机与多层网络"></a>5.2 感知机与多层网络</h3><ul>
<li>感知机由两层神经元组成，输入层接收外界信号后传递给输出层，输出层是M-P神经元</li>
<li><p>更一般地，给定训练数据集，权重 $w_i\,(i=1,2,…,n)$ 以及阈值 $\theta$ 可通过学习得到。阈值 $\theta$ 可看作一个固定输入为 $-1.0$ 的“哑结点”所对应的连接权重 $w_{n+1}$，这样，权重和阈值的学习就可统一为权重的学习</p>
</li>
<li><p>学习规则：</p>
<ul>
<li>对训练样例 $(x,y)$，若当前感知机的输出为 $\hat{y}$，则感知机权重将这样调整：$\triangle w_i=\eta(y-\hat{y})x_i,\, w_i\leftarrow w_i+\triangle w_i$。根据错误的程度进行权重调整</li>
<li>极小化损失函数的解 $\min_{w,\theta}L(w,\theta)=\min_{w,\theta}\sum_{x_i\in M}(\hat{y}_i-y_i)(w^Tx_i-\theta)$</li>
<li>感知机的学习算法具体采用的是<strong>随机梯度下降法</strong>，极小化过程中一次随机选取一个误分类点使其梯度下降</li>
</ul>
</li>
<li><p>感知机只有<strong>输出层</strong>神经元进行<strong>激活函数处理</strong>，即只拥有<strong>一层功能神经元</strong>，学习能力非常有限</p>
</li>
<li><p>异或问题是非线性可分问题，用两层感知机能解决，隐含层和输出层神经元<strong>都是拥有激活函数的功能神经元</strong></p>
</li>
</ul>
<ul>
<li><strong>多层前馈神经网络</strong>：每层神经元与下一层神经元<strong>全互连</strong>，神经元之间不存在同层连接，也不存在跨层连接<ul>
<li><strong>前馈</strong>并不意味着网络中信号不能向后传，而是指网络<strong>拓扑结构</strong>上不存在<strong>环或回路</strong></li>
</ul>
</li>
<li>输入层神经元仅是接受输入，不进行函数处理，隐层和输出层包含功能神经元</li>
</ul>
<ul>
<li>神经网络的学习过程，就是根据训练数据来调整<strong>神经元之间的“连接权”</strong>以及每个<strong>功能神经元的阈值</strong></li>
<li>换言之，神经网络学到的东西，蕴含在连接权与阈值中</li>
</ul>
<h3 id="5-3-误差逆传播算法"><a href="#5-3-误差逆传播算法" class="headerlink" title="5.3 误差逆传播算法"></a>5.3 误差逆传播算法</h3><ul>
<li>误差逆传播/反向传播算法（error BackPropagation）</li>
<li>过程<ul>
<li>将输入示例提供给输入层神经元，然后逐层将信号前传，直到产生输出层的结果</li>
<li>计算输出层的误差</li>
<li>再将误差逆向传播至隐层神经元</li>
<li>最后根据<strong>隐层神经元的误差</strong>来对连接权和阈值进行调整</li>
</ul>
</li>
<li>其中要计算<strong>输出层神经元的梯度项</strong>和<strong>隐层神经元的梯度项</strong></li>
<li>标准BP算法 VS 累积BP算法<ul>
<li>标准BP算法：<ul>
<li>每次仅针对<strong>单个样例</strong>更新连接权重和阈值</li>
<li>参数更新得非常<strong>频繁</strong>，而且对不同样例进行更新的效果可能出现“<strong>抵消</strong>”现象</li>
<li>为了达到同样的累积误差极小点，标准BP算法往往需进行更多次数的迭代</li>
</ul>
</li>
<li>累积BP算法：<ul>
<li>直接针对累积误差最小化，在读取整个训练集 $D$ 一遍后才对参数进行更新</li>
<li>参数更新频率低得多</li>
<li>但很多任务中，累积误差下降到一定程度之后，<strong>进一步下降会非常缓慢</strong>（这时标准BP往往会更快获得较好的解，尤其是在训练集 $D$ 非常大时更明显）</li>
</ul>
</li>
<li>标准BP算法和累积BP算法的区别类似于<strong>随机梯度下降（SGD）</strong>与<strong>标准梯度下降</strong>之间的区别</li>
</ul>
</li>
<li>BP神经网络缓解过拟合策略<ul>
<li>早停：若训练集误差降低但验证集误差升高，则停止训练，同时返回具有最小验证集误差的连接权和阈值</li>
<li>正则化：在误差目标函数中增加一个用于描述网络复杂度的部分<ul>
<li>增加连接权与阈值平方和这一项后，训练过程将会偏好比较小的连接权和阈值，使网络输出更加“光滑”，从而对过拟合有所缓解</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="5-4-全局最小与局部最小"><a href="#5-4-全局最小与局部最小" class="headerlink" title="5.4 全局最小与局部最小"></a>5.4 全局最小与局部最小</h3><ul>
<li>梯度下降法就是沿着负梯度方向搜索最优解</li>
<li>感知机更新规则式和BP更新规则式都是基于梯度下降</li>
<li>跳出局部极小的策略<ul>
<li>以<strong>多组不同参数值</strong>初始化多个神经网络。相当于从多个不同的初始点开始搜索</li>
<li><strong>模拟退火</strong>技术。模拟退火在每一步都<strong>以一定的概率接受比当前解更差的结果</strong>，从而有助于“跳出”局部极小。在每部迭代过程中，接受“次优解”的概率要随着时间的推移而<strong>逐渐降低</strong>，从而保证算法稳定。（但是也会造成“跳出”全局最小）</li>
<li>使用<strong>随机梯度下降</strong>。与标准梯度下降法精确计算梯度不同，随机梯度下降法在计算梯度时加入了<strong>随机因素</strong>。于是，即便陷入局部极小点，它计算出的梯度仍可能不为零，这样就有机会跳出局部极小继续搜索</li>
</ul>
</li>
</ul>
<h3 id="5-5-其他常见神经网络"><a href="#5-5-其他常见神经网络" class="headerlink" title="5.5 其他常见神经网络"></a>5.5 其他常见神经网络</h3><ul>
<li><p>RBF网络（Radial Basis Function，径向基函数）</p>
<ul>
<li>单隐层前馈神经网络（单隐层较常见），使用<strong>径向基函数</strong>作为<strong>隐层神经元激活函数</strong>，而输出层则是对隐层神经元输出的<strong>线性组合</strong></li>
<li>假定输入为 $d$ 维向量 $x$，输出为实值，则RBF网络可表示为 $\phi(x)=\sum_{i=1}^qw_i\rho(x,c_i)$ <ul>
<li>$q$ 为隐层神经元个数，$c_i$ 和 $w_i$ 分别是第 $i$ 个<strong>隐层神经元</strong>所对应的<strong>中心</strong>和<strong>权重</strong>，$\rho(x,c_i)$ 是径向基函数，这是某种<strong>沿径向对称的标量函数</strong>，通常定义为样本 $x$ 到数据中心 $c_i$ 之间<strong>欧氏距离的单调函数</strong>。常用的<strong>高斯径向基函数</strong>形如 $\rho(x,c_i)=e^{-\beta_i||x-c_i||^2}$</li>
</ul>
</li>
<li>足够多隐层神经元的RBF网络能以任意精度逼近任意连续函数</li>
<li>两步过程来训练RBF网络：<ul>
<li><strong>确定神经元中心</strong> $c_i$，常用的方式包括<strong>随机采样、聚类</strong>等</li>
<li>利用BP算法等来确定参数 $w_i$ 和 $\beta_i$</li>
</ul>
</li>
</ul>
</li>
<li><p>ART网络</p>
<ul>
<li><strong>竞争型学习</strong>是神经网络中一种常用的<strong>无监督学习</strong>策略。在使用该策略时，网络的输出神经元相互竞争，每一时刻仅有一个竞争获胜的神经元被激活，其他神经元的状态被抑制。这种机制亦称“胜者通吃”原则</li>
<li>ART网络是竞争型学习的重要代表<ul>
<li>比较层、识别层、识别阈值和重置模块</li>
<li>识别阈值较高时，输入样本将会被分成比较多、比较精细的模式类；而如果识别阈值较低，则会产生比较少、比较粗略的模式类</li>
<li>ART比较好地缓解了竞争型学习中的“可塑性-稳定性窘境”</li>
<li>可进行增量学习或在线学习<ul>
<li>增量学习是指在<strong>学得模型后</strong>，再接收到训练样例时，仅需根据新样例对模型进行更新，不必重新训练整个模型，且先前学得的有效信息不会被“冲掉”</li>
<li>在线学习是指<strong>每获得一个新样本就进行一次模型更新</strong></li>
<li>在线学习是增量学习的<strong>特例</strong>，而增量学习可视为“<strong>批模式</strong>”的在线学习</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li>SOM网络（Self-Organizing feature Map，自组织特征映射）<ul>
<li>竞争型的无监督神经网络</li>
<li>将高维数据映射到低维空间（通常为2维），<strong>高维空间中相似的样本点</strong>映射到网络<strong>输出层中邻近神经元</strong></li>
<li>每个神经元拥有一个权向量</li>
<li>目标：为每个<strong>输出层神经元</strong>找到合适的<strong>权向量</strong>以保持<strong>拓扑结构</strong>（降维、聚类）</li>
<li>训练<ul>
<li>网络接收输入样本后，将会确定输出层的“获胜”神经元（胜者通吃）</li>
<li><strong>获胜神经元</strong>的<strong>权向量</strong>将向当前输入样本移动</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li>级联相关网络（Cascade-Correlation）<ul>
<li><strong>结构自适应</strong>网络的重要代表</li>
<li>构造性神经网络：将网络的结构也当做学习的目标之一，希望在训练过程中找到适合数据的网络结构</li>
<li>训练：<ul>
<li>开始时只有输入层和输出层</li>
<li><strong>级联</strong>：新的隐层结点逐渐加入，从而创建起<strong>层级结构</strong></li>
<li><strong>相关</strong>：最大化<strong>新结点的输出</strong>与<strong>网络误差</strong>之间的相关性</li>
</ul>
</li>
<li>与一般的前馈神经网络相比，级联相关网络无需设置网络层数、隐层神经元数目，且训练速度较快，但其在数据较小时易陷入过拟合</li>
</ul>
</li>
</ul>
<ul>
<li><strong>Elman网络</strong><ul>
<li>递归神经网络<ul>
<li>网络中可以有环形结构，可让使一些神经元的输出反馈回来作为输入</li>
<li>$t$ 时刻网络的<strong>输出状态</strong>：由 $t$ 时刻的<strong>输入状态</strong>和 $t-1$ 时刻的<strong>网络状态</strong>共同决定</li>
</ul>
</li>
<li>Elman网络是最常用的递归神经网络之一<ul>
<li>结构与前馈神经网路很相似，但<strong>隐层神经元</strong>的输出被反馈回来</li>
<li>使用推广的BP算法训练</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="5-6-深度学习"><a href="#5-6-深度学习" class="headerlink" title="5.6 深度学习"></a>5.6 深度学习</h3><ul>
<li>trick<ul>
<li>预训练+微调<ul>
<li>预训练：无监督逐层训练（自编码器？）+ 每次训练一层隐结点</li>
<li>微调：预训练全部完成后，对全网络进行微调训练</li>
<li>“预训练+微调”的做法可视为将大量参数分组，对每组先找到局部看来比较好的设置，然后再基于这些局部较优的结果联合起来进行全局寻优。在利用了模型大量参数所提供的自由度的同时，节省了训练开销</li>
</ul>
</li>
<li>Dropout<ul>
<li>在每轮训练时随机选择一些参数令其不被更新（下一轮可能被更新）</li>
<li>降低Rademacher复杂度</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="第6章-支持向量机"><a href="#第6章-支持向量机" class="headerlink" title="第6章 支持向量机"></a>第6章 支持向量机</h1><h3 id="6-1-间隔与支持向量"><a href="#6-1-间隔与支持向量" class="headerlink" title="6.1 间隔与支持向量"></a>6.1 间隔与支持向量</h3><ul>
<li>对线性可分的情形，构造硬间隔，位于间隔边界上的样本点称为<strong>支持向量</strong>（硬间隔的<strong>支持向量</strong>）。</li>
</ul>
<ul>
<li><p>什么是<strong>支持向量</strong>？</p>
<ul>
<li><p>对于<strong>可分情况</strong></p>
<ul>
<li>支持向量是落在间隔超平面 $w\cdot x_i+b=\pm 1$ 上的样本。</li>
<li>支持向量可以完全定义<strong>最大间隔超平面</strong>或<strong>SVM问题的解</strong>，这便是算法命名的由来</li>
<li>支持向量的权重向量 $w$ 是支持向量的 $x_i$ 的线性组合 $w=\sum_{i=1}^m a_iy_ix_i$（只有支持向量的 $a_i\not=0$）</li>
</ul>
</li>
<li><p>对于<strong>不可分情况</strong></p>
<ul>
<li>支持向量落在间隔超平面 $w\cdot x_i+b=\pm 1$ 上，或者是一个<strong>异常点</strong>（松弛变量大于0 的点 / 没有落在间隔超平面相应的正确一侧）</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li>SVM 的目标是<strong>最大化间隔</strong><ul>
<li><strong>间隔</strong>：离超平面 $wx+b=0$ 最近的正/负样本到超平面的距离</li>
<li>为了保证每个超平面的参数只有唯一解，额外约束离超平面最近的正负样本代入超平面方程后的绝对值为1，即支持向量到超平面的距离被约束为 $\frac{1}{||w||}$</li>
<li>有个前提：最近的正/负样本到超平面的距离相等</li>
</ul>
</li>
</ul>
<ul>
<li>一个点（样例）的边际margin是其到<strong>分界超平面</strong>的垂直距离</li>
<li>SVM最大化（所有训练样本的）最小边际</li>
<li>有最小边际的点称为支持向量</li>
</ul>
<ul>
<li>虽然在一个特定问题中<u>支持向量机的解是唯一的</u>，但是<u>支持向量可能不唯一</u>。对于 $N$ 维问题，$N+1$ 个点已经足够定义超平面。因此当超过 $N+1$ 个点落在间隔超平面上时，对于 $N+1$ 个支持向量可能会有不同的选择</li>
</ul>
<ul>
<li>区别（划分）超平面和间隔超平面</li>
<li>划分超平面通过线性方程 $w^Tx+b=0$ 来描述。<ul>
<li>$w$ 为法向量，决定了超平面的方向</li>
<li>$b$ 为位移项，决定了超平面与原点之间的距离</li>
</ul>
</li>
</ul>
<ul>
<li>SVM的基本型</li>
</ul>
<script type="math/tex; mode=display">
\min_{w,b}\frac{1}{2}||w||^2\\
s.t.\; y_i(w^Tx_i+b)\geq 1,\, i=1,2,...,m</script><h3 id="6-2-对偶问题"><a href="#6-2-对偶问题" class="headerlink" title="6.2 对偶问题"></a>6.2 对偶问题</h3><ul>
<li><p>什么是<strong>凸优化问题</strong>？</p>
<ul>
<li><script type="math/tex; mode=display">
\min\quad f(x)\\
s.t.\quad g_i(x)\leq 0,\quad i=1,2,...,m\\
\quad \quad h_j(x)=0,\quad j=1,2,...,n</script></li>
<li><p>目标函数 $f(x)$ 是凸函数，不等式约束 $g_i(x)$ 是凸函数，等式约束 $h_j(x)$ 是仿射函数</p>
</li>
</ul>
</li>
</ul>
<ul>
<li><p>Lagrange 对偶问题的最优值，用 $d^<em>$ 表示，是通过 Lagrange 函数得到的原问题最优值 $p^</em>$ 的最好下界。$d^<em>\leq p^</em>$（弱对偶性，即使原问题不是凸问题，亦成立）</p>
<ul>
<li>$p^*=\inf_x\sup_{\lambda\geq 0}L(x,\lambda)$</li>
<li>$d^*=\sup_{\lambda\geq 0}\inf_x L(x,\lambda)$</li>
</ul>
</li>
<li><p>当 Slater 条件成立（且原问题是<strong>凸问题</strong>）时，强对偶性成立</p>
<ul>
<li>Slater条件：当主问题是凸优化问题，且存在一点 $x\in \,relint\,D$ （定义域的相对内部）能使得所有等式约束成立，除仿射函数以外的不等式约束严格成立，则强对偶性成立</li>
</ul>
</li>
<li><p><img src="image-20230427105711681.png" alt="image-20230427105711681" style="zoom:50%;"></p>
</li>
<li><p>若某个<strong>凸优化问题</strong>具有可微的目标函数和约束函数，且其满足 Slater 条件，那么 KKT 条件是最优性的充要条件：Slater 条件意味着最优对偶间隙为零且对偶最优解可以达到，因此 $x$ 是原问题最优解，当且仅当存在 $(\lambda,\mathcal{v})$，二者满足 KKT 条件。（<strong>KKT 条件和强对偶关系是等价关系</strong>）</p>
</li>
<li><p>非凸问题不能用 Slater 条件（该条件要求问题是凸）来判断强对偶性</p>
</li>
<li><p>凸问题的 KKT 条件</p>
<script type="math/tex; mode=display">
\begin{align}
f_i(\tilde{x})&\leq 0,\; i=1,...,m \; (原问题约束)\\
h_i(\tilde{x})&= 0,\; i=1,...,p \; (原问题约束)\\
\tilde{\lambda}_i&\geq 0,\; i=1,...,m\; (拉格朗日乘子非负)\\
\tilde{\lambda}_if_i(\tilde{x}) &= 0,\; i=1,...,m\; (互补松弛条件)\\
\nabla f_0(\tilde{x})+\sum_{i=1}^m \tilde{\lambda}_i\nabla f_i(\tilde{x})+\sum_{i=1}^p \tilde{v}_i\nabla h_i(\tilde{x}) &=0
\end{align}</script></li>
</ul>
<ul>
<li>在推导对偶问题时，常通过将拉格朗日函数 $L(x,\lambda,\mu)$ 对 $x$ 求导并令导数为0，来获得对偶函数的表达形式<ul>
<li>对于强对偶性成立的优化问题，其主问题的最优解 $x^<em>$ 一定满足KKT条件，而KKT条件中的其中一条就要求最优解 $x^</em>$ 能使得拉格朗日函数 $L(x,\lambda,\mu)$ 关于 $x$ 的一阶导数等于0</li>
<li>对于任意优化问题，若拉格朗日函数 $L(x,\lambda,\mu)$ 是关于 $x$ 的凸函数，那么此时对 $L(x,\lambda,\mu)$ 关于 $x$ 求导并令导数等于0解出来的点一定是最小值点。根据对偶函数的定义可知，将最小值点代回 $L(x,\lambda,\mu)$ 即可得到对偶函数</li>
</ul>
</li>
</ul>
<ul>
<li><p>对偶形式</p>
<ul>
<li><script type="math/tex; mode=display">
\max_{\alpha} \sum_{i=1}^m\alpha_i-\frac{1}{2}\sum_{i=1}^m\sum_{j=1}^m\alpha_i\alpha_jy_iy_jx_i^Tx_j\\
s.t.\,\sum_{i=1}^m\alpha_i y_i=0\\
\quad\quad\quad\quad\quad\quad a_i\geq 0,\quad i=1,2,...,m</script></li>
<li></li>
</ul>
</li>
<li><p>解出 $\alpha$ 后，求出 $w$ 与 $b$ 即可得到模型 $f(x)=w^Tx+b=\sum_{i=1}^m\alpha_iy_ix_i^Tx+b$</p>
<ul>
<li>对于任意支持向量 $x_i$，$w^Tx_i+b=y_i$，因此 $b=y_i-\sum_{j=1}^m\alpha_jy_jx_j^Tx_i$。可以取平均</li>
</ul>
</li>
</ul>
<ul>
<li><strong>为什么用对偶形式？</strong><ul>
<li>原问题优化变量的维度是样本特征个数 $d$ ，对偶问题优化变量的维度等于训练样本个数 $m$，通常 $m\ll d$，通常求解对偶问题更高效，反之求解原问题更高效</li>
<li>对偶问题目标式中有样本内积 $x_i^Tx_j$ 的形式，后续可以很自然地引入核函数，进而使得支持向量机也能对在原始特征空间线性不可分的数据进行分类</li>
</ul>
</li>
</ul>
<ul>
<li>二次规划问题（QP）：目标函数是变量的二次函数，而约束条件是变量的线性不等式<ul>
<li>解法：椭球法、内点法、增广拉格朗日法、梯度投影法</li>
</ul>
</li>
<li><p>对偶问题是一个二次规划问题，但问题规模正比于训练样本数，实际中开销大</p>
<ul>
<li>SMO算法：每次选择两个变量 $\alpha_i$ 和 $\alpha_j$，并固定其他参数。这样，在参数初始化后，SMO不断执行如下两个步骤直至收敛：<ul>
<li>选取一对需更新的变量 $\alpha_i$ 和 $\alpha_j$</li>
<li>固定 $\alpha_i$ 和 $\alpha_j$ 以外的参数，求解对偶问题目标式获得更新后的 $\alpha_i$ 和 $\alpha_j$</li>
</ul>
</li>
<li>SMO 先选取违背 KKT 条件程度最大的变量，第二个变量应选择一个使目标函数值减小最快的变量，但比较各变量所对应的目标函数值减幅的复杂度过高，因此 SMO 采用了一个启发式：<ul>
<li>使选取的两变量所对应样本之间的间隔最大（有很大差别）</li>
</ul>
</li>
<li>消去 $\alpha_j$ 后得到一个关于 $\alpha_i$ 的一元二次问题，仅有的约束是 $\alpha_i\geq 0$，有闭式解</li>
</ul>
</li>
<li><p>求 $b$</p>
<ul>
<li>$S=\{i|\alpha_i&gt;0,i=1,2,…,m\}$ 为所有支持向量的下标集</li>
<li>鲁棒的做法：使用所有支持向量求解的平均值：$b=\frac{1}{|S|}\sum_{s\in S}(y_s-\sum_{i\in S}\alpha_iy_ix_i^Tx_s)$</li>
</ul>
</li>
</ul>
<h3 id="6-3-核函数"><a href="#6-3-核函数" class="headerlink" title="6.3 核函数"></a>6.3 核函数</h3><ul>
<li><script type="math/tex; mode=display">
\begin{align}
f(x)&=w^T\phi(x)+b\\
&=\sum_{i=1}^m\alpha_iy_i\phi(x_i)^T\phi(x)+b\\
&=\sum_{i=1}^m\alpha_iy_ik(x,x_i)+b
\end{align}</script></li>
<li><p>只要一个<strong>对称函数</strong>所对应的<strong>核矩阵半正定</strong>，它就能作为<strong>核函数</strong>使用</p>
</li>
<li><p>对于一个半正定核矩阵，总能找到一个与之对应的映射 $\phi$（映射函数 $\not=$ 核函数）。换言之，任何一个核函数都隐式地定义了一个称为”再生核希尔伯特空间“的特征空间</p>
</li>
<li><p>常见核函数（线性核、多项式核、高斯核、拉普拉斯核、sigmoid核）</p>
</li>
<li><p>以下核函数的组合也是核函数</p>
<ul>
<li>线性组合 $\gamma_1\kappa_1+\gamma_2\kappa_2$ </li>
<li>核函数的直积 $\kappa_1\otimes\kappa_2(x,z)=\kappa_1(x,z)\kappa_2(x,z)$</li>
<li>对于任意函数 $g(x)$，$\kappa(x,z)=g(x)\kappa_1(x,z)g(z)$</li>
</ul>
</li>
<li><p>$K(x,y)=\phi(x)^T\phi(y)$，非线性函数 $K$ 表示两个向量的相似程度 （高维特征的内积？）</p>
</li>
</ul>
<h3 id="6-4-软间隔与正则化"><a href="#6-4-软间隔与正则化" class="headerlink" title="6.4 软间隔与正则化"></a>6.4 软间隔与正则化</h3><ul>
<li><p>硬间隔：要求所有样本均满足约束，即所有样本都必须划分正确</p>
</li>
<li><p>软间隔：允许某些样本不满足约束 $y_i(w^Tx_i+b)\geq 1$</p>
</li>
<li><p>采用 hinge 损失，引入”松弛变量“ $\xi_i\geq0$</p>
</li>
<li><script type="math/tex; mode=display">
\min_{w,b}\quad \frac{1}{2}||w||^2+C\sum_{i=1}^m\xi_i\\
s.t.\quad y_i(w^Tx_i+b)\geq 1-\xi_i\\
\xi_i\geq 0</script></li>
<li><p>对偶问题解出 $C=\alpha_i+\mu_i$</p>
<ul>
<li>若 $\alpha_i=0$，则该样本不会对 $f(x)$ 有任何影响</li>
<li>若 $\alpha_i&gt;0$，则必有 $y_if(x_i)=1-\xi_i$，即该样本是支持向量<ul>
<li>若 $\alpha_i<C$，则 $\mu_i>0$，进而有 $\xi_i=0$，即该样本恰在最大间隔边界上</C$，则></li>
<li>若 $\alpha_i=C$，则 $\mu_i=0$，此时若 $\xi_i\leq 1$ 则该样本落在最大间隔内部，若 $\xi_i&gt;1$ 则该样本被错误分类</li>
</ul>
</li>
</ul>
</li>
<li><p>软间隔支持向量机的最终模型仅与支持向量有关，即通过采用 hinge 损失函数仍保持了稀疏性</p>
<ul>
<li>hinge 损失有一块“平坦”的零区域，这使得SVM的解具有稀疏性</li>
</ul>
</li>
<li><p>如果使用对率损失函数 $l_{log}(z)=\log(1+\exp(-z))$ 来替代 $0/1$ 损失函数，则几乎就得到了对率回归模型</p>
</li>
<li><p>支持向量机的输出不具有概率意义，欲得到概率需进行特殊处理</p>
</li>
<li><script type="math/tex; mode=display">
\min_f\quad \Omega(f)+C\sum_{i=1}^m l(f(x_i),y_i)</script><ul>
<li>$\Omega(f)$ 称为“结构风险”，用来描述划分超平面的“间隔”大小<ul>
<li>有助于削减假设空间，降低最小化训练误差的过拟合风险</li>
<li>也称为“正则化项”</li>
<li>$L_2$ 范数 $||w||_2$ 倾向于 $w$ 的分量取值尽量均衡，即非零分量个数尽量稠密；$L_0,L_1$ 范数倾向于 $w$ 分量尽量稀疏，即非零分量个数尽量少</li>
</ul>
</li>
<li>第二项是经验风险，表达训练集上的误差</li>
</ul>
</li>
</ul>
<h3 id="6-5-支持向量回归"><a href="#6-5-支持向量回归" class="headerlink" title="6.5 支持向量回归"></a>6.5 支持向量回归</h3><ul>
<li><p>SVR 假设我们能容忍 $f(x)$ 与 $y$ 之间最多有 $\epsilon$ 的偏差，即仅当 $f(x)$ 与 $y$ 之间的差别绝对值大于 $\epsilon$ 时才计算损失</p>
</li>
<li><script type="math/tex; mode=display">
\min_{w,b,\xi_i,\hat{\xi}_i}\frac{1}{2}||w||^2+C\sum_{i=1}^m(\xi_i+\hat{\xi}_i)\\
s.t.\, \,f(x_i)-y_i\leq \epsilon+\xi_i\\
\quad y_i-f(x_i)\leq \epsilon+\hat{\xi}_i\\
\quad \xi_i\geq 0,\,\hat{\xi}_i\geq 0</script><ul>
<li>仅当样本 $(x_i,y_i)$ 不落入 $\epsilon$-间隔带中，相应的 $\alpha_i$ 和 $\hat{\alpha}_i$ 才能取得非零值。且两者至少有一个为零</li>
</ul>
</li>
</ul>
<h3 id="6-6-核方法"><a href="#6-6-核方法" class="headerlink" title="6.6 核方法"></a>6.6 核方法</h3><ul>
<li>核方法将（输入空间的）一个<strong>非线性分类问题</strong>转换为在（通常维度更高的）特征空间中一个等效的<strong>线性分类问题</strong>。</li>
<li>预测的过程通过核技巧来完成 $f(x)=\sum_{i=1}^n\alpha_iy_ik(x_i,x)+b$<ul>
<li>然而该计算比线性 SVM 中的计算要昂贵很多。假设 $k(x_i,x)$ 的复杂度为 $O(d)$，预测一个样本可能需要 $O(nd)$ 步。当训练样本的数量很大时，核 SVM 的预测会非常慢，并且还需要将所有训练样本都保存在 SVM 模型中，这会带来非常高的存储代价</li>
<li>不过 SVM 预测的实际代价却低于 $O(nd)$。如果一个训练样本 $x_i$ 不是支持向量，那么其拉格朗日乘子 $\alpha_i=0$，在上述求和中没有用。因此只有支持向量才会被用于预测，才会被存储在 SVM 模型里</li>
<li>拉格朗日乘子是稀疏的，即很多 $\alpha_i$ 都是0。实际预测复杂度远低于 $nd$</li>
</ul>
</li>
</ul>
<h1 id="第7章-贝叶斯分类器"><a href="#第7章-贝叶斯分类器" class="headerlink" title="第7章 贝叶斯分类器"></a>第7章 贝叶斯分类器</h1><h3 id="7-1-贝叶斯决策论"><a href="#7-1-贝叶斯决策论" class="headerlink" title="7.1 贝叶斯决策论"></a>7.1 贝叶斯决策论</h3><ul>
<li><p>$\lambda_{ij}$ 是将一个真实标记为 $c_j$ 的样本误分类为 $c_i$ 所产生的损失。基于后验概率 $P(c_i|x)$ 可获得将样本 $x$ 分类为 $c_i$ 所产生的<strong>期望损失</strong>，即在样本 $x$ 上的“<strong>条件风险</strong>” $R(c_i|x)=\sum_{j=1}^N \lambda_{ij}P(c_j|x)$（明明是其他类，但分类成 $c_i$）</p>
</li>
<li><p><strong>贝叶斯判定准则</strong>：为最小化总体风险，只需在每个样本上选择那个能使条件风险 $R(c|x)$ 最小的类别标记，即 $h^<em>(x)=\arg\min_{c\in\mathcal{Y}}R(c|x)$。此时 $h^</em>$ 称为<strong>贝叶斯最优分类器</strong>，与之对应的总体风险 $R(h^*)$ 称为贝叶斯风险</p>
</li>
</ul>
<ul>
<li><strong>判别式</strong>：直接对 $p(c|x)$ 建模（决策树、BP神经网络、SVM）</li>
<li><strong>生成式</strong>：先对<strong>联合概率分布</strong> $p(x,c)$ 建模，再由贝叶斯公式获得 $p(c|x)=\frac{p(x,c)}{p(x)}$（贝叶斯分类器）</li>
<li>$P(c|x)=\frac{P(c)P(x|c)}{P(x)}$<ul>
<li>$P(x|c)$ 是类条件概率 / 似然</li>
<li>$P(x)$ 证据因子</li>
</ul>
</li>
<li>类条件概率涉及关于 $x$ 所有属性的联合概率，直接根据样本出现的频率来估计将会遇到严重的困难</li>
</ul>
<h3 id="7-2-极大似然估计"><a href="#7-2-极大似然估计" class="headerlink" title="7.2 极大似然估计"></a>7.2 极大似然估计</h3><ul>
<li>极大似然估计是<strong>频率主义学派</strong>（MLE，Maximum Likelihood Estimation）</li>
<li>概率模型的训练过程就是参数估计过程</li>
<li>参数估计，不同解决方案<ul>
<li>频率主义学派：参数未知，但却是客观存在的固定值。可通过优化似然函数等准则来确定参数值</li>
<li>贝叶斯学派：参数是未观察到的<strong>随机变量</strong>，其本身也可有<strong>分布</strong>。可假定<strong>参数服从一个先验分布</strong>，然后<strong>基于观测到的数据来计算参数的后验分布</strong></li>
</ul>
</li>
<li><p>假设样本是<strong>独立同分布</strong>的，则参数 $\theta_c$ 对于数据集 $D_c$ 的似然是 $P(D_c|\theta_c)=\prod_{x\in D_c}P(x|\theta_c)$。连乘容易下溢，通常使用对数似然 $LL(\theta_c)=\log P(D_c|\theta_c)=\sum_{x\in D_c}\log P(x|\theta_c)$</p>
</li>
<li><p>MLE参数化的方法虽能使类条件概率估计变得相对简单，但估计结果的准确性严重依赖于<strong>所假设的概率分布形式</strong>是否符合潜在的真实数据分布</p>
</li>
</ul>
<h3 id="7-3-朴素贝叶斯分类器"><a href="#7-3-朴素贝叶斯分类器" class="headerlink" title="7.3 朴素贝叶斯分类器"></a>7.3 朴素贝叶斯分类器</h3><ul>
<li>类条件概率 $P(x|c)$ 是<strong>所有属性</strong>上的联合概率，难以从有限的训练样本直接估计而得。<ul>
<li>为避开障碍，朴素贝叶斯分类器采用了“<strong>属性条件独立性假设</strong>”：对已知类别，假设所有属性相互独立。即 假设每个属性独立地对分类结果发生影响。</li>
<li>基于属性条件独立性假设，$P(c|x)=\frac{P(c)P(x|c)}{P(x)}=\frac{P(c)}{P(x)}\prod_{i=1}^d P(x_i|c)$，其中 $d$ 为属性数目，$x_i$ 为 $x$ 在第 $i$ 个属性上的取值</li>
<li>所有类别 $P(x)$ 相同，贝叶斯判定准则 $h_{nb}(x)=\arg\max_{c\in \mathcal{Y}}P(c)\prod_{i=1}^d P(x_i|c)$</li>
</ul>
</li>
<li>朴素贝叶斯分类器的<strong>训练过程</strong>就是基于训练集 $D$ 来估计<strong>类先验概率</strong> $P(c)$，并为<strong>每个属性估计条件概率</strong> $P(x_i|c)$</li>
<li><p>拉普拉斯修正：为了避免其他属性携带的信息被训练集中未出现的属性值“抹去”，在估计概率值时通常要进行“平滑”</p>
<ul>
<li>$N$：训练集 $D$ 中可能的类别数，$N_i$：第 $i$ 个属性可能的取值数</li>
<li>$\hat{P}(c)=\frac{|D_c|+1}{|D|+N}$，$\hat{P}(x_i|c)=\frac{|D_{c,x_i}|+1}{|D_c|+N_i}$</li>
</ul>
</li>
<li><p>拉普拉斯修正实质上假设了<strong>属性值与类别均匀分布</strong>，这是在朴素贝叶斯学习过程中额外引入的关于数据的先验</p>
</li>
<li>拉普拉斯修正避免了<strong>因训练集样本不充足而导致概率估值为零</strong>的问题</li>
</ul>
<h3 id="7-4-半朴素贝叶斯分类器"><a href="#7-4-半朴素贝叶斯分类器" class="headerlink" title="7.4 半朴素贝叶斯分类器"></a>7.4 半朴素贝叶斯分类器</h3><ul>
<li>朴素贝叶斯分类器采用了属性条件独立性假设，但实际中假设比较难成立。对属性条件独立性假设进行一定程度的放松，得到“半朴素贝叶斯分类器”</li>
<li>半朴素贝叶斯分类器的<strong>基本思想</strong>：适当考虑一部分属性间的相互依赖信息</li>
<li><strong>独依赖估计</strong>（ODE, One-Dependent Estimator）是半朴素贝叶斯分类器最常用的一种策略<ul>
<li>假设每个属性在<strong>类别</strong>之外最多仅依赖于<strong>一个其他属性</strong></li>
<li>$P(c|x)\propto P(c)\prod_{i=1}^d P(x_i|c,pa_i)$</li>
<li>$pa_i$ 是属性 $x_i$ 所依赖的属性，称为 $x_i$ 的父属性</li>
</ul>
</li>
<li>问题的关键转化为<strong>如何确定每个属性的父属性</strong>，不同的做法产生不同的独依赖分类器<ul>
<li>SPODE（Super-Parent ODE）<ul>
<li>假设所有属性都依赖于同一个属性，称为“超父”。通过交叉验证等模型选择方法确定<strong>超父属性</strong></li>
</ul>
</li>
<li>TAN（Tree Augmented naive Bayes）<ul>
<li><strong>最大带权生成树</strong>算法的基础上，通过以下步骤将属性间依赖关系约简为树形结构<ul>
<li>计算任意两个属性之间的<strong>条件互信息</strong><ul>
<li>$I(x_i,x_j|y)=\sum_{x_i,x_j;c\in\mathcal{Y}}P(x_i,x_j|c)\log\frac{P(x_i,x_j|c)}{P(x_i|c)P(x_j|c)}$</li>
</ul>
</li>
<li>以属性为结点构建完全图，任意两个结点之间边的权重设为 $I(x_i.x_j|y)$</li>
<li>构建此完全图的<strong>最大带权生成树</strong>，挑选根变量，将边置为有向</li>
<li>加入类别结点 $y$，增加从 $y$ 到每个属性的有向边</li>
</ul>
</li>
<li><strong>条件互信息</strong> $I(x_i,x_j|y)$ 刻画了属性 $x_i$ 和 $x_j$ 在<strong>已知类别</strong>情况下的<strong>相关性</strong></li>
<li>通过最大生成树算法，TAN实际上仅保留了强相关属性之间的依赖性</li>
</ul>
</li>
<li>AODE（Averaged One-Dependent Estimator）<ul>
<li>是一种基于<strong>集成学习机制</strong>、更为强大的独依赖分类器</li>
<li>SPODE：通过模型选择确定超父属性；AODE：将每个属性作为超父来构建 SPODE，将<strong>具有足够训练数据支撑的 SPODE 集成</strong>起来作为最终结果<ul>
<li>$P(c|x)\propto \sum_{i=1,|D_{x_i}|\geq m’}^d P(c,x_i)\prod_{j=1}^d P(x_j|c,x_i)$</li>
<li>与朴素贝叶斯分类器相似，AODE 无需模型选择，既能通过预计算节省预测时间，也能采取懒惰学习方式在预测时再进行计数，并且易于实现增量学习</li>
</ul>
</li>
</ul>
</li>
<li><img src="image-20230512170709571.png" alt="image-20230512170709571" style="zoom:50%;"></li>
<li></li>
</ul>
</li>
</ul>
<h3 id="7-5-贝叶斯网"><a href="#7-5-贝叶斯网" class="headerlink" title="7.5 贝叶斯网"></a>7.5 贝叶斯网</h3><ul>
<li><strong>结构</strong>：</li>
<li>贝叶斯网，亦称“信念网”，用<strong>有向无环图</strong>（DAG）来刻画属性之间的依赖关系，用条件概率表描述属性的联合概率分布</li>
<li>一个贝叶斯网 $B$ 由结构 $G$ 和参数 $\Theta$ 构成，$B=<G,\Theta>$</G,\Theta></li>
<li><img src="image-20230512183857383.png" alt="image-20230512183857383" style="zoom:50%;"><ul>
<li>同父结构：给定父结点 $x_1$ 的取值，$x_3$ 和 $x_4$ 条件独立，$x_3⊥x_4|x_1$。但<strong>不满足</strong>边际独立性（若 $x_1$ 的取值未知，则 $x_3$ 和 $x_4$ 就不独立）</li>
<li>V 型结构：$x_4$ 取值<strong>未知</strong>，$x_1$ 和 $x_2$ 相互独立，称“<strong>边际独立性</strong>”，记为 $x_1⊥x_2$ （两条竖线）</li>
<li>顺序结构：给定 $x$ 的值，则 $y$ 和 $z$ 条件独立。不满足边际独立性</li>
</ul>
</li>
<li>为了分析有向图中变量间的条件独立性，可使用“有向分离”。<ul>
<li>先把有向图转变为一个无向图，产生的无向图称为“道德图”，令父结点相连的过程称为“道德化”<ul>
<li>找出有向图中的所有 <strong>V 型结构</strong>，在 V 型结构的两个<strong>父结点</strong>之间加上一条无向边</li>
<li>将所有有向边改为无向边</li>
</ul>
</li>
<li>若变量 $x$ 和 $y$ 能在图上被 $z$ 分开，即从道德图中将变量集合 $z$ 去除后，$x$ 和 $y$ 分属两个连通分支，则称变量 $x$ 和 $y$ 被 $z$ 有向分离，$x⊥y|z$ 成立</li>
</ul>
</li>
<li>在可信的贝叶斯网络中，一个结点的<strong>马尔可夫毯</strong>即为该结点的父结点、子结点以及子结点的父结点</li>
</ul>
<ul>
<li><p><strong>学习：</strong></p>
</li>
<li><p>贝叶斯网学习的首要任务是根据训练数据集找出结构最“恰当”的贝叶斯网</p>
</li>
</ul>
<ul>
<li><p><strong>推断：</strong></p>
</li>
<li><p>推断：通过已知变量观测值来推断待查询变量的过程，已知变量观测值称为“证据”</p>
</li>
<li>贝叶斯网的<strong>近似推断</strong>常使用<strong>吉布斯采样</strong>来完成，是一种<strong>随机采样</strong>方法</li>
<li><img src="image-20230513204140090.png" alt="image-20230513204140090" style="zoom:50%;"></li>
<li>吉布斯采样是在贝叶斯网所有变量的联合状态空间与证据 $E=e$ 一致的子空间中进行“随机漫步”。每一步仅依赖于前一步的状态，这是一个“马尔科夫链”。$t\rightarrow ∞$ 时必收敛于一个平稳分布；对于吉布斯采样来说，这个分布恰好是 $P(Q|E=e)$。因此在 $T$ 很大时，吉布斯采样相当于根据 $P(Q|E=e)$ 采样，保证 $\frac{n_q}{T}$ 收敛于 $P(Q=q|E=e)$</li>
<li>马尔可夫链趋于平稳分布需很长时间，因此吉布斯算法的收敛速度很慢。若贝叶斯网中存在极端概率0或1，则不能保证马尔科夫链存在平稳分布</li>
</ul>
<h3 id="7-6-EM算法"><a href="#7-6-EM算法" class="headerlink" title="7.6 EM算法"></a>7.6 EM算法</h3><ul>
<li>EM（Expectation-Maximization）：期望最大化算法</li>
<li>未观测变量 / 隐变量</li>
<li>原型是先基于参数推断隐变量期望，再基于已观测变量和隐变量<strong>对参数做极大似然估计</strong></li>
<li>还可以基于 $\Theta^t$ 计算隐变量 $Z$ 的概率分布 $P(Z|X,\Theta^t)$。两个步骤：<ul>
<li>$E$ 步：以当前参数 $\Theta^t$ 推断<strong>隐变量分布</strong> $P(Z|X,\Theta^t)$，并计算<strong>对数似然 $LL(\Theta|X,Z)$ 关于 $Z$ 的期望</strong> $Q(\Theta|\Theta^t)=\mathbb{E}_{Z|X,\Theta^t}LL(\Theta|X,Z)$</li>
<li>$M$ 步：寻找参数最大化期望似然，即 $\Theta^{t+1}=\arg\max_{\Theta}Q(\Theta|\Theta^t)$</li>
<li>E步利用当前估计的参数值来计算<strong>对数似然的期望值</strong>；M步寻找能使E步产生的似然期望最大化的参数值</li>
</ul>
</li>
<li>EM 算法可看作用<strong>坐标下降法</strong>来最大化对数似然下界的过程</li>
<li>应用：GMM、k-means</li>
</ul>
<ul>
<li>贝叶斯分类器与一般意义上的“贝叶斯学习”有显著区别<ul>
<li>前者是通过最大后验概率进行单点估计</li>
<li>后者是进行分布估计</li>
</ul>
</li>
</ul>
<h1 id="第8章-集成学习"><a href="#第8章-集成学习" class="headerlink" title="第8章 集成学习"></a>第8章 集成学习</h1><h3 id="8-1-个体与集成"><a href="#8-1-个体与集成" class="headerlink" title="8.1 个体与集成"></a>8.1 个体与集成</h3><ul>
<li>集成学习：<strong>构建并结合多个学习器</strong>来完成学习任务<ul>
<li>个体学习器：由一个现有的学习算法从训练数据中产生（如C4.5决策树算法、BP神经网络算法）</li>
<li><strong>同质集成</strong>中的个体学习器：基学习器；学习算法：基学习算法</li>
<li><strong>异质集成</strong>中的个体学习器：组件学习器/个体学习器</li>
</ul>
</li>
<li>要获得好的集成，个体学习器应“好而不同”（要有一定“准确性”，并且要有“多样性”）</li>
<li>式 8.3 关键假设：基学习器的误差相互独立<ul>
<li>但在现实任务中，个体学习器是为解决同一个问题训练出来的，显然不可能相互独立</li>
<li>事实上，个体学习器的“准确性”和“多样性”本身就存在冲突</li>
</ul>
</li>
<li>根据<strong>个体学习器的生成方式</strong>，集成学习方法分两大类：<ul>
<li><strong>序列化方法</strong>：个体学习器间存在强依赖关系、必须串行生成。（Boosting）</li>
<li><strong>并行化方法</strong>：个体学习器间不存在强依赖关系、可同时生成。（Bagging和随机森林）</li>
</ul>
</li>
</ul>
<h3 id="8-2-Boosting"><a href="#8-2-Boosting" class="headerlink" title="8.2 Boosting"></a>8.2 Boosting</h3><ul>
<li>Boosting是一族可将弱学习器提升为强学习器的算法<ul>
<li>机制：先从初始训练集训练出一个基学习器，再根据基学习器的表现对训练样本的分布进行调整，使得先前基学习器做错的训练样本在后续受到更多关注，然后基于调整后的样本分布来训练下一个基学习器；如此重复进行，直至基学习器数目达到事先指定的值 $T$，最终将这 $T$ 个基学习器加权结合</li>
</ul>
</li>
<li>adaboost用指数损失函数最小化，分类错误率也最小化，达到了贝叶斯最优错误率。指数损失函数是分类任务原本0/1损失函数的一致的替代损失函数。<ul>
<li>指数损失函数是连续可微函数</li>
</ul>
</li>
<li>Boosting 算法在训练的每一轮都要检查当前生成的基学习器是否满足基本条件（检查基分类器是否比<strong>随机猜测</strong>好），一旦条件不满足，则当前基学习器即被抛弃，且学习过程停止</li>
<li>Boosting 算法要求基学习器能对特定的数据分布进行学习，这可通过<strong>“重赋权法”</strong>实施；对无法接受带权样本的基学习算法，则可通过<strong>“重采样法“</strong>来处理</li>
<li>从偏差-方差分解的角度看，Boosting主要关注<strong>降低偏差</strong>。因此Boosting能基于<strong>泛化性能相当弱</strong>的学习器构建出很强的集成</li>
</ul>
<h3 id="8-3-Bagging与随机森林"><a href="#8-3-Bagging与随机森林" class="headerlink" title="8.3 Bagging与随机森林"></a>8.3 Bagging与随机森林</h3><ul>
<li>bagging：Bootstrap AGGregatING</li>
<li>Bagging 基本流程：用自助法采样出 $T$ 个含 $m$ 个训练样本的采样集，然后基于每个采样集训练出一个基学习器，再将这些基学习器进行结合。在对预测输出进行结合时，Bagging 通常对分类任务使用简单投票法，对回归任务使用简单平均法</li>
<li>训练一个 Bagging 集成与直接使用基学习器算法训练一个学习器的复杂度同阶。说明 Bagging 是一个很高效的集成学习算法</li>
<li>包外样本作用<ul>
<li>基学习器是决策树时，用来辅助剪枝，或用于估计决策树中各节点的<strong>后验概率</strong>以辅助对零训练样本结点的处理；</li>
<li>基学习器是神经网络时，可使用包外样本来辅助早停以减小过拟合风险</li>
</ul>
</li>
<li>Bagging 泛化误差的包外估计为 $\epsilon^{oob}=\frac{1}{|D|}\sum_{(x,y)\in D}\mathbb{I}(H^{oob}(x)\not= y)$<ul>
<li>直接除以训练集 $D$ 样本个数，也就是说此处假设 $T$ 个基分类器的各自的包外样本的并集一定为训练集 $D$。（成立概率较大，对于每个基分类器，样本属于包内的概率为 0.632）</li>
</ul>
</li>
<li>从偏差-方差分解角度看，Bagging 主要关注<strong>降低方差</strong>，因此在不剪枝决策树、神经网络等易受样本扰动的学习器上效用更为明显</li>
</ul>
<ul>
<li><strong>随机森林</strong>（random forest）是 <strong>Bagging 的一个扩展变体</strong>。RF 在<strong>以决策树为基学习器</strong>构建 Bagging 集成的基础上，进一步在<strong>决策树的训练过程</strong>中引入了<strong>随机属性选择</strong>。<ul>
<li>重点一：以决策树为基学习器</li>
<li>重点二：在基学习器训练过程中，选择划分属性时只使用当前结点属性集合的一个子集，再从这个子集中选择一个最优属性用于划分</li>
</ul>
</li>
<li>多样性<ul>
<li>Bagging 中基学习器的”多样性“：通过<strong>样本扰动</strong>（对初始训练集采样）</li>
<li>随机森林中基学习器的”多样性“：不仅来自<strong>样本扰动</strong>，还来自<strong>属性扰动</strong>（个体学习器之间的差异度增加，泛化性提升）</li>
</ul>
</li>
<li>随机森林的训练效率常优于 Bagging。随机森林用的是”随机型“的决策树，选择划分属性时只需考察一个属性子集</li>
</ul>
<h3 id="8-4-结合策略"><a href="#8-4-结合策略" class="headerlink" title="8.4 结合策略"></a>8.4 结合策略</h3><ul>
<li><strong>学习器结合</strong>可能从三个方面带来好处<ul>
<li><strong>统计的原因</strong>：学习任务假设空间往往很大，可能有多个假设在训练集上达到同等性能，若使用<u>单学习器可能因误选</u>而导致泛化性能不佳。结合多个学习器则会减小这一风险</li>
<li><strong>计算的原因</strong>：学习算法往往会<u>陷入局部极小</u>，有的局部极小点所对应的泛化性能可能很糟糕，而多次运行之后进行结合，可降低陷入糟糕局部极小点的风险</li>
<li><strong>表示的原因</strong>：某些学习任务的真实假设可能不在当前学习算法所考虑的假设空间中，通过结合多个学习器，由于<u>相应的假设空间有所扩大</u>，有可能学得更好的近似</li>
</ul>
</li>
<li>对基学习器进行结合的策略<ul>
<li>平均法（数值型输出）<ul>
<li>简单平均法</li>
<li>加权平均法</li>
</ul>
</li>
<li>投票法（分类任务）<ul>
<li>绝对多数投票法（若某标记得票过半数，则预测为该标记）</li>
<li>相对多数投票法</li>
<li>加权投票法</li>
</ul>
</li>
<li>学习法<ul>
<li>代表 Stacking：把个体学习器称为初级学习器，用于结合的学习器称为次级学习器或元学习器</li>
<li>思路：Stacking 先从初始数据集训练出初级学习器，然后“生成”一个新数据集用于训练次级学习器。在这个新数据集中，初级学习器的输出被当作<strong>样例输入特征</strong>，而初始样本的标记仍被当作样例标记。</li>
</ul>
</li>
</ul>
</li>
<li>加权平均法的权重一般是从训练数据中学习而得，不完全可靠/过拟合。加权平均法未必一定优于简单平均法。个体学习器性能相差较大时使用加权平均法，个体学习器性能相近时使用简单平均法</li>
<li>若<strong>基学习器的类型不同</strong>，则其类概率值不能直接进行比较。在此情形下，通常可将类概率输出转化为类标记输出（例如将类概率输出最大的 $h_i^j(x)$ 设为1，其他设为0）然后再投票</li>
<li>训练阶段，次级训练集是利用初级学习器产生的，若直接用初级学习器的训练集来产生次级训练集，则<strong>过拟合风险会比较大</strong>；因此，一般是通过使用交叉验证或留一法这样的方式，用训练初级学习器未使用的样本来产生次级学习器的训练样本</li>
</ul>
<h3 id="8-5-多样性"><a href="#8-5-多样性" class="headerlink" title="8.5 多样性"></a>8.5 多样性</h3><ul>
<li><p>误差-分歧分解</p>
<ul>
<li>$\overline{A}(h|x)=\overline{E}(h|x)-E(H|x)$</li>
<li>$\overline{E}=\sum_{i=1}^T w_iE_i$：个体学习器泛化误差的加权均值</li>
<li>$\overline{A}=\sum_{i=1}^T w_i A_i$：个体学习器的加权分歧值</li>
<li>$E =\overline{E}-\overline{A}$：个体学习器准确性越高、多样性越大，则集成越好</li>
</ul>
</li>
<li><p>多样性度量</p>
<ul>
<li>不合度量</li>
<li>相关系数</li>
<li>$Q-$统计量</li>
<li>$\mathcal{K}-$统计量<ul>
<li>分类器 $h_i$ 与 $h_j$ 在 $D$ 上完全一致，则 $\mathcal{K}=1$</li>
<li>若它们仅是偶然达成一致，则 $\mathcal{K}=0$</li>
<li>$\mathcal{K}$ 越大，多样性越小</li>
</ul>
</li>
</ul>
</li>
<li><p>多样性增强</p>
<ul>
<li>数据样本扰动：通常基于采样法<ul>
<li>Bagging 中使用自主采样；Adaboost 中使用序列采样</li>
<li>对稳定基学习器（线性学习器、SVM、朴素贝叶斯、k近邻）进行集成往往需使用输入属性扰动等其他机制</li>
</ul>
</li>
<li><p>输入属性扰动（随机子空间算法）</p>
</li>
<li><p>输出表示扰动</p>
<ul>
<li>翻转法：随机改变一些训练样本的标记</li>
<li>输出调制法：将分类输出转化为回归后构建个体学习器</li>
<li>ECOC法：将原任务拆解为多个可同时求解的子任务。ECOC利用纠错输出码将多分类任务拆解为一系列二分类任务来训练基学习器</li>
</ul>
</li>
<li>算法参数扰动</li>
</ul>
</li>
<li><p>随机森林中同时使用了数据样本扰动和输入属性扰动</p>
</li>
</ul>
<h1 id="第9章-聚类"><a href="#第9章-聚类" class="headerlink" title="第9章 聚类"></a>第9章 聚类</h1><h3 id="9-1-聚类任务"><a href="#9-1-聚类任务" class="headerlink" title="9.1 聚类任务"></a>9.1 聚类任务</h3><ul>
<li>无监督学习：训练样本的标记信息是未知的，目标是通过对无标记训练样本的学习来揭示数据的内在性质及规律，为进一步的数据分析提供基础</li>
<li>聚类既能作为一个单独过程，用于寻找<strong>数据内在的分布结构</strong>，也可作为<strong>分类等其他学习任务的前驱过程</strong></li>
</ul>
<h3 id="9-2-性能度量"><a href="#9-2-性能度量" class="headerlink" title="9.2 性能度量"></a>9.2 性能度量</h3><ul>
<li>聚类性能度量亦称聚类“有效性指标”</li>
<li>对<strong>聚类结果</strong>，需通过某种性能度量来<strong>评估其好坏</strong>；另一方面，若明确了最终将要使用的性能度量，可直接将其作为<strong>聚类过程的优化目标</strong></li>
<li>聚类结果希望<strong>“簇内相似度”高</strong>且<strong>“簇间相似度”低</strong></li>
<li>聚类性能度量，两类<ul>
<li>将聚类结果与某个“<strong>参考模型</strong>”进行比较，称为<strong>外部指标</strong><ul>
<li>Jaccard 系数，FM 指数（Fowlkes and Mallows Index，简称 FMI），Rand 指数（Rand Index，简称 RI）</li>
<li>结果值均在 [0,1] 区间，值越大越好</li>
</ul>
</li>
<li>直接考察聚类结果而不利用任何参考模型，称为<strong>内部指标</strong><ul>
<li>DB 指数（Davies-Bouldin Index，简称 DBI），Dunn 指数（Dunn Index，简称 DI）</li>
<li>DBI 的值越小越好；DI 值越大越好</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="9-3-距离计算"><a href="#9-3-距离计算" class="headerlink" title="9.3 距离计算"></a>9.3 距离计算</h3><ul>
<li>距离度量的性质<ul>
<li>非负性</li>
<li>同一性（自反）：$dist(x_i,x_j)=0$ 当且仅当  $x_i=x_j$</li>
<li>对称性</li>
<li>直递性（三角不等式）</li>
</ul>
</li>
<li>闵可夫斯基距离 $dist_{mk}(x_i,x_j)=(\sum_{u=1}^n|x_{iu}-x_{ju}|^p)^{\frac{1}{p}}$<ul>
<li>注意是绝对值</li>
<li>闵可夫斯基距离可用于<strong>有序属性</strong>（离散属性和连续属性都可能是有序属性）</li>
</ul>
</li>
<li>对<strong>无序属性</strong>，可用 VDM（Value Difference Metric）<ul>
<li>属性 $u$ 上两个离散值 $a$ 和 $b$ 之间的 VDM 距离为 $VDM_p(a,b)=\sum_{i=1}^k|\frac{m_{u,a,i}}{m_{u,a}}-\frac{m_{u,b,i}}{m_{u,b}}|^p$</li>
</ul>
</li>
<li>对<strong>混合属性</strong>，可使用 MinkovDM<ul>
<li>$MinkovDM_p(x_i,x_j)=(\sum_{u=1}^{n_c}|x_{iu}-x_{ju}|^p+\sum_{u=n_c+1}^n VDM_p(x_{iu},x_{ju}))^{\frac{1}{p}}$</li>
</ul>
</li>
</ul>
<ul>
<li>用于相似度度量的距离<strong>未必一定要满足</strong>距离度量的所有基本性质，尤其是<strong>直递性</strong>。</li>
<li>距离不再满足直递性，这样的距离称为“非度量距离”</li>
</ul>
<h3 id="9-4-原型聚类"><a href="#9-4-原型聚类" class="headerlink" title="9.4 原型聚类"></a>9.4 原型聚类</h3><ul>
<li>“基于原型的聚类”</li>
<li>假设：聚类结构能<strong>通过一组原型刻画</strong></li>
<li>过程：先对<strong>原型初始化</strong>，然后对原型进行<strong>迭代更新求解</strong></li>
<li>代表：k均值聚类，学习向量量化（LVQ），高斯混合聚类</li>
</ul>
<ul>
<li>“原型”是指样本空间中具有代表性的点</li>
</ul>
<ul>
<li><strong>k均值算法（k-means）</strong></li>
<li>无监督</li>
<li>最小化平方误差 $E=\sum_{i=1}^k\sum_{x\in C_i}||x-\mu_i||_2^2$</li>
<li>一定程度上刻画了簇内样本围绕簇均值向量的紧密程度，$E$ 值越小则簇内样本相似度越高</li>
<li>最小化 $E$ 是 NP难问题。k均值用<strong>贪心策略</strong>，通过<strong>迭代优化来近似求解</strong></li>
</ul>
<ul>
<li><strong>学习向量量化（Learning Vector Quantization，LVQ）</strong></li>
<li>有监督</li>
<li>LVQ 假设数据样本带有<strong>类别标记</strong>，学习过程利用样本的<strong>监督信息</strong>来辅助聚类</li>
<li>对原型向量进行初始化时，可以对第 $q$ 个簇从<strong>类别标记</strong>为 $t_q$ 的样本中随机选取一个作为原型向量（$t_i$ 可以有相同）</li>
<li>每一轮迭代，<strong>随机</strong>选一个有标记训练样本，找出<strong>距离最近的原型向量</strong><ul>
<li>竞争学习的“胜者为王”策略。SOM 是基于无标记样本的聚类算法，LVQ 可看作 SOM 基于监督信息的扩展</li>
</ul>
</li>
<li>根据两者的<strong>类别标记是否一致</strong>来对原型向量进行相应的更新<ul>
<li>对样本 $x_j$，若最近的原型向量 $p_{i^<em>}$ 与 $x_j$ 的<strong>类别标记相同</strong>，则令 $p_{i^</em>}$ 向 $x_j$ 的方向<strong>靠拢</strong>，否则<strong>远离</strong></li>
</ul>
</li>
<li>Voronoi 剖分：对样本空间 $\mathcal{X}$ 的簇划分 $\{R_1,R_2,…,R_q\}$。对任意样本 $x$，被划分入与其距离最近的原型向量所代表的簇中。即每个原型向量 $p_i$ 定义了与之相关的一个区域 $R_i$，该区域中每个样本与 $p_i$ 的距离不大于它与其他原型向量 $p_{i’}$ 的距离。</li>
</ul>
<ul>
<li><strong>高斯混合聚类（Mixture-of-Gaussian）</strong></li>
<li>k均值、LVQ 用<strong>原型向量</strong>刻画聚类结构；高斯混合聚类用<strong>概率模型（高斯分布）</strong>来表达聚类原型，簇划分则由<strong>原型对应后验概率</strong>确定</li>
<li>定义高斯混合分布 $p_\mathcal{M}(x)=\sum_{i=1}^k\alpha_i\cdot p(x|\mu_i,\Sigma_i)$。$\alpha_i$ 是混合系数，和为1。样本的生成过程：<ul>
<li>根据 $\alpha_1,\alpha_2,…,\alpha_k$ 定义的先验分布选择<strong>高斯混合成分</strong>，其中 $\alpha_i$ 为选择第 $i$ 个混合成分的概率</li>
<li>根据被选择的混合成分的概率密度函数进行采样，从而生成相应的样本</li>
<li>$z_j$ 表示生成样本 $x_j$ 的高斯混合成分。根据贝叶斯定理，$z_j$ 的后验分布对应于 $p_\mathcal{M}(z_j=i|x_j)=\frac{\alpha_i\cdot p(x_j|\mu_i,\Sigma_i)}{\sum_{l=1}^k \alpha_l\cdot p(x_j|\mu_l,\Sigma_l)}$，即样本 $x_j$ 由第 $i$ 个高斯混合成分生成的后验概率</li>
<li>模型参数 $\{(\alpha_i,\mu_i,\Sigma_i)\}$ 求解：最大化对数似然，常用 EM 算法进行迭代优化求解</li>
<li>$\mu_i=\frac{\sum_{j=1}^m\gamma_{ji} x_j}{\sum_{j=1}^m\gamma_{ji}}$ ：各混合成分的均值可通过样本加权平均来估计，样本权重是每个样本属于该成分的后验概率</li>
<li>$\alpha_i=\frac{1}{m}\sum_{j=1}^m\gamma_{ji}$：每个高斯成分的混合系数由样本属于该成分的平均后验概率确定</li>
</ul>
</li>
<li>高斯混合模型的 EM 算法：<ul>
<li>E 步：先根据当前参数 $\{(\alpha_i,\mu_i,\Sigma_i)\}$ 来计算每个样本属于每个高斯成分的后验概率 $\gamma_{ji}$</li>
<li>M 步：再根据对对数似然求导/拉格朗日法，更新模型参数 $\{(\alpha_i,\mu_i,\Sigma_i)\}$</li>
</ul>
</li>
</ul>
<ul>
<li>迭代停止条件：已达到最大轮数 / 似然函数 $LL(D)$ 增长很少甚至不再增长</li>
</ul>
<h3 id="9-5-密度聚类"><a href="#9-5-密度聚类" class="headerlink" title="9.5 密度聚类"></a>9.5 密度聚类</h3><ul>
<li>“基于密度的聚类”</li>
<li>假设：聚类结构能通过<strong>样本分布的紧密程度</strong>确定</li>
<li>过程：从样本密度的角度来考察样本之间的可连接性，并基于可连接样本不断扩展聚类簇</li>
<li>代表：DBSCAN、OPTICS、DENCLUE</li>
</ul>
<ul>
<li><strong>DBSCAN（Density-Based Spatial Clustering of Applications with Noise）</strong></li>
<li>基于一组“邻域”参数 $(\epsilon,MinPts)$ 来刻画样本分布的紧密程度</li>
<li><strong>核心对象</strong>：$\epsilon$-邻域内至少包含 $MinPts$ 个样本</li>
<li><strong>密度直达</strong>：$x_j$ 在 $x_i$ 的 $\epsilon$-邻域中，且 $x_i$ 是核心对象，则称 $x_j$ 由 $x_i$ 密度直达<ul>
<li>通常不满足对称性（$x_j$ 不一定是核心对象）</li>
</ul>
</li>
<li><strong>密度可达</strong>：对 $x_i$ 与 $x_j$，若存在样本序列 $p_1,p_2,…,p_n$，其中 $p_1=x_i,p_n=x_j$，且 $p_{i+1}$ 由 $p_i$ 密度直达，则称 $x_j$ 由 $x_i$ 密度可达<ul>
<li>满足<strong>直递性</strong>，但<strong>不满足对称性</strong></li>
</ul>
</li>
<li><strong>密度相连</strong>：对 $x_i$ 与 $x_j$，若<strong>存在 $x_k$ 使得 $x_i$ 与 $x_j$ 均由 $x_k$ 密度可达</strong>，则称 $x_i$ 与 $x_j$ 密度相连<ul>
<li>满足对称性</li>
</ul>
</li>
<li><p><strong>核心对象</strong>之间的密度直达/可达满足<strong>对称性</strong></p>
</li>
<li><p>DBSCAN 将“簇”定义为：由<strong>密度可达关系</strong>导出的<strong>最大的密度相连样本集合</strong></p>
<ul>
<li>给定邻域参数 $(\epsilon,Minpts)$，簇 $C\subseteq D$ 是满足<strong>连接性和最大性</strong>的非空样本子集<ul>
<li>连接性：$x_i\in C,x_j\in C\Rightarrow x_i与x_j密度相连$</li>
<li>最大性：$x_i\in C,x_j由x_i密度可达 \Rightarrow x_j\in C$</li>
</ul>
</li>
<li>若 $x$ 为<strong>核心对象</strong>，由 $x$ <strong>密度可达</strong>的所有样本组成的集合 $X$ 为满足<strong>连接性和最大性</strong>的簇</li>
</ul>
</li>
</ul>
<ul>
<li><strong>层次聚类</strong></li>
<li>假设：能够产生不同粒度的聚类结果</li>
<li>过程：在不同层次对数据集进行划分，从而形成树形的聚类结构</li>
<li>代表：AGNES（自底向上），DIANA（自顶向下）</li>
</ul>
<ul>
<li>AGNES（AGglomerative NESting）<ul>
<li>是一种采用<strong>自底向上聚合</strong>策略的层次聚类算法。先将数据集中的每个样本看作一个初始聚类簇，然后在算法运行的每一步中找出<strong>距离最近的两个聚类簇</strong>进行合并，并对合并得到的聚类簇的距离矩阵进行更新；不断重复，直至达到预设的聚类簇个数</li>
<li>距离：<ul>
<li>最小距离 $d_{min}$（由两个簇的最近样本决定），AGNES 算法被相应地称为“单链接”算法</li>
<li>最大距离 $d_{max}$（..最远样本），“全链接”算法</li>
<li>平均距离 $d_{avg}$（所有样本决定），“均链接”算法</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="第10章-降维与度量学习"><a href="#第10章-降维与度量学习" class="headerlink" title="第10章 降维与度量学习"></a>第10章 降维与度量学习</h1><h3 id="10-1-k近邻学习"><a href="#10-1-k近邻学习" class="headerlink" title="10.1 k近邻学习"></a>10.1 k近邻学习</h3><ul>
<li>什么是KNN？<ul>
<li><strong>监督学习</strong>方法。给定测试样本，<strong>基于某种距离度量</strong>找出训练集中与其最靠近的 $k$ 个训练样本，然后基于这 $k$ 个“邻居”的信息来进行预测</li>
</ul>
</li>
<li>KNN 在分类任务中可使用“投票法”，在回归任务中可使用“平均法”，还可基于距离远近进行加权平均或加权投票，距离越近的样本权重越大</li>
<li>懒惰学习，在训练阶段仅仅是把样本保存起来，训练时间开销为零，待收到测试样本后再进行处理</li>
<li>当训练样本趋于<strong>无穷</strong>时 $(n\rightarrow ∞)$，<strong>最近邻的错误率</strong>最多是<strong>最佳错误率</strong>的<strong>两倍</strong>；有限样本时的结论尚不清楚</li>
</ul>
<p><img src="image-20230307154735174.png" alt="image-20230307154735174" style="zoom:50%;"></p>
<ul>
<li>补充假设，$P(c|x)$ 必须是连续函数（对于连续函数 $f(x)$ 和任意小正数 $\delta$，$f(x)\approx f(x+\delta)$），即对于两个非常像的样本 $z$ 和 $x$ 有 $P(c|x)\approx P(c|z)$</li>
</ul>
<ul>
<li>降低NN的计算、存储代价<ul>
<li>近似最近邻（ANN）<ul>
<li>不要求一定是距离最短的 $k$ 个</li>
<li>第 $k$ 个NN的距离是 $d_k$，ANN要求其选取的所有 $k$ 个样例的距离 $\hat{d}\leq (1+\epsilon)d_k$ 即可</li>
<li>可将KNN搜索速度提高几个数量级</li>
</ul>
</li>
<li>二值哈希（binary hashing）<ul>
<li>hash函数 $f_i$ 将 $\mathbb{R}^d$ 分成两部分，$f_i=0/1$</li>
<li>m个hash函数，每个 $x$ 表示为m个bits</li>
<li>$m\ll d$，减少计算和存储</li>
<li>进一步：基于深度学习的哈希</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="10-2-低维嵌入"><a href="#10-2-低维嵌入" class="headerlink" title="10.2 低维嵌入"></a>10.2 低维嵌入</h3><ul>
<li>上一节的讨论是基于密采样假设：任意测试样本 $x$ 附近任意小的 $\delta$ 距离范围内总能找到一个训练样本</li>
<li>维数灾难：在高维情形下出现的<strong>数据样本稀疏</strong>、<strong>距离计算困难</strong>等问题<ul>
<li>KNN中若基于<strong>密采样假设</strong>，当属性维度很高时，需要很多数据（密采样假设：样本的每个 $\epsilon-$邻域都有近邻）</li>
<li>缓解途径之一：降维</li>
<li>高维空间中的低维嵌入</li>
</ul>
</li>
<li><strong>多维缩放（Multiple Dimensional Scaling，MDS）</strong><ul>
<li>要求原始空间中样本之间的距离在低维空间中得以保持</li>
<li>在保持距离矩阵相同的前提下，$d’$ 维空间的样本集合 $Z\in\mathbb{R}^{d’×m}$ 的<strong>内积矩阵</strong> $B=Z^TZ\in\mathbb{R}^{m×m}$ 可以由距离矩阵得到。再对 $B$ 进行特征值分解即可得到 $Z$</li>
<li><img src="image-20230322175920210.png" alt="image-20230322175920210" style="zoom:50%;"></li>
<li><img src="image-20230307170703736.png" alt="image-20230307170703736" style="zoom:67%;"></li>
<li>实对称矩阵的性质<ul>
<li>实对称矩阵的属于不同特征值对应的特征向量相互正交</li>
<li>设 $A$ 为 $n$ 阶实对称矩阵，则必存在正交阵 $Q$，使得 $Q^{-1}AQ=Q^TAQ=\Lambda$</li>
<li>MDS中，$B=V\Lambda V^T$</li>
</ul>
</li>
</ul>
</li>
<li>线性降维 $Z=W^TX$，$W\in\mathbb{R}^{d×d’}$ 是变换矩阵，$X=(x_1,..,x_m)\in\mathbb{R}^{d×m}$，$Z\in\mathbb{R}^{d’×m}$ 是样本在新空间的表达<ul>
<li>变换矩阵可视为 $d’$ 个 $d$ 维基向量，$z_i=W^Tx_i$ 是原属性向量在新坐标系 $\{w_1,…,w_{d’}\}$ 中的坐标向量</li>
<li>新空间中的属性是原空间中属性的线性组合</li>
</ul>
</li>
</ul>
<h3 id="10-3-主成分分析"><a href="#10-3-主成分分析" class="headerlink" title="10.3 主成分分析"></a>10.3 主成分分析</h3><ul>
<li><p>PCA（<strong>Principal Component Analysis，主成分分析</strong>）</p>
<ul>
<li>PCA利用正交变换把<strong>线性相关变量</strong>表示的观测数据转换为少数几个由<strong>线性无关变量</strong>表示的数据，线性无关的变量称为<strong>主成分</strong>，实则，<strong>协方差矩阵的特征向量</strong>。PCA属于降维方法。</li>
</ul>
</li>
<li><p>PCA是一种线性的特征提取方法（组合？），也是一种线性的降维技术</p>
</li>
<li><p>降维的好处 / 舍弃最小的 $d-d’$ 个特征值的特征向量的好处</p>
<ul>
<li>降低资源需求</li>
<li><strong>去除（白）噪声</strong>（当特征值非常小时，可能是由于白噪声，或其他类型的噪声）</li>
<li>舍弃这部分信息后能使样本的<strong>采样密度增大</strong>（<strong>降维的重要动机</strong>）</li>
<li>解释与理解（降维后<strong>可视化</strong>）</li>
</ul>
</li>
<li><p>什么是<strong>主成分</strong>？</p>
<ul>
<li>是一组向量，可以较低维度上概括原本较高维度数据的分布</li>
<li>实则，协方差矩阵的特征向量</li>
</ul>
</li>
<li><p>需要<strong>多少维度</strong>？</p>
<p>​    1、用户事先指定</p>
<p>​    2、在 $d’$ 值不同的低维空间中对 $k$ 近邻分类器（或其他开销较小的学习器）进行交叉验证选取较好的 $d’$ 值</p>
<p>​    3、从重构的角度设置一个重构阈值，比如 累积的特征值已经超过所有特征值之和的90%，则选择在此停止</p>
</li>
<li><p>如何处理<strong>新样本</strong>？</p>
<ul>
<li>保留 $W^<em>$ 与<em>*样本的均值向量</em></em>，即可用向量减法和矩阵-向量乘法将新样本投影到低维空间</li>
<li>保存均值向量是为了通过向量减法对新样本同样进行中心化</li>
</ul>
</li>
<li><p>PCA中：（投影值的）方差 = 协方差矩阵的特征值 = 近似误差的减少</p>
</li>
<li><p>特征值越大，其对应的特征向量（投影方向）将更大幅度地减小近似误差</p>
</li>
<li><p>最近重构性 角度（<strong>最小重构误差</strong>）</p>
<ul>
<li><p>最小化 $\sum_{i=1}^{m}||\sum_{j=1}^{d’}z_{ij}w_j-x_i||_2^2\propto -tr(W^T(\sum_{i=1}^mx_ix_i^T)W)$</p>
<p>样本点 $x_i$ 在低维坐标系中的投影是 $z_i=(z_{i1};z_{i2};..;z_{id’})$，其中 $z_{ij}=w_j^Tx_i$ 是 $x_i$ 在低维坐标系下第 $j$ 维的坐标。基于 $z_j$ 来重构 $x_i$，得 $\hat{x}_i=\sum_{j=1}^{d’}z_{ij}w_j$。</p>
<p>$w_j$ 是标准正交基向量。</p>
</li>
<li><p>即 $\min_{W}-tr(W^TXX^TW)$   s.t. $W^TW=I$ </p>
</li>
<li><p>$Z=W^TX$，即寻找 $W\in\mathbb{R}^{d×d’}$ 使协方差矩阵 $\frac{1}{m}ZZ^T$ 对角线元素之和（迹）/ $Z$ 各行方差之和 最大</p>
</li>
<li><p>$\min_{W}-tr(W^TXX^TW)=\max_{W}\sum_{i=1}^{d’}\lambda_i$。令 $\lambda_1,..\lambda_{d’}$ 和 $w_1,…w_{d’}$ 分别为矩阵 $XX^T$ 的前 $d’$ 个最大的特征值和单位特征向量。</p>
</li>
<li><p>重建：$x=\overline{x}+WW^T(x-\overline{x})=\overline{x}+Wy$ </p>
</li>
<li><p>特征值越大，其对应的特征向量（投影方向）将更大幅度地减小近似误差</p>
</li>
</ul>
</li>
<li><p>最大可分性 角度（<strong>最大化投影方差</strong>）</p>
<ul>
<li>方差是衡量<strong>新特征包含信息多少</strong>的度量，有时也称<strong>能量</strong></li>
<li>投影后样本点的方差是 $\sum_i W^Tx_ix_i^TW$，可写为 $\max_W tr(W^TXX^TW)$   s.t. $W^TW=I$</li>
</ul>
</li>
</ul>
<ul>
<li>$y=W^T(x-\overline{x})$<ul>
<li>$W$ 是<strong>正交矩阵</strong>，那么如果使用了<strong>所有的特征向量</strong>，PCA只是一个<strong>位移加一个旋转变换</strong>，使新特征各个维度<strong>互不相关</strong>（对高斯分布，还意味着互相独立）</li>
<li>且在此情况下，范数不变 $||y||=||x-\overline{x}||$ </li>
</ul>
</li>
</ul>
<ul>
<li><p>PCA算法步骤（给定样本集、降维后低维空间的维度 $d’$）</p>
<ul>
<li>对所有样本进行<strong>中心化</strong>       $X(I-\frac{1}{m}11^T)$</li>
<li>计算样本的协方差矩阵 $XX^T$</li>
<li>对协方差矩阵 $XX^T$ 做特征值分解（实践中常对 $X$ 进行奇异值分解代替）</li>
<li>取最大的 $d’$ 个特征值所对应的特征向量 $w_1,w_2,…,w_{d’}$，得到投影矩阵 $W^*=(w_1,w_2,…,w_{d’})$</li>
</ul>
</li>
<li><p>PCA也可看作是<strong>逐一选取方差最大方向</strong></p>
<ul>
<li><img src="image-20230322090437528.png" alt="image-20230322090437528" style="zoom:50%;"></li>
</ul>
</li>
<li><p><img src="image-20230519131936327.png" alt="image-20230519131936327" style="zoom:50%;"></p>
</li>
<li><p>白化变化</p>
<ul>
<li><p>$\Sigma=\sum_{i=1}^d \lambda_i\xi_i\xi_i^T=\sum_{i=1}^d\lambda_i w_i w_i^T=W\Lambda W^T$</p>
<p>$y=(W\Lambda^{-\frac{1}{2}})^T(x-\mu)$    （即 $\frac{x-\mu}{\sigma}$）（直接记）</p>
</li>
<li><p>$y\sim\mathcal{N}(0,I)$，各向同性</p>
</li>
<li><p>什么时候需要做白化变换？</p>
<ul>
<li>后续(分类)任务中是否需要特征的相对重要性</li>
</ul>
</li>
<li><p><img src="image-20230326200656657.png" alt="image-20230326200656657" style="zoom:50%;"></p>
</li>
</ul>
</li>
<li><p>什么时候使用/不使用PCA？</p>
<ul>
<li>如果数据服从高斯分布<ul>
<li>单峰分布（<strong>单个高斯分布</strong>）</li>
<li>白噪声<ul>
<li>$x=x’+\epsilon$，$\epsilon\sim\mathcal{N}(0,\Gamma)$</li>
<li>噪声独立于数据，噪声均值为0，各维独立（$\Gamma$ 是对角阵），噪声幅度有限</li>
<li>此时PCA效果最佳</li>
</ul>
</li>
</ul>
</li>
<li>实际上如果<strong>特征值服从指数递减</strong>即可</li>
<li>PCA<strong>不能处理离群值</strong>（PCA本质是拟合线性数据，但outliner是高度非线性的）</li>
</ul>
</li>
<li><p>PCA有利于表示数据，但和分类无关</p>
</li>
</ul>
<ul>
<li>PCA 人脸识别<ul>
<li>计算训练样本的协方差矩阵并计算其特征值和特征向量，保留最大的几个特征值对应的特征向量作为特征脸</li>
<li>高维的人脸可以用特征脸的线性组合近似表示</li>
</ul>
</li>
</ul>
<h3 id="10-4-核化线性降维"><a href="#10-4-核化线性降维" class="headerlink" title="10.4 核化线性降维"></a>10.4 核化线性降维</h3><ul>
<li><p>核主成分分析（Kernelized PCA, KPCA）：一种非线性降维方法，基于核技巧对线性降维方法进行“核化”</p>
</li>
<li><p>$\phi(X)\phi^T(X)$ 当数据维度大时，难以特征值分解</p>
</li>
<li><script type="math/tex; mode=display">
\phi(X)\phi^T(X)w_j=\lambda_jw_j\\
\sum_{i=1}^m\phi(x_i)\phi^T(x_i)w_j=\lambda_jw_j\\
\sum_{i=1}^m\phi(x_i)\alpha_i^j=w_j\\
w_j=\phi(X)\alpha^j\,代入第一个式子\\
\phi(X)\phi^T(X)\phi(X)\alpha^j=\lambda_j\phi(X)\alpha^j\,左右同乘\phi^T(X)\\
\phi^T(X)\phi(X)\phi^T(X)\phi(X)\alpha^j=\lambda_j\phi^T(X)\phi(X)\alpha^j\\
K\cdot K\alpha^j=\lambda_j K\alpha^j\\
K\alpha^j=\lambda_j\alpha^j</script></li>
</ul>
<p>​    特征向量 $w_j$ 可以表示为所有 $\phi(x_i)$ 的线性组合</p>
<p>​    对于新样本 $x$，投影后的第 $j(j=1,2,…,d’)$ 维坐标为</p>
<script type="math/tex; mode=display">
z_j=w_j^T\phi(x)=\sum_{i=1}^m\alpha_i^j\phi(x_i)^T\phi(x)=\sum_{i=1}^m\alpha_i^j\mathcal{k}(x_i,x)</script><ul>
<li>KPCA需对所有样本求和，因此它的计算开销较大</li>
</ul>
<h3 id="10-5-流形学习"><a href="#10-5-流形学习" class="headerlink" title="10.5 流形学习"></a>10.5 流形学习</h3><ul>
<li><p>流形学习（manifold learning）：一类借鉴了<strong>拓扑流形概念</strong>的<strong>降维方法</strong></p>
<ul>
<li>流形：在局部具有欧氏空间的性质，能用欧氏距离来进行距离计算</li>
</ul>
</li>
<li><p>等度量映射（Isomap）</p>
<ul>
<li><p>低维嵌入流形上两点间距离是“测地线”距离</p>
</li>
<li><p>如何计算测地线距离：利用流形在局部上与欧氏空间同胚，对每个点基于欧氏距离找出其近邻点，然后就能建立一个<strong>近邻连接图</strong>，图中近邻点之间存在连接，非近邻点之间不存在连接。</p>
<p>计算两点间测地线距离的问题，转变为计算近邻连接图上两点间的最短路径问题。可用Dijkstra算法或Floyd算法。</p>
<p>得到任意两点距离后，可用MDS获得样本点在低维空间中的坐标。</p>
</li>
<li><p><img src="image-20230322183755288.png" alt="image-20230322183755288" style="zoom:50%;"></p>
</li>
<li><p>对于<strong>新样本</strong>，如何<strong>映射到低维空间</strong>？</p>
<ul>
<li>将<strong>训练样本</strong>的<strong>高维空间坐标</strong>作为输入、<strong>低维空间坐标</strong>作为输出，训练一个<strong>回归学习器</strong>来对新样本的低维空间坐标进行预测。</li>
</ul>
</li>
<li>近邻图的构建（$k$近邻图、$\epsilon$近邻图），不足：<ul>
<li>近邻范围指定得较大：距离很远的点可能被误认为近邻（短路）</li>
<li>近邻范围指定得较小：图中有些区域可能与其他区域不存在连接（断路）</li>
</ul>
</li>
</ul>
</li>
<li><p>局部线性嵌入（Locally Linear Embedding, LLE）</p>
<ul>
<li><p>Isomap：保持近邻样本之间的距离</p>
<p>LLE：保持邻域内样本之间的线性关系</p>
</li>
</ul>
</li>
</ul>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul>
<li>MDS的降维准则：原始空间中样本之间的距离在低维空间中得以保持</li>
<li>PCA的降维准则：要求低维子空间对样本具有最大可分性</li>
<li>Isomap与MDS区别：距离矩阵计算方法不同<ul>
<li>MDS中距离矩阵即为普通样本之间欧氏距离</li>
<li>Isomap中距离矩阵要先构建近邻图，再用最短路径算法，遵循流形假设</li>
</ul>
</li>
</ul>
<h1 id="第11章-特征选择与稀疏学习"><a href="#第11章-特征选择与稀疏学习" class="headerlink" title="第11章 特征选择与稀疏学习"></a>第11章 特征选择与稀疏学习</h1><ul>
<li>常见的特征选择方法：过滤式、包裹式和嵌入式<ul>
<li><strong>过滤式</strong>：先对数据集进行特征选择，然后再训练学习器，特征选择过程与后续学习器无关</li>
<li>包裹式：直接把最终将要使用的学习器的性能作为特征子集的评价准则</li>
<li>嵌入式：将特征选择过程与学习器训练过程融为一体，两者在同一个优化过程中完成（LASSO）</li>
</ul>
</li>
</ul>
<h1 id="模式识别"><a href="#模式识别" class="headerlink" title="模式识别"></a>模式识别</h1><h2 id="第八章-概率方法"><a href="#第八章-概率方法" class="headerlink" title="第八章 概率方法"></a>第八章 概率方法</h2><ul>
<li>PDF：probability density function</li>
<li>PMF：probability mass function</li>
<li>估计PDF就是估计参数</li>
</ul>
<ul>
<li>推理 inference：估计各种密度函数</li>
<li>决策 decision：据估计得到的PDF对任意的 $x$ 预测输出</li>
</ul>
<ul>
<li><p>非参数估计（Non-parametric）：不假设PDF是任何已知形式的函数</p>
<ul>
<li><p>使用<strong>训练数据</strong>直接估计空间中任何点的密度</p>
</li>
<li><p>非参数<strong>不代表无参数</strong>，实际上是可以<strong>允许无穷多的参数</strong>；而参数估计的参数个数是有限的</p>
</li>
</ul>
</li>
<li><p>参数化估计（ML,MAP频率派观点，贝叶斯 贝叶斯派观点）</p>
<ul>
<li>最大似然 ML<ul>
<li>视 $\theta$ 为<strong>固定参数</strong>，假设存在一个<strong>最佳的参数</strong>（或参数的真实值是存在的），目的是找到这个值</li>
<li>给定一个数据集 $D$ 和一个参数化的密度 $p$，我们定义 $p(D|\theta)=\prod_{i=1}^np(x_i|\theta)$</li>
<li>$p(D|\theta)$ 被称为（当参数值固定为 $\theta$ 时，观测到训练数据 $D$ 的）似然</li>
<li>因为 $\theta$ 不是一个随机变量，$p(D|\theta)$ <strong>不是一个条件分布</strong>。因此通常会定义一个<strong>似然函数</strong> $l(\theta)=\prod_{i=1}^np(x_i|\theta)$ ，则似然是关于 $\theta$ 的<strong>函数</strong></li>
</ul>
</li>
<li>最大后验 MAP<ul>
<li>考虑<strong>先验分布</strong> $p(\theta)$ ，将其影响代入，但<strong>仍然假设存在最优的参数</strong></li>
<li>将先验知识和训练数据同时纳入考虑（当只有少量训练样本可用时，可引入关于参数的领域知识）</li>
<li>假设不存在关于 $\sigma$ 的先验知识，但先验地假设 $\mu$ 服从高斯分布，如均值为5.5，且方差 $\sigma_0^2$ 很大，$p(\theta)=p(\mu,\sigma)=\frac{1}{\sqrt{2\pi}\sigma_0}\exp(-\frac{(\mu-5.5)^2}{2\sigma_0^2})$</li>
<li>MAP 估计求解 $\arg\max_\theta p(\theta)l(\theta)=\arg\max_{\theta}\{\ln p(\theta)+ll(\theta)\}$</li>
</ul>
</li>
<li>贝叶斯<ul>
<li>贝叶斯观点中，$\theta$ 是一个<strong>分布/随机变量</strong>，所以估计应该是<strong>估计一个分布</strong>，而不是一个值（点）</li>
<li>$p(\theta|D)$：是贝叶斯参数估计的<strong>输出</strong>，是一个<strong>完整的分布</strong>，而不是一个点</li>
</ul>
</li>
<li>参数估计的一些性质<ul>
<li>渐进性质：研究 $n\rightarrow ∞$ 时的性质。如<strong>一致性</strong>：随样本容量增大收敛到参数真值的估计量 </li>
<li>无偏估计：<strong>估计量</strong>的期望和<strong>被估计量</strong>的真值相等</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li><p>概率的<strong>频率</strong>学派观点</p>
<ul>
<li>ML，MAP，使用训练样本来找到这组固定但未知的参数值</li>
<li>估计结果是位于可能的参数空间中（不包含随机性）的一个固定点，因此被称为<strong>点估计</strong></li>
<li>点估计方法为 $\theta$ 返回一个单独的最优值</li>
</ul>
</li>
<li><p>概率的<strong>贝叶斯</strong>学派观点</p>
<ul>
<li>参数也被视为随机变量，要估计的不是一组固定的值，而是一些分布</li>
</ul>
</li>
</ul>
<h2 id="第九章-距离度量与数据变换"><a href="#第九章-距离度量与数据变换" class="headerlink" title="第九章 距离度量与数据变换"></a>第九章 距离度量与数据变换</h2><ul>
<li>metric data：实数向量、可以计算距离或相似程度</li>
<li>标记数据 Nominal data<ul>
<li>不是连续的实数值，也不可以比较大小，不可以比较相似性</li>
</ul>
</li>
<li>不相似程度 / 距离：欧氏距离</li>
<li>相似程度：内积 / RBF核</li>
</ul>
<ul>
<li><p>度量metric必须满足</p>
<ul>
<li>非负</li>
<li>自反：$d(x,y)=0$ 当且仅当 $x=y$</li>
<li>对称</li>
<li>三角不等式</li>
</ul>
</li>
<li><p>马氏距离：$d^{\color{Red}{2}}(x,y)=(x-y)^T\Sigma^{-1}(x-y)$</p>
<ul>
<li>$\Sigma$ 是数据的协方差矩阵</li>
<li>若对数据进行白化操作，则原空间中的马氏距离等价于白化变化以后新空间的欧式距离</li>
<li>推广：用半正定矩阵 $A$ 代替 $\Sigma^{-1}$<ul>
<li>$A$ 半正定，存在 $G$，使得 $A=G^TG$</li>
<li>$d^2_A(x,y)=||Gx-Gy||_2^2$</li>
<li>$A$ 没有被限定是正定的，通过放松，$||x-y||_A$ 不再是一个严格意义上的度量，因为即使 $x\not= y$，仍有可能 $||x-y||_A=0$。但这个放松允许我们学得一个固有的低维表示。如 $G\in \mathbb{R}^k×\mathbb{R}^d$ 且 $k&lt;d$ 时，$A$ 是半正定但不是正定的，$Gx$ 比 $x$ 有更低的维度</li>
<li>学习 $A$：利用标记信息<ul>
<li><img src="image-20230519140132273.png" alt="image-20230519140132273" style="zoom:50%;"></li>
<li>学到的距离度量应当使同一类的样例之间的距离越小越好（通过最小化目标函数），而使不同类的样例之间的距离比较大（通过第一个约束）。学到的最优距离度量对二分类问题很有用</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Minkowski distance：$d_p(x,y)=(\sum_{i=1}^d|x_i-y_i|^p)^{\frac{1}{p}}$<ul>
<li>$p\geq 1$ 时是metric</li>
<li>$L_0$ 不是metric</li>
</ul>
</li>
</ul>
<ul>
<li><p>幂平均函数</p>
<ul>
<li>$M_p(x_1,…,x_n)=({\color{Red}\frac{1}{n}}\sum_{i=1}^nx_i^p)^{\frac{1}{p}}$</li>
<li><img src="image-20230519143211591.png" alt="image-20230519143211591" style="zoom:50%;"></li>
<li>若 $p&lt;q$，则 $M_p(x_1,…,x_n)\leq M_q(x_1,…,x_n)$（但 $||x||_p\geq ||x||_q$）</li>
</ul>
</li>
<li><p>幂平均核</p>
<ul>
<li>$M_p(x,y)=\sum_{i=1}^dM_p(x_i,y_i)$</li>
<li><img src="image-20230519143831190.png" alt="image-20230519143831190" style="zoom:40%;"></li>
<li><img src="image-20230519151220401.png" alt="image-20230519151220401" style="zoom:50%;"><ul>
<li>直方图相交核（Histogram Intersection Kernel，HIK）</li>
</ul>
</li>
</ul>
</li>
<li><p><img src="image-20230519150809024.png" alt="image-20230519150809024" style="zoom:50%;"></p>
</li>
</ul>
<h2 id="第十章-信息论与决策树"><a href="#第十章-信息论与决策树" class="headerlink" title="第十章 信息论与决策树"></a>第十章 信息论与决策树</h2><ul>
<li>均匀分布是最不确定的情况，霍夫曼编码需要 $\lceil \log_2m\rceil$ 个比特编码每个符号</li>
<li>如果分布是连续的：微分熵 $h(x)=-\int p(x)\ln(p(x))dx$<ul>
<li>若 $X\sim N(\mu,\sigma^2)$，则 $h(X)=\frac{1}{2}\ln(2\pi e\sigma^2)$ nats</li>
<li>如果 $\sigma\ll 1$，$N(0,\sigma^2)$ 的熵是负的</li>
</ul>
</li>
<li>在所有<strong>均值和方差固定</strong>的连续分布中，高斯分布具有最大的熵（或者说，不确定性最大）</li>
<li>在<strong>知道均值</strong>的情况下，指数分布的熵最大</li>
<li>联合熵<ul>
<li>$H(X,Y)=-\sum_x\sum_yP(x,y)\log_2P(x,y)$</li>
<li>$h(X,Y)=-\int p(x.y)\ln p(x,y)dxdy$</li>
</ul>
</li>
<li>条件熵<ul>
<li>$H(X|Y)=\sum_yp(y)H(X|Y=y)=-\sum_{x,y}P(x,y)\log_2\frac{P(x,y)}{P(y)}$</li>
<li>$h(X|Y)=-\int p(x,y)\ln\frac{p(x,y)}{p(y)}dxdy$</li>
</ul>
</li>
<li><img src="image-20230519155511217.png" alt="image-20230519155511217" style="zoom:30%;"></li>
</ul>
<ul>
<li><script type="math/tex; mode=display">
\begin{align}
I(X;Y)&=H(X)+H(Y)-H(X,Y)\\
&= H(X)-H(X|Y)\\
&= H(Y)-H(Y|X)\\
&= \sum_{x,y}p(x,y)\log_2\frac{p(x,y)}{p(x)p(y)}\\
&= D_{KL}(p(x,y)||p(x)p(y))
\end{align}</script></li>
<li><p>KL和交叉熵：最小化KL = 最小化交叉熵</p>
</li>
<li></li>
</ul>
<h2 id="第十一章-“稀疏”数据、未对齐数据"><a href="#第十一章-“稀疏”数据、未对齐数据" class="headerlink" title="第十一章  “稀疏”数据、未对齐数据"></a>第十一章  “稀疏”数据、未对齐数据</h2><ul>
<li>图像在什么意义上稀疏？<ul>
<li>不是在原来的空间，而是在某种更有效的（通常<strong>高维但稀疏</strong>的）表达方式上</li>
</ul>
</li>
<li>动态时间弯曲<ul>
<li>假设两组（顺序的）数据 $x=(x_1,…,x_n),\, y=(y_1,…,y_m)$ 匹配</li>
<li>要求 $\forall i$，$x_i$ 必须和一个 $y_j$ 匹配，反之亦然</li>
<li>但是一个 $x_i$ 可以和多个 $y_j$ 匹配，一个 $y_i$ 也可以和多个 $x_j$ 匹配</li>
</ul>
</li>
</ul>
<h2 id="PR-11-HMM"><a href="#PR-11-HMM" class="headerlink" title="PR_11 HMM"></a>PR_11 HMM</h2><ul>
<li><p>随机过程：是一个有序的随机变量序列，可以看作是一个随机系统中状态随着时间演化的过程</p>
</li>
<li><p>马尔可夫性质</p>
<ul>
<li>$P(X_t|X_{1:t-1})=P(X_t|X_{t-1})$</li>
<li>无记忆性</li>
<li>好处是防止维度诅咒，$P(X_t|X_{1:t-1})$ 需要 $N^t$ 存储空间</li>
</ul>
</li>
<li><p>离散时间马尔科夫链（DTMC）</p>
<ul>
<li>DTMC中，随机变量被认为是可观测的</li>
</ul>
</li>
<li><p>GPT：generative pretraining transformer。目的是拟合自然语言的分布 $P(x)$</p>
</li>
<li><p>HMM 学习中的三个问题</p>
<ul>
<li>Evaluation：<ul>
<li>输入：一个完全指定的HMM模型，即 $\lambda=(\pi,A,B)$ 已知；一个完全观测的输出序列 $O=O_{1:T}$</li>
<li>输出： $P(O|\lambda)$ ，在这个模型 $\lambda$ 中观察到特点输出 $O$ 的概率</li>
<li>似然</li>
<li>作用：看作score，选择最适合的模型</li>
</ul>
</li>
<li><p>Decoding：</p>
<ul>
<li>输入：一个完全指定的HMM模型，即 $\lambda=(\pi,A,B)$ 已知；一个完全观测的输出序列 $O=O_{1:T}$；<strong>某个标准criterion</strong></li>
<li>输出：一个完全指定的隐变量序列 $X_{1:T}$ 的值</li>
<li>作用：<ul>
<li>语音识别中状态可能有实际意义；可以用来观察模型结构，优化模型</li>
</ul>
</li>
</ul>
</li>
<li><p>Learning：</p>
<ul>
<li>输入：<ul>
<li>网络结构，状态数、输出数</li>
<li>若干观测序列 $\{O\}$</li>
</ul>
</li>
<li>输出：最优的参数 $\lambda=\{\pi,A,B\}$ 使得 $P(\{O\}|\lambda)$ 最大（最大似然）</li>
<li>有时候一个足够长的观测序列就够了</li>
</ul>
</li>
<li>前两个问题：动态规划；第三个问题：期望最大化 EM</li>
</ul>
</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://seline02.github.io">Seline</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://seline02.github.io/2023/03/06/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">https://seline02.github.io/2023/03/06/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://seline02.github.io" target="_blank">Seline's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/03/06/%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/"><img class="prev-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">数学基础</div></div></a></div><div class="next-post pull-right"><a href="/2023/03/01/%E7%AE%97%E6%B3%95/"><img class="next-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">算法与数据结构</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Seline</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">25</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E7%AB%A0-%E7%BB%AA%E8%AE%BA"><span class="toc-number">1.</span> <span class="toc-text">第一章 绪论</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%E7%AB%A0-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9"><span class="toc-number">2.</span> <span class="toc-text">第二章 模型评估与选择</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E7%BB%8F%E9%AA%8C%E8%AF%AF%E5%B7%AE%E4%B8%8E%E8%BF%87%E6%8B%9F%E5%90%88"><span class="toc-number">2.0.1.</span> <span class="toc-text">2.1 经验误差与过拟合</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E8%AF%84%E4%BC%B0%E6%96%B9%E6%B3%95"><span class="toc-number">2.0.2.</span> <span class="toc-text">2.2 评估方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-%E6%80%A7%E8%83%BD%E5%BA%A6%E9%87%8F"><span class="toc-number">2.0.3.</span> <span class="toc-text">2.3 性能度量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-5-%E5%81%8F%E5%B7%AE%E4%B8%8E%E6%96%B9%E5%B7%AE"><span class="toc-number">2.0.4.</span> <span class="toc-text">2.5 偏差与方差</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E7%AB%A0-%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.</span> <span class="toc-text">第三章 线性模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="toc-number">3.0.1.</span> <span class="toc-text">3.2 线性回归</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E5%AF%B9%E6%95%B0%E5%87%A0%E7%8E%87%E5%9B%9E%E5%BD%92"><span class="toc-number">3.0.2.</span> <span class="toc-text">3.3 对数几率回归</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-%E7%BA%BF%E6%80%A7%E5%88%A4%E5%88%AB%E5%88%86%E6%9E%90"><span class="toc-number">3.0.3.</span> <span class="toc-text">3.4 线性判别分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-5-%E5%A4%9A%E5%88%86%E7%B1%BB%E5%AD%A6%E4%B9%A0"><span class="toc-number">3.0.4.</span> <span class="toc-text">3.5 多分类学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-6-%E7%B1%BB%E5%88%AB%E4%B8%8D%E5%B9%B3%E8%A1%A1%E9%97%AE%E9%A2%98"><span class="toc-number">3.0.5.</span> <span class="toc-text">3.6 类别不平衡问题</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC4%E7%AB%A0-%E5%86%B3%E7%AD%96%E6%A0%91"><span class="toc-number">4.</span> <span class="toc-text">第4章 决策树</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-%E5%9F%BA%E6%9C%AC%E6%B5%81%E7%A8%8B"><span class="toc-number">4.0.1.</span> <span class="toc-text">4.1 基本流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-%E5%88%92%E5%88%86%E9%80%89%E6%8B%A9"><span class="toc-number">4.0.2.</span> <span class="toc-text">4.2 划分选择</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-%E5%89%AA%E6%9E%9D%E5%A4%84%E7%90%86"><span class="toc-number">4.0.3.</span> <span class="toc-text">4.3 剪枝处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-%E8%BF%9E%E7%BB%AD%E4%B8%8E%E7%BC%BA%E5%A4%B1%E5%80%BC"><span class="toc-number">4.0.4.</span> <span class="toc-text">4.4 连续与缺失值</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-5-%E5%A4%9A%E5%8F%98%E9%87%8F%E5%86%B3%E7%AD%96%E6%A0%91"><span class="toc-number">4.0.5.</span> <span class="toc-text">4.5 多变量决策树</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%BA%94%E7%AB%A0-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">5.</span> <span class="toc-text">第五章 神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-%E7%A5%9E%E7%BB%8F%E5%85%83%E6%A8%A1%E5%9E%8B"><span class="toc-number">5.0.1.</span> <span class="toc-text">5.1 神经元模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-%E6%84%9F%E7%9F%A5%E6%9C%BA%E4%B8%8E%E5%A4%9A%E5%B1%82%E7%BD%91%E7%BB%9C"><span class="toc-number">5.0.2.</span> <span class="toc-text">5.2 感知机与多层网络</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-%E8%AF%AF%E5%B7%AE%E9%80%86%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95"><span class="toc-number">5.0.3.</span> <span class="toc-text">5.3 误差逆传播算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-%E5%85%A8%E5%B1%80%E6%9C%80%E5%B0%8F%E4%B8%8E%E5%B1%80%E9%83%A8%E6%9C%80%E5%B0%8F"><span class="toc-number">5.0.4.</span> <span class="toc-text">5.4 全局最小与局部最小</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-5-%E5%85%B6%E4%BB%96%E5%B8%B8%E8%A7%81%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">5.0.5.</span> <span class="toc-text">5.5 其他常见神经网络</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-6-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0"><span class="toc-number">5.0.6.</span> <span class="toc-text">5.6 深度学习</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC6%E7%AB%A0-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA"><span class="toc-number">6.</span> <span class="toc-text">第6章 支持向量机</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-%E9%97%B4%E9%9A%94%E4%B8%8E%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F"><span class="toc-number">6.0.1.</span> <span class="toc-text">6.1 间隔与支持向量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-%E5%AF%B9%E5%81%B6%E9%97%AE%E9%A2%98"><span class="toc-number">6.0.2.</span> <span class="toc-text">6.2 对偶问题</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-3-%E6%A0%B8%E5%87%BD%E6%95%B0"><span class="toc-number">6.0.3.</span> <span class="toc-text">6.3 核函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-4-%E8%BD%AF%E9%97%B4%E9%9A%94%E4%B8%8E%E6%AD%A3%E5%88%99%E5%8C%96"><span class="toc-number">6.0.4.</span> <span class="toc-text">6.4 软间隔与正则化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-5-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E5%9B%9E%E5%BD%92"><span class="toc-number">6.0.5.</span> <span class="toc-text">6.5 支持向量回归</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-6-%E6%A0%B8%E6%96%B9%E6%B3%95"><span class="toc-number">6.0.6.</span> <span class="toc-text">6.6 核方法</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC7%E7%AB%A0-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8"><span class="toc-number">7.</span> <span class="toc-text">第7章 贝叶斯分类器</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%86%B3%E7%AD%96%E8%AE%BA"><span class="toc-number">7.0.1.</span> <span class="toc-text">7.1 贝叶斯决策论</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-2-%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1"><span class="toc-number">7.0.2.</span> <span class="toc-text">7.2 极大似然估计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-3-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8"><span class="toc-number">7.0.3.</span> <span class="toc-text">7.3 朴素贝叶斯分类器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-4-%E5%8D%8A%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8"><span class="toc-number">7.0.4.</span> <span class="toc-text">7.4 半朴素贝叶斯分类器</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-5-%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BD%91"><span class="toc-number">7.0.5.</span> <span class="toc-text">7.5 贝叶斯网</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-6-EM%E7%AE%97%E6%B3%95"><span class="toc-number">7.0.6.</span> <span class="toc-text">7.6 EM算法</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC8%E7%AB%A0-%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0"><span class="toc-number">8.</span> <span class="toc-text">第8章 集成学习</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#8-1-%E4%B8%AA%E4%BD%93%E4%B8%8E%E9%9B%86%E6%88%90"><span class="toc-number">8.0.1.</span> <span class="toc-text">8.1 个体与集成</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-2-Boosting"><span class="toc-number">8.0.2.</span> <span class="toc-text">8.2 Boosting</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-3-Bagging%E4%B8%8E%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97"><span class="toc-number">8.0.3.</span> <span class="toc-text">8.3 Bagging与随机森林</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-4-%E7%BB%93%E5%90%88%E7%AD%96%E7%95%A5"><span class="toc-number">8.0.4.</span> <span class="toc-text">8.4 结合策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-5-%E5%A4%9A%E6%A0%B7%E6%80%A7"><span class="toc-number">8.0.5.</span> <span class="toc-text">8.5 多样性</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC9%E7%AB%A0-%E8%81%9A%E7%B1%BB"><span class="toc-number">9.</span> <span class="toc-text">第9章 聚类</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#9-1-%E8%81%9A%E7%B1%BB%E4%BB%BB%E5%8A%A1"><span class="toc-number">9.0.1.</span> <span class="toc-text">9.1 聚类任务</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-2-%E6%80%A7%E8%83%BD%E5%BA%A6%E9%87%8F"><span class="toc-number">9.0.2.</span> <span class="toc-text">9.2 性能度量</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-3-%E8%B7%9D%E7%A6%BB%E8%AE%A1%E7%AE%97"><span class="toc-number">9.0.3.</span> <span class="toc-text">9.3 距离计算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-4-%E5%8E%9F%E5%9E%8B%E8%81%9A%E7%B1%BB"><span class="toc-number">9.0.4.</span> <span class="toc-text">9.4 原型聚类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-5-%E5%AF%86%E5%BA%A6%E8%81%9A%E7%B1%BB"><span class="toc-number">9.0.5.</span> <span class="toc-text">9.5 密度聚类</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC10%E7%AB%A0-%E9%99%8D%E7%BB%B4%E4%B8%8E%E5%BA%A6%E9%87%8F%E5%AD%A6%E4%B9%A0"><span class="toc-number">10.</span> <span class="toc-text">第10章 降维与度量学习</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#10-1-k%E8%BF%91%E9%82%BB%E5%AD%A6%E4%B9%A0"><span class="toc-number">10.0.1.</span> <span class="toc-text">10.1 k近邻学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-2-%E4%BD%8E%E7%BB%B4%E5%B5%8C%E5%85%A5"><span class="toc-number">10.0.2.</span> <span class="toc-text">10.2 低维嵌入</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-3-%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90"><span class="toc-number">10.0.3.</span> <span class="toc-text">10.3 主成分分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-4-%E6%A0%B8%E5%8C%96%E7%BA%BF%E6%80%A7%E9%99%8D%E7%BB%B4"><span class="toc-number">10.0.4.</span> <span class="toc-text">10.4 核化线性降维</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-5-%E6%B5%81%E5%BD%A2%E5%AD%A6%E4%B9%A0"><span class="toc-number">10.0.5.</span> <span class="toc-text">10.5 流形学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">10.0.6.</span> <span class="toc-text">总结</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC11%E7%AB%A0-%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E4%B8%8E%E7%A8%80%E7%96%8F%E5%AD%A6%E4%B9%A0"><span class="toc-number">11.</span> <span class="toc-text">第11章 特征选择与稀疏学习</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB"><span class="toc-number">12.</span> <span class="toc-text">模式识别</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E5%85%AB%E7%AB%A0-%E6%A6%82%E7%8E%87%E6%96%B9%E6%B3%95"><span class="toc-number">12.1.</span> <span class="toc-text">第八章 概率方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B9%9D%E7%AB%A0-%E8%B7%9D%E7%A6%BB%E5%BA%A6%E9%87%8F%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%8F%98%E6%8D%A2"><span class="toc-number">12.2.</span> <span class="toc-text">第九章 距离度量与数据变换</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E5%8D%81%E7%AB%A0-%E4%BF%A1%E6%81%AF%E8%AE%BA%E4%B8%8E%E5%86%B3%E7%AD%96%E6%A0%91"><span class="toc-number">12.3.</span> <span class="toc-text">第十章 信息论与决策树</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E5%8D%81%E4%B8%80%E7%AB%A0-%E2%80%9C%E7%A8%80%E7%96%8F%E2%80%9D%E6%95%B0%E6%8D%AE%E3%80%81%E6%9C%AA%E5%AF%B9%E9%BD%90%E6%95%B0%E6%8D%AE"><span class="toc-number">12.4.</span> <span class="toc-text">第十一章  “稀疏”数据、未对齐数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#PR-11-HMM"><span class="toc-number">12.5.</span> <span class="toc-text">PR_11 HMM</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/05/08/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/" title="线性代数"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="线性代数"/></a><div class="content"><a class="title" href="/2023/05/08/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/" title="线性代数">线性代数</a><time datetime="2023-05-08T07:05:38.000Z" title="发表于 2023-05-08 15:05:38">2023-05-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/23/AIMA%E7%AC%94%E8%AE%B0/" title="AIMA笔记"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="AIMA笔记"/></a><div class="content"><a class="title" href="/2023/03/23/AIMA%E7%AC%94%E8%AE%B0/" title="AIMA笔记">AIMA笔记</a><time datetime="2023-03-23T09:51:42.000Z" title="发表于 2023-03-23 17:51:42">2023-03-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/21/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AC%94%E8%AE%B0/" title="神经网络笔记"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="神经网络笔记"/></a><div class="content"><a class="title" href="/2023/03/21/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AC%94%E8%AE%B0/" title="神经网络笔记">神经网络笔记</a><time datetime="2023-03-21T04:32:51.000Z" title="发表于 2023-03-21 12:32:51">2023-03-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/20/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/" title="自然语言处理笔记"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="自然语言处理笔记"/></a><div class="content"><a class="title" href="/2023/03/20/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/" title="自然语言处理笔记">自然语言处理笔记</a><time datetime="2023-03-20T08:31:21.000Z" title="发表于 2023-03-20 16:31:21">2023-03-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/15/%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E7%AC%94%E8%AE%B0/" title="多智能体笔记"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="多智能体笔记"/></a><div class="content"><a class="title" href="/2023/03/15/%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E7%AC%94%E8%AE%B0/" title="多智能体笔记">多智能体笔记</a><time datetime="2023-03-15T08:05:41.000Z" title="发表于 2023-03-15 16:05:41">2023-03-15</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By Seline</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>