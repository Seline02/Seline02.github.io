<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>AIMA笔记 | Seline's blog</title><meta name="author" content="Seline"><meta name="copyright" content="Seline"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="AI 历史 阶段 推理期：60-70年代  至  80年代初期 知识期：80年代初期  至  90年代中期 专家系统expert systems   学习期：90年代中期  至     两次寒冬 第一次寒冬开始于1974至1977，也被称为“AI危机”，主要是由于当时作为AI研究的核心技术——知识表示认知机制表现不佳， 机器翻译“寂静的十年” 联结主义的衰落（Minsky and Papert’s">
<meta property="og:type" content="article">
<meta property="og:title" content="AIMA笔记">
<meta property="og:url" content="https://seline02.github.io/2023/03/23/AIMA%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="Seline&#39;s blog">
<meta property="og:description" content="AI 历史 阶段 推理期：60-70年代  至  80年代初期 知识期：80年代初期  至  90年代中期 专家系统expert systems   学习期：90年代中期  至     两次寒冬 第一次寒冬开始于1974至1977，也被称为“AI危机”，主要是由于当时作为AI研究的核心技术——知识表示认知机制表现不佳， 机器翻译“寂静的十年” 联结主义的衰落（Minsky and Papert’s">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">
<meta property="article:published_time" content="2023-03-23T09:51:42.000Z">
<meta property="article:modified_time" content="2023-07-01T04:14:07.651Z">
<meta property="article:author" content="Seline">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://seline02.github.io/2023/03/23/AIMA%E7%AC%94%E8%AE%B0/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'AIMA笔记',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-07-01 12:14:07'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.2.0"><link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">25</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><hr/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Seline's blog</a></span><div id="menus"><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">AIMA笔记</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-03-23T09:51:42.000Z" title="发表于 2023-03-23 17:51:42">2023-03-23</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-07-01T04:14:07.651Z" title="更新于 2023-07-01 12:14:07">2023-07-01</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="AIMA笔记"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="AI-历史"><a href="#AI-历史" class="headerlink" title="AI 历史"></a>AI 历史</h1><ul>
<li>阶段<ul>
<li>推理期：60-70年代  至  80年代初期</li>
<li>知识期：80年代初期  至  90年代中期<ul>
<li>专家系统expert systems</li>
</ul>
</li>
<li>学习期：90年代中期  至  </li>
</ul>
</li>
<li>两次寒冬<ul>
<li>第一次寒冬开始于1974至1977，也被称为“AI危机”，主要是由于当时作为AI研究的核心技术——<strong>知识表示认知机制</strong>表现不佳，<ul>
<li>机器翻译“寂静的十年”</li>
<li>联结主义的衰落（Minsky and Papert’s book Perceptrons：感知器只能被训练用于解决线性可分问题，异或问题就不行。对于多层网络没有算法能用来训练）</li>
<li>组合爆炸问题（计算量爆炸），但计算能力弱（Lighthill report）</li>
</ul>
</li>
<li>第二次寒冬主要指1987年英国素有“机器人热”的情况出现突然转折，以及90年代以后因无法解决实际问题而导致投资者收回投资撤出的情况。<ul>
<li>John McCarthy 对专家系统进行批评说，它们缺少常识性知识</li>
<li>人工智能领域当时主要使用约翰麦卡锡的LISP编程语言，逐步发展的LISP机器被蓬勃发展的个人电脑击败，专用LISP机器硬件销售市场严重崩溃</li>
</ul>
</li>
</ul>
</li>
<li>1956 Dartmouth会议（阿兰图灵没来，约翰麦卡锡、马文闵斯基、克莱德香农来了）<ul>
<li>John McCarthy（人工智能之父）：人工智能不一定等于生物智能</li>
<li>Marvin Minsky</li>
<li>Turing没来</li>
</ul>
</li>
<li>Turing：“计算机科学之父”和“人工智能之父”<ul>
<li>《机器能思考吗》论文中，图灵提出了一种判定机器是否具有智能的实验方法，即著名的<strong>图灵测试</strong>：如果一台机器能够与人类展开对话而不能被辨别出其机器身份，那么这台机器就是智能的。</li>
</ul>
</li>
<li>图灵，约翰·麦卡锡，马文·明斯基</li>
<li><img src="image-20230323182827185.png" alt="image-20230323182827185" style="zoom:50%;"></li>
<li>IBM 深蓝：国际象棋（穷举搜索 min-max、alpha-beta剪枝）</li>
<li>AlphaGo的主力<ul>
<li>从大量人工到人工越来越少</li>
<li>希望机器具有和人一样的学习能力，而不是把人学习总结的结果放到机器里面</li>
</ul>
</li>
<li>Agent包括：humans、robots、softbots（软件机器人）、thermostats（自动调温器）</li>
<li>Agent types<ul>
<li>最简单的条件反射 simple reflex agents</li>
<li>有状态的条件反射 reflex agents with state（前面两条都可以写成if-else）</li>
<li>goal-based agents</li>
<li>utility-based agents</li>
</ul>
</li>
</ul>
<p><img src="image-20230629195044879.png" alt="image-20230629195044879" style="zoom:50%;"></p>
<p><img src="image-20230629195106706.png" alt="image-20230629195106706" style="zoom:50%;"></p>
<h1 id="搜索"><a href="#搜索" class="headerlink" title="搜索"></a>搜索</h1><ul>
<li>搜索问题中 node 是数据结构，不同的node可能包含相同的state</li>
<li><p><img src="image-20230323192305179.png" alt="image-20230323192305179" style="zoom:50%;"></p>
</li>
<li><p>tree search：uninformed</p>
</li>
</ul>
<p><strong>蒙特卡洛树搜索（简称 MCTS）</strong>：基于蒙特卡洛方法的树搜索</p>
<p>简而言之是用<strong>蒙特卡洛方法</strong>估算每一种走法的胜率。如果描述的再具体一些，通过不断的模拟每一种走法，直至<strong>终局</strong>，该走法的模拟总次数N，与胜局次数W，即可推算出该走法的胜率为 W/N。</p>
<p><img src="image-20230330135621088.png" alt="image-20230330135621088" style="zoom:50%;"></p>
<ol>
<li><strong>选择</strong>（Selection）</li>
<li><strong>扩展</strong> (expansion)</li>
<li><strong>模拟</strong>（Simulation）</li>
<li><strong>回溯</strong>（Backpropagation）</li>
</ol>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/53948964">https://zhuanlan.zhihu.com/p/53948964</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/361120908">https://zhuanlan.zhihu.com/p/361120908</a></p>
<p>是最优的（前提：无数次采样）</p>
<h3 id="AlphaGo"><a href="#AlphaGo" class="headerlink" title="AlphaGo"></a>AlphaGo</h3><p>是tree search、DNN、RL的组合</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/410069008">https://zhuanlan.zhihu.com/p/410069008</a></p>
<h3 id="uninformed-search-无信息搜索"><a href="#uninformed-search-无信息搜索" class="headerlink" title="uninformed search 无信息搜索"></a>uninformed search 无信息搜索</h3><ul>
<li>无信息搜索也被称为盲目搜索，该术语（无信息、盲目的）意味着该搜索策略<strong>没有</strong>超出问题定义提供的状态之外的<strong>附加信息</strong>。所有能做的就是<strong>生成后继节点</strong>，并且<strong>区分</strong>一个目标状态或一个非目标状态。所有的搜索策略是由节点<strong>扩展的顺序</strong>加以区分。这些搜索策略是：<strong>宽度优先、深度优先、以及一致代价搜索。</strong></li>
</ul>
<p><img src="image-20230410202559161.png" alt="image-20230410202559161" style="zoom:50%;"></p>
<p>（1）b或分支因子，其表示任何结点的最多后继数；</p>
<p>（2）d或目标结点所在的最浅深度（从根节点到目标状态的步数）；</p>
<p>（3）m状态空间中任何路径的最大长度。</p>
<h4 id="BFS"><a href="#BFS" class="headerlink" title="BFS"></a>BFS</h4><ul>
<li><p><img src="image-20230410211326504.png" alt="image-20230410211326504" style="zoom:50%;"></p>
</li>
<li><p>d是目标所在的那一层</p>
</li>
</ul>
<h4 id="DFS"><a href="#DFS" class="headerlink" title="DFS"></a>DFS</h4><ul>
<li><p><img src="image-20230410211429347.png" alt="image-20230410211429347" style="zoom:50%;"></p>
</li>
<li><p>m是最深的层数，$b^m$ 和 $b^d$ 是不同阶的</p>
</li>
<li>时间长，空间小</li>
<li>最大空间是一次下去走到底，是线性的</li>
<li>不是<strong>optimal</strong>的</li>
</ul>
<h4 id="uniform-cost-search-代价优先搜索"><a href="#uniform-cost-search-代价优先搜索" class="headerlink" title="uniform-cost search 代价优先搜索"></a>uniform-cost search 代价优先搜索</h4><ul>
<li>从队列中出去的cost都是逐渐增长的</li>
<li>如果现在有一个node比在memory中的node的cost还要小，先加到队列中去</li>
<li>不是在把node往里放的时候检查goal state，把node往外拿的时候检查</li>
<li>如果cost都一样，等于BFS</li>
<li><img src="image-20230410214323452.png" alt="image-20230410214323452" style="zoom:50%;"></li>
</ul>
<p><img src="image-20230410214256694.png" alt="image-20230410214256694" style="zoom:50%;"></p>
<ul>
<li>考！！！</li>
<li>BFS时间更低，DFS空间更低，如何结合优点？</li>
</ul>
<h4 id="深度受限的深度优先搜索"><a href="#深度受限的深度优先搜索" class="headerlink" title="深度受限的深度优先搜索"></a>深度受限的深度优先搜索</h4><p><img src="image-20230410220806633.png" alt="image-20230410220806633" style="zoom:50%;"></p>
<p><img src="image-20230410220835219.png" alt="image-20230410220835219" style="zoom:50%;"></p>
<ul>
<li><strong>迭代加深的深度优先搜索</strong>：宏观上是BFS，是一层一层搜的，微观上是DFS</li>
<li>上面有重复搜的，但多花的时间是常数倍，时间复杂度的阶和BFS的阶一样</li>
</ul>
<p><img src="image-20230410220940961.png" alt="image-20230410220940961" style="zoom:50%;"></p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p><img src="image-20230410232108449.png" alt="image-20230410232108449" style="zoom:50%;"></p>
<h3 id="informed-cost-search"><a href="#informed-cost-search" class="headerlink" title="informed-cost search"></a>informed-cost search</h3><h4 id="A"><a href="#A" class="headerlink" title="$A^*$"></a>$A^*$</h4><ul>
<li>可采纳性（admissible）：heuristic function 只能低估 $h(n)\leq h^*(n)$</li>
<li>一致性（consistency）：$h(n)\leq c(n,a,n’)+h(n’)$</li>
</ul>
<p><img src="image-20230411152858591.png" alt="image-20230411152858591" style="zoom:50%;"></p>
<ul>
<li>证明最优性：<ul>
<li>对于任何一个在最优路径上的node，$f(n)=g(n)+h(n)\leq g(n)+h^*(n)=g(G(1))\leq g(G(2))$，所以最优路径上的那些结点会比 $G(2)$ 先出来。</li>
<li>$h(n)$ 是启发式的值，$h^*(n)$ 是实际值</li>
<li><img src="image-20230411163052333.png" alt="image-20230411163052333" style="zoom:50%;"></li>
</ul>
</li>
</ul>
<ul>
<li>$A^<em>$ 有如下性质：如果 $h(n)$ 是可采纳的，那么 $A^</em>$ 的树搜索版本是最优的；如果 $h(n)$ 是一致的，那么图搜索的 $A^*$ 算法是最优的</li>
<li>从一致性证明可采纳性<ul>
<li>数学归纳法：对从n结点到目标的最短路径上的结点个数k做归纳</li>
<li>k=1，$n’$ 是目标节点，$h(n)\leq c(n,a,n’)$</li>
<li>假设 $n’$ 在最短路径上离目标点k步的地方，且 $h(n’)$ 是可采纳的，有 $h(n)\leq c(n,a,n’)+h(n’)\leq c(n,a,n’)+h^<em>(n’)=h^</em>(n)$</li>
<li>所以最短路上距离目标k+1步的结点也满足可采纳性</li>
</ul>
</li>
</ul>
<p>旅行商问题TSP NP难问题 放松成 最小生成树问题</p>
<p><a target="_blank" rel="noopener" href="https://www.docin.com/p-669655901.html">https://www.docin.com/p-669655901.html</a></p>
<p>？？？</p>
<p><img src="image-20230415170522844.png" alt="image-20230415170522844" style="zoom:50%;"></p>
<p><img src="image-20230415164820193.png" alt="image-20230415164820193" style="zoom:50%;"></p>
<p>算法导论P654</p>
<p><img src="image-20230415171045664.png" alt="image-20230415171045664" style="zoom:50%;"></p>
<p><img src="image-20230415170720925.png" alt="image-20230415170720925" style="zoom:80%;"></p>
<p><img src="image-20230415171119282.png" alt="image-20230415171119282" style="zoom:60%;"></p>
<ul>
<li>IBM deep blue 和深度学习无关</li>
</ul>
<h3 id="minimax"><a href="#minimax" class="headerlink" title="minimax"></a>minimax</h3><p><img src="image-20230411170236642.png" alt="image-20230411170236642" style="zoom:50%;"></p>
<ul>
<li>$\alpha-\beta$ 剪枝：time complexity $O(b^{m/2})$，不影响 completeness</li>
<li>深度受限：看不到终局，采用评估当前局面的函数。不能完全保证是最优的</li>
</ul>
<h3 id="General-Solution-Space-Search-amp-CSP"><a href="#General-Solution-Space-Search-amp-CSP" class="headerlink" title="General Solution Space Search &amp; CSP"></a>General Solution Space Search &amp; CSP</h3><ul>
<li>贪心思想<ul>
<li>爬山、梯度下降（做了很大的“利用”）</li>
<li>都可能找不到全局最优解</li>
</ul>
</li>
<li>纯随机探索：在无限步后是最优的（做了很大的“探索”）</li>
</ul>
<ul>
<li>局部搜索<ul>
<li>爬山法（贪婪局部搜索，只是选择邻居中状态最好的一个）</li>
<li>模拟退火搜索（把爬山法和随机行走以某种方式结合）</li>
<li>局部束搜索</li>
<li>遗传算法（零阶，不需求导，收敛/有最优解条件）</li>
</ul>
</li>
</ul>
<h1 id="Knowledge"><a href="#Knowledge" class="headerlink" title="Knowledge"></a>Knowledge</h1><ul>
<li><p>inference by enumeration：Depth-first enumeration of all models is <strong>sound and complete</strong></p>
<ul>
<li>$O(2^n)$ for $n$ symbols；problem is <strong>co-NP-complete</strong></li>
</ul>
</li>
<li><p>命题逻辑定理证明</p>
<ul>
<li>概念<ul>
<li>有效性（valid）：一个语句是有效的，如果在所有的模型中它都为真<ul>
<li>$\alpha\models \beta$ 当且仅当语句 $\alpha \Rightarrow\beta$ 是有效的<ul>
<li>可以通过检查每个模型中 $\alpha \Rightarrow\beta$ 来判断 $\alpha\models \beta$，或者证明 $\alpha \Rightarrow\beta$ 等价于 True</li>
<li>反过来，演绎定理说明每个有效的蕴含语句都描述了一个合法的推理</li>
</ul>
</li>
</ul>
</li>
<li>可满足性（satisfiability）<ul>
<li>如果一个语句在某些模型中为真，那么这个句子是可满足的</li>
<li><strong>命题逻辑语句的可满足性判定</strong>——<strong>SAT问题</strong>，是第一个被证明为NP完全的问题</li>
<li>$KB\models \alpha$ 当且仅当 $KB\wedge \neg \alpha$ 是不可满足的</li>
</ul>
</li>
</ul>
</li>
<li>前向和反向链接<ul>
<li>前向链接：数据驱动，自动、无意识的过程</li>
<li>反向链接：目标驱动，适用于问题解决，通常开销远小于知识库规模的线性值<ul>
<li>从查询开始进行推理。如果查询 q 已知为真，那么无须进行任何操作。否则，算法寻找知识库中那些能以 q 为结论的蕴涵式。如果其中某个蕴涵式的所有前提都能证明为真（通过反向链接），则 q 为真</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>命题逻辑三种特性</p>
<ul>
<li><strong>描述性语言</strong>。它的语义是基于语句和可能世界之间的真值关系</li>
<li>（有充分的表达能力，）可以采用析取式和否定式来处理不完全信息</li>
<li><strong>合成性</strong>。语句的含义是它的各部分含义的一个函数，如 $S_{1,4}\wedge S_{1,2}$ 与 $S_{1,4}$ 和 $S_{1,2}$ 的含义有关</li>
</ul>
</li>
<li><p>原子语句</p>
<ul>
<li>由谓词符号以及随后被括号括起来的列表项组成</li>
<li>原子语句可以使用复合项作为参数</li>
</ul>
</li>
<li><p>复合语句</p>
<ul>
<li>由逻辑连接词构成的语句</li>
</ul>
</li>
<li><p>命题逻辑真值表有穷；一阶逻辑真值表<strong>无穷</strong>（有变量，变量一旦可以取成谓词，则可以自己嵌套自己，变量的取值可以无穷）</p>
</li>
<li><p>命题化</p>
<ul>
<li>通过保持蕴涵，每个一阶知识库和查询都可以命题化。这样，得到一个有关蕴涵的完备决策过程……也可能得不到。</li>
<li>当知识库中包含函词时，可能的基项置换集是无限的</li>
<li>如果某个语句被原始的一阶知识库蕴涵，则存在一个只涉及命题化知识库的有限子集（已被证明）</li>
<li>通过命题化进行一阶推理是<strong>完备</strong>的，即任何蕴涵语句都能得到证明</li>
<li>一阶逻辑的蕴涵问题是<strong>半可判定</strong>的：存在算法能够证明蕴涵成立的语句，不存在算法否定蕴涵不成立的语句</li>
</ul>
</li>
<li><p>实例化后可以用处理命题逻辑的方法处理一阶逻辑，这是系统在一阶逻辑上进行推理的办法</p>
<ul>
<li>全称量词把所有可能性写一遍，存在量词就找个名字</li>
<li>前提是不嵌套，有限长</li>
</ul>
</li>
<li><p>三种命题逻辑的推理方法都是complete和sound</p>
<ul>
<li>完备complete不一定是算法决定的，要根据问题。命题逻辑是有限的，容易证明complete</li>
<li>一阶逻辑是无限的，算法最多是正确的，不一定完备</li>
<li>一阶逻辑FOL是semidecidable（最坏情况是不可判定）<ul>
<li>与一般的一阶逻辑一样，具有确定子句的蕴涵是半可判定的</li>
</ul>
</li>
</ul>
</li>
<li><p>一阶逻辑的推理</p>
<ul>
<li><p>unification</p>
</li>
<li><p>前件推理</p>
<ul>
<li><p>证据出发推结论</p>
</li>
<li><p>事实和条件不一定能匹配上，要做一个替换</p>
</li>
<li><p>正确但不完备，不一定能停下来（可能有无穷递归）；有限clause是正确且完备的</p>
</li>
<li><p>和命题逻辑的前向推理多了一个unify</p>
</li>
<li><p><img src="image-20230414162807363.png" alt="image-20230414162807363" style="zoom:50%;"></p>
</li>
<li><p>性质</p>
<ul>
<li>前向链接对于<strong>一阶确定子句</strong>是正确、完备的</li>
<li><p>数据日志 是一种受限于一阶确定语句的没有函词的语言。FC 对数据日志可在多项式次迭代内完成 $p\cdot n^k$</p>
</li>
<li><p>与一般的一阶逻辑一样，具有确定子句的蕴涵是半可判定的</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>反向链接</p>
<ul>
<li>DFS搜索，空间需求与证明规模呈线性关系</li>
<li>反向链接与前向链接不同，要忍受重复状态和不完备问题的困扰</li>
<li>广泛应用于逻辑程序设计系统</li>
</ul>
</li>
<li><p>Prolog</p>
<ul>
<li><p>用prolog实现dfs，不是过程性的表述</p>
</li>
<li><p>Prolog程序的执行是深度优先的反向链接</p>
</li>
<li><pre><code>dfs(X)  :-  goal(X)
dfs(X)  :-  successor(X,S), dfs(S)
</code></pre><p>backward chaining是用深度优先搜索实现的，prolog是用backward chaining实现的</p>
</li>
<li><p>Prolog是<strong>不完备</strong>的，原因是对有些知识库，它无法证明被蕴涵的语句。前向链接不会有这个问题</p>
</li>
</ul>
</li>
<li><p>FOL的消解是完备的</p>
</li>
</ul>
<ul>
<li>SAT problems<ul>
<li>2SAT：every clause has at most 2 literals    =&gt;   P-solvable</li>
<li>3SAT：every clause has at most 3 literals    =&gt;   NP-hard</li>
<li>DFLL：a deep-first search with heuristics （回溯/DFS）</li>
<li>WalkSAT：a local search hill-climbing or others（failure $\not=$ unsatisfiable）</li>
</ul>
</li>
</ul>
<h1 id="概率推理"><a href="#概率推理" class="headerlink" title="概率推理"></a>概率推理</h1><ul>
<li>给定父结点，结点 $X$ 条件独立于它的非后代结点</li>
<li>给定马尔可夫覆盖（一个结点的父结点、子结点以及子结点的父结点），结点 $X$ 条件独立于网络中的所有其他结点</li>
</ul>
<ul>
<li>贝叶斯网<ul>
<li>精确推断：先把隐变量全部拆出来，再写成条件概率形式<ul>
<li>recursive depth-first enumeration：$O(n)$ space，$O(d^n)$ time</li>
</ul>
</li>
<li><strong>近似推断</strong><ul>
<li><strong>直接采样</strong><ul>
<li><strong>拒绝采样</strong>：计算条件概率 $P(X|e)$。先根据网络指定的先验分布生成采样样本，再拒绝所有与证据不匹配的样本，最后在剩余样本中通过统计 $X=x$ 的出现频次而计算出估计概率 $\hat{P}(X=x|e)$ <ul>
<li>把不符合条件的采样扔掉（效率低，万一所需的采样概率很小的话需要sample很多）</li>
</ul>
</li>
<li><strong>似然加权</strong>：先把条件固定住，再去sample其他的变量。每个sample的样本有一个权重</li>
</ul>
</li>
<li><strong>MCMC 马尔可夫链蒙特卡洛</strong><ul>
<li>马尔可夫表示没有记忆性</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li>NPC：<ul>
<li>存在这一类NP问题，所有的NP问题都可以约化成它。换句话说，只要解决了这个问题，那么所有的NP问题都解决了。</li>
<li>同时满足下面<strong>两个条件</strong>的问题就是NPC问题。<ul>
<li>首先，它得是一个NP问题；</li>
<li>然后，所有的NP问题都可以约化到它。</li>
</ul>
</li>
<li>证明一个问题是 NPC问题也很简单。先证明它至少是一个NP问题，再证明其中一个已知的NPC问题能约化到它</li>
<li>逻辑电路问题是NPC类问题的“鼻祖”。<ul>
<li>有了第一个NPC问题后，一大堆NPC问题就出现了，因为再证明一个新的NPC问题只需要将一个已知的NPC问题约化到它就行了。后来，Hamilton 回路成了NPC问题，TSP问题也成了NPC问题。</li>
</ul>
</li>
</ul>
</li>
<li>NP-hard<ul>
<li>NP-Hard问题是这样一种问题，它满足NPC问题定义的第二条但不一定要满足第一条（就是说，NP-Hard问题要比 NPC问题的范围广）。</li>
<li>即不一定是NP问题，但NP问题能约化成NP-hard</li>
</ul>
</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://seline02.github.io">Seline</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://seline02.github.io/2023/03/23/AIMA%E7%AC%94%E8%AE%B0/">https://seline02.github.io/2023/03/23/AIMA%E7%AC%94%E8%AE%B0/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://seline02.github.io" target="_blank">Seline's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/05/08/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"><img class="prev-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">线性代数</div></div></a></div><div class="next-post pull-right"><a href="/2023/03/21/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AC%94%E8%AE%B0/"><img class="next-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">神经网络笔记</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Seline</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">25</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">6</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#AI-%E5%8E%86%E5%8F%B2"><span class="toc-number">1.</span> <span class="toc-text">AI 历史</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%90%9C%E7%B4%A2"><span class="toc-number">2.</span> <span class="toc-text">搜索</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#AlphaGo"><span class="toc-number">2.0.1.</span> <span class="toc-text">AlphaGo</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#uninformed-search-%E6%97%A0%E4%BF%A1%E6%81%AF%E6%90%9C%E7%B4%A2"><span class="toc-number">2.0.2.</span> <span class="toc-text">uninformed search 无信息搜索</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#BFS"><span class="toc-number">2.0.2.1.</span> <span class="toc-text">BFS</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#DFS"><span class="toc-number">2.0.2.2.</span> <span class="toc-text">DFS</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#uniform-cost-search-%E4%BB%A3%E4%BB%B7%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2"><span class="toc-number">2.0.2.3.</span> <span class="toc-text">uniform-cost search 代价优先搜索</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B7%B1%E5%BA%A6%E5%8F%97%E9%99%90%E7%9A%84%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2"><span class="toc-number">2.0.2.4.</span> <span class="toc-text">深度受限的深度优先搜索</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">2.0.2.5.</span> <span class="toc-text">总结</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#informed-cost-search"><span class="toc-number">2.0.3.</span> <span class="toc-text">informed-cost search</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#A"><span class="toc-number">2.0.3.1.</span> <span class="toc-text">$A^*$</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#minimax"><span class="toc-number">2.0.4.</span> <span class="toc-text">minimax</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#General-Solution-Space-Search-amp-CSP"><span class="toc-number">2.0.5.</span> <span class="toc-text">General Solution Space Search &amp; CSP</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Knowledge"><span class="toc-number">3.</span> <span class="toc-text">Knowledge</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%A6%82%E7%8E%87%E6%8E%A8%E7%90%86"><span class="toc-number">4.</span> <span class="toc-text">概率推理</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/05/08/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/" title="线性代数"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="线性代数"/></a><div class="content"><a class="title" href="/2023/05/08/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/" title="线性代数">线性代数</a><time datetime="2023-05-08T07:05:38.000Z" title="发表于 2023-05-08 15:05:38">2023-05-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/23/AIMA%E7%AC%94%E8%AE%B0/" title="AIMA笔记"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="AIMA笔记"/></a><div class="content"><a class="title" href="/2023/03/23/AIMA%E7%AC%94%E8%AE%B0/" title="AIMA笔记">AIMA笔记</a><time datetime="2023-03-23T09:51:42.000Z" title="发表于 2023-03-23 17:51:42">2023-03-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/21/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AC%94%E8%AE%B0/" title="神经网络笔记"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="神经网络笔记"/></a><div class="content"><a class="title" href="/2023/03/21/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AC%94%E8%AE%B0/" title="神经网络笔记">神经网络笔记</a><time datetime="2023-03-21T04:32:51.000Z" title="发表于 2023-03-21 12:32:51">2023-03-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/20/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/" title="自然语言处理笔记"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="自然语言处理笔记"/></a><div class="content"><a class="title" href="/2023/03/20/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/" title="自然语言处理笔记">自然语言处理笔记</a><time datetime="2023-03-20T08:31:21.000Z" title="发表于 2023-03-20 16:31:21">2023-03-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/03/15/%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E7%AC%94%E8%AE%B0/" title="多智能体笔记"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="多智能体笔记"/></a><div class="content"><a class="title" href="/2023/03/15/%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E7%AC%94%E8%AE%B0/" title="多智能体笔记">多智能体笔记</a><time datetime="2023-03-15T08:05:41.000Z" title="发表于 2023-03-15 16:05:41">2023-03-15</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By Seline</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>